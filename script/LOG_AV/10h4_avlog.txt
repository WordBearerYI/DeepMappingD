maxpool
latent size single: 16
loading dataset
16
pccppcpc1123 (16, 27, 48, 3)
creating model
start training
[8/15000], training loss: 0.1688
[16/15000], training loss: 0.1267
[24/15000], training loss: 0.1169
[32/15000], training loss: 0.1194
[40/15000], training loss: 0.1079
16
AVD_Home_010_1_traj4, ate: 460.6710411008095
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[48/15000], training loss: 0.1086
[56/15000], training loss: 0.1221
[64/15000], training loss: 0.1138
[72/15000], training loss: 0.1175
[80/15000], training loss: 0.1160
16
AVD_Home_010_1_traj4, ate: 480.8711435197269
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[88/15000], training loss: 0.1102
[96/15000], training loss: 0.1029
[104/15000], training loss: 0.0935
[112/15000], training loss: 0.1032
[120/15000], training loss: 0.1063
16
AVD_Home_010_1_traj4, ate: 537.2694340470422
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[128/15000], training loss: 0.1135
[136/15000], training loss: 0.0937
[144/15000], training loss: 0.1057
[152/15000], training loss: 0.1255
[160/15000], training loss: 0.0962
16
AVD_Home_010_1_traj4, ate: 522.2710042368972
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[168/15000], training loss: 0.1046
[176/15000], training loss: 0.0984
[184/15000], training loss: 0.1040
[192/15000], training loss: 0.1051
[200/15000], training loss: 0.0948
16
AVD_Home_010_1_traj4, ate: 488.6840078002137
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[208/15000], training loss: 0.1003
[216/15000], training loss: 0.0994
[224/15000], training loss: 0.1189
[232/15000], training loss: 0.1090
[240/15000], training loss: 0.1001
16
AVD_Home_010_1_traj4, ate: 502.5608467532247
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[248/15000], training loss: 0.0958
[256/15000], training loss: 0.0924
[264/15000], training loss: 0.1102
[272/15000], training loss: 0.1008
[280/15000], training loss: 0.0895
16
AVD_Home_010_1_traj4, ate: 495.97052988015906
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[288/15000], training loss: 0.1024
[296/15000], training loss: 0.0964
[304/15000], training loss: 0.1047
[312/15000], training loss: 0.1128
[320/15000], training loss: 0.0921
16
AVD_Home_010_1_traj4, ate: 467.1498515267869
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[328/15000], training loss: 0.1056
[336/15000], training loss: 0.0915
[344/15000], training loss: 0.0822
[352/15000], training loss: 0.0861
[360/15000], training loss: 0.1033
16
AVD_Home_010_1_traj4, ate: 386.83624779100285
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[368/15000], training loss: 0.1178
[376/15000], training loss: 0.0898
[384/15000], training loss: 0.0933
[392/15000], training loss: 0.1041
[400/15000], training loss: 0.0933
16
AVD_Home_010_1_traj4, ate: 351.15332988811485
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[408/15000], training loss: 0.0881
[416/15000], training loss: 0.1112
[424/15000], training loss: 0.1020
[432/15000], training loss: 0.0922
[440/15000], training loss: 0.0839
16
AVD_Home_010_1_traj4, ate: 289.0286951954696
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[448/15000], training loss: 0.0938
[456/15000], training loss: 0.0935
[464/15000], training loss: 0.0763
[472/15000], training loss: 0.0874
[480/15000], training loss: 0.1028
16
AVD_Home_010_1_traj4, ate: 273.36296939071644
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[488/15000], training loss: 0.0886
[496/15000], training loss: 0.0968
[504/15000], training loss: 0.0779
[512/15000], training loss: 0.0851
[520/15000], training loss: 0.1028
16
AVD_Home_010_1_traj4, ate: 243.87531213158985
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[528/15000], training loss: 0.1001
[536/15000], training loss: 0.0763
[544/15000], training loss: 0.0849
[552/15000], training loss: 0.1011
[560/15000], training loss: 0.0858
16
AVD_Home_010_1_traj4, ate: 237.08494755262257
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[568/15000], training loss: 0.1006
[576/15000], training loss: 0.0926
[584/15000], training loss: 0.0941
[592/15000], training loss: 0.0920
[600/15000], training loss: 0.0924
16
AVD_Home_010_1_traj4, ate: 231.63503276217418
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[608/15000], training loss: 0.0839
[616/15000], training loss: 0.0718
[624/15000], training loss: 0.0913
[632/15000], training loss: 0.0747
[640/15000], training loss: 0.0876
16
AVD_Home_010_1_traj4, ate: 209.78207825123562
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[648/15000], training loss: 0.0724
[656/15000], training loss: 0.0762
[664/15000], training loss: 0.1001
[672/15000], training loss: 0.0959
[680/15000], training loss: 0.0882
16
AVD_Home_010_1_traj4, ate: 206.3211282443477
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[688/15000], training loss: 0.0932
[696/15000], training loss: 0.0873
[704/15000], training loss: 0.0926
[712/15000], training loss: 0.0922
[720/15000], training loss: 0.0778
16
AVD_Home_010_1_traj4, ate: 193.01363560333132
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[728/15000], training loss: 0.0845
[736/15000], training loss: 0.0856
[744/15000], training loss: 0.0924
[752/15000], training loss: 0.0928
[760/15000], training loss: 0.0753
16
AVD_Home_010_1_traj4, ate: 183.64532863271612
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[768/15000], training loss: 0.0936
[776/15000], training loss: 0.0878
[784/15000], training loss: 0.0894
[792/15000], training loss: 0.0866
[800/15000], training loss: 0.0853
16
AVD_Home_010_1_traj4, ate: 180.42358573953013
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[808/15000], training loss: 0.0734
[816/15000], training loss: 0.0866
[824/15000], training loss: 0.0786
[832/15000], training loss: 0.0710
[840/15000], training loss: 0.0723
16
AVD_Home_010_1_traj4, ate: 163.12953607372538
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[848/15000], training loss: 0.0821
[856/15000], training loss: 0.0849
[864/15000], training loss: 0.0928
[872/15000], training loss: 0.0983
[880/15000], training loss: 0.0893
16
AVD_Home_010_1_traj4, ate: 192.0256162841245
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[888/15000], training loss: 0.0914
[896/15000], training loss: 0.0807
[904/15000], training loss: 0.0703
[912/15000], training loss: 0.0772
[920/15000], training loss: 0.0805
16
AVD_Home_010_1_traj4, ate: 169.03080695118888
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[928/15000], training loss: 0.0693
[936/15000], training loss: 0.0847
[944/15000], training loss: 0.0805
[952/15000], training loss: 0.0766
[960/15000], training loss: 0.0642
16
AVD_Home_010_1_traj4, ate: 164.34014329419063
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[968/15000], training loss: 0.0872
[976/15000], training loss: 0.0728
[984/15000], training loss: 0.0791
[992/15000], training loss: 0.0831
[1000/15000], training loss: 0.0789
16
AVD_Home_010_1_traj4, ate: 159.85735873902328
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[1008/15000], training loss: 0.0904
[1016/15000], training loss: 0.0750
[1024/15000], training loss: 0.0732
[1032/15000], training loss: 0.0780
[1040/15000], training loss: 0.0795
16
AVD_Home_010_1_traj4, ate: 145.94109063389385
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[1048/15000], training loss: 0.0823
[1056/15000], training loss: 0.0794
[1064/15000], training loss: 0.0789
[1072/15000], training loss: 0.0774
[1080/15000], training loss: 0.0998
16
AVD_Home_010_1_traj4, ate: 143.0758082364308
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[1088/15000], training loss: 0.0851
[1096/15000], training loss: 0.0813
[1104/15000], training loss: 0.0865
[1112/15000], training loss: 0.0740
[1120/15000], training loss: 0.0777
16
AVD_Home_010_1_traj4, ate: 146.2346383292354
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[1128/15000], training loss: 0.1126
[1136/15000], training loss: 0.0822
[1144/15000], training loss: 0.0733
[1152/15000], training loss: 0.0887
[1160/15000], training loss: 0.0968
16
AVD_Home_010_1_traj4, ate: 141.53224477829784
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[1168/15000], training loss: 0.0794
[1176/15000], training loss: 0.0876
[1184/15000], training loss: 0.0819
[1192/15000], training loss: 0.0810
[1200/15000], training loss: 0.0754
16
AVD_Home_010_1_traj4, ate: 145.4796817523344
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[1208/15000], training loss: 0.0781
[1216/15000], training loss: 0.0719
[1224/15000], training loss: 0.0721
[1232/15000], training loss: 0.0737
[1240/15000], training loss: 0.0766
16
AVD_Home_010_1_traj4, ate: 145.91105991560576
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[1248/15000], training loss: 0.0873
[1256/15000], training loss: 0.0729
[1264/15000], training loss: 0.0708
[1272/15000], training loss: 0.0732
[1280/15000], training loss: 0.0714
16
AVD_Home_010_1_traj4, ate: 144.43628570100677
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[1288/15000], training loss: 0.0691
[1296/15000], training loss: 0.0896
[1304/15000], training loss: 0.0900
[1312/15000], training loss: 0.0900
[1320/15000], training loss: 0.0872
16
AVD_Home_010_1_traj4, ate: 144.63833005248168
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[1328/15000], training loss: 0.0685
[1336/15000], training loss: 0.0859
[1344/15000], training loss: 0.0733
[1352/15000], training loss: 0.1044
[1360/15000], training loss: 0.0702
16
AVD_Home_010_1_traj4, ate: 150.5105892066118
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[1368/15000], training loss: 0.0914
[1376/15000], training loss: 0.0825
[1384/15000], training loss: 0.0788
[1392/15000], training loss: 0.0765
[1400/15000], training loss: 0.0976
16
AVD_Home_010_1_traj4, ate: 129.55706867709236
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[1408/15000], training loss: 0.0737
[1416/15000], training loss: 0.0666
[1424/15000], training loss: 0.0851
[1432/15000], training loss: 0.0906
[1440/15000], training loss: 0.0867
16
AVD_Home_010_1_traj4, ate: 117.6716239785817
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[1448/15000], training loss: 0.0813
[1456/15000], training loss: 0.0681
[1464/15000], training loss: 0.0670
[1472/15000], training loss: 0.0855
[1480/15000], training loss: 0.0736
16
AVD_Home_010_1_traj4, ate: 134.44481852709677
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[1488/15000], training loss: 0.0756
[1496/15000], training loss: 0.0654
[1504/15000], training loss: 0.0795
[1512/15000], training loss: 0.0712
[1520/15000], training loss: 0.0705
16
AVD_Home_010_1_traj4, ate: 119.28230726861395
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[1528/15000], training loss: 0.0829
[1536/15000], training loss: 0.0819
[1544/15000], training loss: 0.0806
[1552/15000], training loss: 0.0729
[1560/15000], training loss: 0.0677
16
AVD_Home_010_1_traj4, ate: 125.32168716323814
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[1568/15000], training loss: 0.0829
[1576/15000], training loss: 0.1064
[1584/15000], training loss: 0.0789
[1592/15000], training loss: 0.0676
[1600/15000], training loss: 0.0905
16
AVD_Home_010_1_traj4, ate: 119.77541932597451
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[1608/15000], training loss: 0.0734
[1616/15000], training loss: 0.0652
[1624/15000], training loss: 0.0688
[1632/15000], training loss: 0.0844
[1640/15000], training loss: 0.0729
16
AVD_Home_010_1_traj4, ate: 132.90622256169743
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[1648/15000], training loss: 0.0780
[1656/15000], training loss: 0.0940
[1664/15000], training loss: 0.0828
[1672/15000], training loss: 0.0768
[1680/15000], training loss: 0.0653
16
AVD_Home_010_1_traj4, ate: 113.41225645566267
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[1688/15000], training loss: 0.0701
[1696/15000], training loss: 0.0644
[1704/15000], training loss: 0.0801
[1712/15000], training loss: 0.0755
[1720/15000], training loss: 0.1057
16
AVD_Home_010_1_traj4, ate: 109.95750155295093
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[1728/15000], training loss: 0.0693
[1736/15000], training loss: 0.0654
[1744/15000], training loss: 0.0726
[1752/15000], training loss: 0.0910
[1760/15000], training loss: 0.0653
16
AVD_Home_010_1_traj4, ate: 103.05071260279969
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[1768/15000], training loss: 0.0852
[1776/15000], training loss: 0.0701
[1784/15000], training loss: 0.0710
[1792/15000], training loss: 0.0691
[1800/15000], training loss: 0.0876
16
AVD_Home_010_1_traj4, ate: 109.0412631507691
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[1808/15000], training loss: 0.0906
[1816/15000], training loss: 0.0884
[1824/15000], training loss: 0.0826
[1832/15000], training loss: 0.0788
[1840/15000], training loss: 0.0916
16
AVD_Home_010_1_traj4, ate: 119.63676025007366
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[1848/15000], training loss: 0.1039
[1856/15000], training loss: 0.0771
[1864/15000], training loss: 0.0599
[1872/15000], training loss: 0.0780
[1880/15000], training loss: 0.0797
16
AVD_Home_010_1_traj4, ate: 122.3866908838169
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[1888/15000], training loss: 0.0850
[1896/15000], training loss: 0.0665
[1904/15000], training loss: 0.0605
[1912/15000], training loss: 0.0657
[1920/15000], training loss: 0.0736
16
AVD_Home_010_1_traj4, ate: 102.61740875307744
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[1928/15000], training loss: 0.0749
[1936/15000], training loss: 0.0906
[1944/15000], training loss: 0.0865
[1952/15000], training loss: 0.0723
[1960/15000], training loss: 0.0832
16
AVD_Home_010_1_traj4, ate: 105.25253040865694
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[1968/15000], training loss: 0.0842
[1976/15000], training loss: 0.0891
[1984/15000], training loss: 0.0807
[1992/15000], training loss: 0.0893
[2000/15000], training loss: 0.0701
16
AVD_Home_010_1_traj4, ate: 114.5968466695914
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[2008/15000], training loss: 0.0708
[2016/15000], training loss: 0.0974
[2024/15000], training loss: 0.0653
[2032/15000], training loss: 0.0713
[2040/15000], training loss: 0.1025
16
AVD_Home_010_1_traj4, ate: 100.55152068428183
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[2048/15000], training loss: 0.0723
[2056/15000], training loss: 0.0608
[2064/15000], training loss: 0.0753
[2072/15000], training loss: 0.0832
[2080/15000], training loss: 0.1035
16
AVD_Home_010_1_traj4, ate: 100.87772342512055
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[2088/15000], training loss: 0.0830
[2096/15000], training loss: 0.0834
[2104/15000], training loss: 0.0822
[2112/15000], training loss: 0.0615
[2120/15000], training loss: 0.0846
16
AVD_Home_010_1_traj4, ate: 111.28029721474078
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[2128/15000], training loss: 0.0852
[2136/15000], training loss: 0.0725
[2144/15000], training loss: 0.0760
[2152/15000], training loss: 0.0840
[2160/15000], training loss: 0.0771
16
AVD_Home_010_1_traj4, ate: 111.93386181653709
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[2168/15000], training loss: 0.0591
[2176/15000], training loss: 0.0689
[2184/15000], training loss: 0.0752
[2192/15000], training loss: 0.0680
[2200/15000], training loss: 0.0706
16
AVD_Home_010_1_traj4, ate: 97.35590844279187
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[2208/15000], training loss: 0.0507
[2216/15000], training loss: 0.0598
[2224/15000], training loss: 0.0523
[2232/15000], training loss: 0.0673
[2240/15000], training loss: 0.0677
16
AVD_Home_010_1_traj4, ate: 94.5170601184149
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[2248/15000], training loss: 0.0662
[2256/15000], training loss: 0.0772
[2264/15000], training loss: 0.0764
[2272/15000], training loss: 0.0576
[2280/15000], training loss: 0.0619
16
AVD_Home_010_1_traj4, ate: 95.89131908436751
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[2288/15000], training loss: 0.0699
[2296/15000], training loss: 0.0936
[2304/15000], training loss: 0.0856
[2312/15000], training loss: 0.0642
[2320/15000], training loss: 0.0668
16
AVD_Home_010_1_traj4, ate: 118.45027905075374
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[2328/15000], training loss: 0.0785
[2336/15000], training loss: 0.0687
[2344/15000], training loss: 0.0643
[2352/15000], training loss: 0.0695
[2360/15000], training loss: 0.0913
16
AVD_Home_010_1_traj4, ate: 97.9298206918369
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[2368/15000], training loss: 0.0531
[2376/15000], training loss: 0.0812
[2384/15000], training loss: 0.0745
[2392/15000], training loss: 0.0657
[2400/15000], training loss: 0.0638
16
AVD_Home_010_1_traj4, ate: 96.88652199778352
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[2408/15000], training loss: 0.0723
[2416/15000], training loss: 0.0674
[2424/15000], training loss: 0.0700
[2432/15000], training loss: 0.0739
[2440/15000], training loss: 0.0756
16
AVD_Home_010_1_traj4, ate: 97.49935427455482
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[2448/15000], training loss: 0.0735
[2456/15000], training loss: 0.0662
[2464/15000], training loss: 0.0847
[2472/15000], training loss: 0.0542
[2480/15000], training loss: 0.0721
16
AVD_Home_010_1_traj4, ate: 101.10789493773932
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[2488/15000], training loss: 0.0669
[2496/15000], training loss: 0.0717
[2504/15000], training loss: 0.0739
[2512/15000], training loss: 0.0694
[2520/15000], training loss: 0.0644
16
AVD_Home_010_1_traj4, ate: 91.71365106799702
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[2528/15000], training loss: 0.0711
[2536/15000], training loss: 0.0662
[2544/15000], training loss: 0.0527
[2552/15000], training loss: 0.0622
[2560/15000], training loss: 0.0580
16
AVD_Home_010_1_traj4, ate: 88.03630913279825
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[2568/15000], training loss: 0.0828
[2576/15000], training loss: 0.0543
[2584/15000], training loss: 0.0912
[2592/15000], training loss: 0.0787
[2600/15000], training loss: 0.0749
16
AVD_Home_010_1_traj4, ate: 94.29511380448892
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[2608/15000], training loss: 0.0836
[2616/15000], training loss: 0.0670
[2624/15000], training loss: 0.0724
[2632/15000], training loss: 0.0763
[2640/15000], training loss: 0.0798
16
AVD_Home_010_1_traj4, ate: 88.85568882615863
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[2648/15000], training loss: 0.0577
[2656/15000], training loss: 0.0840
[2664/15000], training loss: 0.0832
[2672/15000], training loss: 0.0730
[2680/15000], training loss: 0.0876
16
AVD_Home_010_1_traj4, ate: 96.82266990948295
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[2688/15000], training loss: 0.0809
[2696/15000], training loss: 0.0682
[2704/15000], training loss: 0.0570
[2712/15000], training loss: 0.0884
[2720/15000], training loss: 0.1034
16
AVD_Home_010_1_traj4, ate: 89.30543726362075
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[2728/15000], training loss: 0.0614
[2736/15000], training loss: 0.0676
[2744/15000], training loss: 0.0561
[2752/15000], training loss: 0.1048
[2760/15000], training loss: 0.0975
16
AVD_Home_010_1_traj4, ate: 86.13066832520606
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[2768/15000], training loss: 0.0605
[2776/15000], training loss: 0.0755
[2784/15000], training loss: 0.0853
[2792/15000], training loss: 0.0738
[2800/15000], training loss: 0.0563
16
AVD_Home_010_1_traj4, ate: 94.40619959734042
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[2808/15000], training loss: 0.0685
[2816/15000], training loss: 0.0495
[2824/15000], training loss: 0.0552
[2832/15000], training loss: 0.0671
[2840/15000], training loss: 0.0758
16
AVD_Home_010_1_traj4, ate: 82.78706825559352
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[2848/15000], training loss: 0.0549
[2856/15000], training loss: 0.0537
[2864/15000], training loss: 0.0781
[2872/15000], training loss: 0.0660
[2880/15000], training loss: 0.0647
16
AVD_Home_010_1_traj4, ate: 79.36643503038943
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[2888/15000], training loss: 0.0578
[2896/15000], training loss: 0.0911
[2904/15000], training loss: 0.0727
[2912/15000], training loss: 0.0541
[2920/15000], training loss: 0.1090
16
AVD_Home_010_1_traj4, ate: 92.88560047227158
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[2928/15000], training loss: 0.1017
[2936/15000], training loss: 0.0644
[2944/15000], training loss: 0.0733
[2952/15000], training loss: 0.0706
[2960/15000], training loss: 0.0713
16
AVD_Home_010_1_traj4, ate: 88.75798798713903
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[2968/15000], training loss: 0.0766
[2976/15000], training loss: 0.0926
[2984/15000], training loss: 0.0671
[2992/15000], training loss: 0.0662
[3000/15000], training loss: 0.0613
16
AVD_Home_010_1_traj4, ate: 93.47181194485991
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[3008/15000], training loss: 0.0559
[3016/15000], training loss: 0.0569
[3024/15000], training loss: 0.0543
[3032/15000], training loss: 0.0500
[3040/15000], training loss: 0.0722
16
AVD_Home_010_1_traj4, ate: 81.02778381350609
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[3048/15000], training loss: 0.0523
[3056/15000], training loss: 0.0552
[3064/15000], training loss: 0.0801
[3072/15000], training loss: 0.0735
[3080/15000], training loss: 0.0746
16
AVD_Home_010_1_traj4, ate: 78.53478886562
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[3088/15000], training loss: 0.0847
[3096/15000], training loss: 0.0637
[3104/15000], training loss: 0.0663
[3112/15000], training loss: 0.0674
[3120/15000], training loss: 0.0668
16
AVD_Home_010_1_traj4, ate: 80.81513662557924
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[3128/15000], training loss: 0.0543
[3136/15000], training loss: 0.0432
[3144/15000], training loss: 0.0630
[3152/15000], training loss: 0.0751
[3160/15000], training loss: 0.0675
16
AVD_Home_010_1_traj4, ate: 80.37755915059473
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[3168/15000], training loss: 0.0575
[3176/15000], training loss: 0.0449
[3184/15000], training loss: 0.0956
[3192/15000], training loss: 0.0725
[3200/15000], training loss: 0.0577
16
AVD_Home_010_1_traj4, ate: 83.04162162785283
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[3208/15000], training loss: 0.0495
[3216/15000], training loss: 0.1051
[3224/15000], training loss: 0.0858
[3232/15000], training loss: 0.0822
[3240/15000], training loss: 0.0648
16
AVD_Home_010_1_traj4, ate: 79.22399033470676
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[3248/15000], training loss: 0.0592
[3256/15000], training loss: 0.0542
[3264/15000], training loss: 0.0715
[3272/15000], training loss: 0.0695
[3280/15000], training loss: 0.0448
16
AVD_Home_010_1_traj4, ate: 84.29309524081064
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[3288/15000], training loss: 0.0549
[3296/15000], training loss: 0.0709
[3304/15000], training loss: 0.0570
[3312/15000], training loss: 0.0635
[3320/15000], training loss: 0.0583
16
AVD_Home_010_1_traj4, ate: 85.8378897191863
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[3328/15000], training loss: 0.0720
[3336/15000], training loss: 0.0582
[3344/15000], training loss: 0.0755
[3352/15000], training loss: 0.0727
[3360/15000], training loss: 0.0736
16
AVD_Home_010_1_traj4, ate: 79.78560217991078
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[3368/15000], training loss: 0.0744
[3376/15000], training loss: 0.0526
[3384/15000], training loss: 0.0636
[3392/15000], training loss: 0.0779
[3400/15000], training loss: 0.0606
16
AVD_Home_010_1_traj4, ate: 77.56227484259365
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[3408/15000], training loss: 0.0565
[3416/15000], training loss: 0.0710
[3424/15000], training loss: 0.0616
[3432/15000], training loss: 0.0719
[3440/15000], training loss: 0.0783
16
AVD_Home_010_1_traj4, ate: 74.35379968313839
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[3448/15000], training loss: 0.0775
[3456/15000], training loss: 0.0981
[3464/15000], training loss: 0.0690
[3472/15000], training loss: 0.0714
[3480/15000], training loss: 0.0543
16
AVD_Home_010_1_traj4, ate: 77.14219535619524
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[3488/15000], training loss: 0.0634
[3496/15000], training loss: 0.0842
[3504/15000], training loss: 0.0684
[3512/15000], training loss: 0.0479
[3520/15000], training loss: 0.0543
16
AVD_Home_010_1_traj4, ate: 80.60069789896205
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[3528/15000], training loss: 0.0552
[3536/15000], training loss: 0.0591
[3544/15000], training loss: 0.0807
[3552/15000], training loss: 0.0671
[3560/15000], training loss: 0.0816
16
AVD_Home_010_1_traj4, ate: 87.38297025001707
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[3568/15000], training loss: 0.0595
[3576/15000], training loss: 0.0633
[3584/15000], training loss: 0.0616
[3592/15000], training loss: 0.0604
[3600/15000], training loss: 0.0645
16
AVD_Home_010_1_traj4, ate: 76.39784665171658
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[3608/15000], training loss: 0.0646
[3616/15000], training loss: 0.0543
[3624/15000], training loss: 0.0671
[3632/15000], training loss: 0.0666
[3640/15000], training loss: 0.0736
16
AVD_Home_010_1_traj4, ate: 73.01818897627207
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[3648/15000], training loss: 0.0648
[3656/15000], training loss: 0.0710
[3664/15000], training loss: 0.0655
[3672/15000], training loss: 0.0755
[3680/15000], training loss: 0.0656
16
AVD_Home_010_1_traj4, ate: 74.19816056075008
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[3688/15000], training loss: 0.0495
[3696/15000], training loss: 0.0682
[3704/15000], training loss: 0.0748
[3712/15000], training loss: 0.0700
[3720/15000], training loss: 0.0581
16
AVD_Home_010_1_traj4, ate: 76.75479429050972
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[3728/15000], training loss: 0.0562
[3736/15000], training loss: 0.0589
[3744/15000], training loss: 0.0617
[3752/15000], training loss: 0.0512
[3760/15000], training loss: 0.0576
16
AVD_Home_010_1_traj4, ate: 75.4295839222793
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[3768/15000], training loss: 0.0539
[3776/15000], training loss: 0.0451
[3784/15000], training loss: 0.0631
[3792/15000], training loss: 0.0509
[3800/15000], training loss: 0.0587
16
AVD_Home_010_1_traj4, ate: 75.89830984029905
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[3808/15000], training loss: 0.0612
[3816/15000], training loss: 0.0628
[3824/15000], training loss: 0.0588
[3832/15000], training loss: 0.0480
[3840/15000], training loss: 0.0781
16
AVD_Home_010_1_traj4, ate: 73.04875920863108
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[3848/15000], training loss: 0.0652
[3856/15000], training loss: 0.0636
[3864/15000], training loss: 0.0539
[3872/15000], training loss: 0.0933
[3880/15000], training loss: 0.0872
16
AVD_Home_010_1_traj4, ate: 70.54303313429294
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[3888/15000], training loss: 0.0474
[3896/15000], training loss: 0.0558
[3904/15000], training loss: 0.0745
[3912/15000], training loss: 0.0527
[3920/15000], training loss: 0.0874
16
AVD_Home_010_1_traj4, ate: 78.8209763363634
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[3928/15000], training loss: 0.0767
[3936/15000], training loss: 0.0724
[3944/15000], training loss: 0.0897
[3952/15000], training loss: 0.0618
[3960/15000], training loss: 0.0494
16
AVD_Home_010_1_traj4, ate: 78.84102348717933
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[3968/15000], training loss: 0.0701
[3976/15000], training loss: 0.0875
[3984/15000], training loss: 0.0668
[3992/15000], training loss: 0.0555
[4000/15000], training loss: 0.0631
16
AVD_Home_010_1_traj4, ate: 79.44968790090763
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[4008/15000], training loss: 0.0506
[4016/15000], training loss: 0.0594
[4024/15000], training loss: 0.0647
[4032/15000], training loss: 0.0656
[4040/15000], training loss: 0.0623
16
AVD_Home_010_1_traj4, ate: 71.62289249938321
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[4048/15000], training loss: 0.0487
[4056/15000], training loss: 0.0664
[4064/15000], training loss: 0.0571
[4072/15000], training loss: 0.0750
[4080/15000], training loss: 0.0530
16
AVD_Home_010_1_traj4, ate: 74.75578454182674
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[4088/15000], training loss: 0.0651
[4096/15000], training loss: 0.0482
[4104/15000], training loss: 0.0709
[4112/15000], training loss: 0.0662
[4120/15000], training loss: 0.0847
16
AVD_Home_010_1_traj4, ate: 72.57022532449628
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[4128/15000], training loss: 0.0521
[4136/15000], training loss: 0.0553
[4144/15000], training loss: 0.0645
[4152/15000], training loss: 0.0760
[4160/15000], training loss: 0.0703
16
AVD_Home_010_1_traj4, ate: 73.0985404978062
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[4168/15000], training loss: 0.0588
[4176/15000], training loss: 0.0634
[4184/15000], training loss: 0.0621
[4192/15000], training loss: 0.0466
[4200/15000], training loss: 0.0619
16
AVD_Home_010_1_traj4, ate: 75.1577477743421
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[4208/15000], training loss: 0.0670
[4216/15000], training loss: 0.0534
[4224/15000], training loss: 0.0698
[4232/15000], training loss: 0.0720
[4240/15000], training loss: 0.0485
16
AVD_Home_010_1_traj4, ate: 72.64192333051754
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[4248/15000], training loss: 0.1303
[4256/15000], training loss: 0.0819
[4264/15000], training loss: 0.0869
[4272/15000], training loss: 0.0885
[4280/15000], training loss: 0.1115
16
AVD_Home_010_1_traj4, ate: 73.30318565806266
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[4288/15000], training loss: 0.0576
[4296/15000], training loss: 0.0697
[4304/15000], training loss: 0.0648
[4312/15000], training loss: 0.0761
[4320/15000], training loss: 0.0738
16
AVD_Home_010_1_traj4, ate: 77.86630798006725
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[4328/15000], training loss: 0.0525
[4336/15000], training loss: 0.0590
[4344/15000], training loss: 0.0565
[4352/15000], training loss: 0.0607
[4360/15000], training loss: 0.0530
16
AVD_Home_010_1_traj4, ate: 74.53534127541911
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[4368/15000], training loss: 0.0749
[4376/15000], training loss: 0.0616
[4384/15000], training loss: 0.0585
[4392/15000], training loss: 0.0566
[4400/15000], training loss: 0.0604
16
AVD_Home_010_1_traj4, ate: 78.10620879804486
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[4408/15000], training loss: 0.0667
[4416/15000], training loss: 0.0603
[4424/15000], training loss: 0.0547
[4432/15000], training loss: 0.0624
[4440/15000], training loss: 0.0727
16
AVD_Home_010_1_traj4, ate: 74.75457928196838
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[4448/15000], training loss: 0.0636
[4456/15000], training loss: 0.0630
[4464/15000], training loss: 0.1092
[4472/15000], training loss: 0.0726
[4480/15000], training loss: 0.0922
16
AVD_Home_010_1_traj4, ate: 72.79411099498233
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[4488/15000], training loss: 0.0725
[4496/15000], training loss: 0.1199
[4504/15000], training loss: 0.0889
[4512/15000], training loss: 0.0668
[4520/15000], training loss: 0.0555
16
AVD_Home_010_1_traj4, ate: 70.68051890116074
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[4528/15000], training loss: 0.0495
[4536/15000], training loss: 0.0478
[4544/15000], training loss: 0.0629
[4552/15000], training loss: 0.0479
[4560/15000], training loss: 0.0704
16
AVD_Home_010_1_traj4, ate: 77.04186192615481
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[4568/15000], training loss: 0.0639
[4576/15000], training loss: 0.0779
[4584/15000], training loss: 0.0765
[4592/15000], training loss: 0.0494
[4600/15000], training loss: 0.0588
16
AVD_Home_010_1_traj4, ate: 79.0029453017965
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[4608/15000], training loss: 0.0584
[4616/15000], training loss: 0.0470
[4624/15000], training loss: 0.0541
[4632/15000], training loss: 0.0575
[4640/15000], training loss: 0.0708
16
AVD_Home_010_1_traj4, ate: 76.43094991591542
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[4648/15000], training loss: 0.0747
[4656/15000], training loss: 0.0664
[4664/15000], training loss: 0.0774
[4672/15000], training loss: 0.0586
[4680/15000], training loss: 0.0652
16
AVD_Home_010_1_traj4, ate: 75.11763442147591
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[4688/15000], training loss: 0.0839
[4696/15000], training loss: 0.0730
[4704/15000], training loss: 0.0604
[4712/15000], training loss: 0.0432
[4720/15000], training loss: 0.0423
16
AVD_Home_010_1_traj4, ate: 78.97949634054915
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[4728/15000], training loss: 0.0719
[4736/15000], training loss: 0.0900
[4744/15000], training loss: 0.0579
[4752/15000], training loss: 0.0568
[4760/15000], training loss: 0.0730
16
AVD_Home_010_1_traj4, ate: 73.51789331961548
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[4768/15000], training loss: 0.0569
[4776/15000], training loss: 0.0436
[4784/15000], training loss: 0.0889
[4792/15000], training loss: 0.0658
[4800/15000], training loss: 0.0580
16
AVD_Home_010_1_traj4, ate: 72.22891766217198
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[4808/15000], training loss: 0.0560
[4816/15000], training loss: 0.0659
[4824/15000], training loss: 0.0957
[4832/15000], training loss: 0.0540
[4840/15000], training loss: 0.0716
16
AVD_Home_010_1_traj4, ate: 73.21286800157884
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[4848/15000], training loss: 0.0748
[4856/15000], training loss: 0.0562
[4864/15000], training loss: 0.0449
[4872/15000], training loss: 0.0639
[4880/15000], training loss: 0.0502
16
AVD_Home_010_1_traj4, ate: 75.41290468008512
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[4888/15000], training loss: 0.0723
[4896/15000], training loss: 0.0502
[4904/15000], training loss: 0.0533
[4912/15000], training loss: 0.0545
[4920/15000], training loss: 0.0525
16
AVD_Home_010_1_traj4, ate: 73.08657861570484
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[4928/15000], training loss: 0.0975
[4936/15000], training loss: 0.0534
[4944/15000], training loss: 0.0828
[4952/15000], training loss: 0.0508
[4960/15000], training loss: 0.0524
16
AVD_Home_010_1_traj4, ate: 71.35514174754934
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[4968/15000], training loss: 0.0657
[4976/15000], training loss: 0.0862
[4984/15000], training loss: 0.0624
[4992/15000], training loss: 0.0436
[5000/15000], training loss: 0.0927
16
AVD_Home_010_1_traj4, ate: 72.35585638253244
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[5008/15000], training loss: 0.0770
[5016/15000], training loss: 0.0745
[5024/15000], training loss: 0.0711
[5032/15000], training loss: 0.0474
[5040/15000], training loss: 0.0550
16
AVD_Home_010_1_traj4, ate: 72.45733776640049
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[5048/15000], training loss: 0.0668
[5056/15000], training loss: 0.0779
[5064/15000], training loss: 0.0505
[5072/15000], training loss: 0.0550
[5080/15000], training loss: 0.0575
16
AVD_Home_010_1_traj4, ate: 67.40430662761318
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[5088/15000], training loss: 0.0566
[5096/15000], training loss: 0.0550
[5104/15000], training loss: 0.0485
[5112/15000], training loss: 0.0789
[5120/15000], training loss: 0.0852
16
AVD_Home_010_1_traj4, ate: 75.37764757319734
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[5128/15000], training loss: 0.0652
[5136/15000], training loss: 0.0885
[5144/15000], training loss: 0.0551
[5152/15000], training loss: 0.0522
[5160/15000], training loss: 0.0607
16
AVD_Home_010_1_traj4, ate: 70.46220087895672
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[5168/15000], training loss: 0.0555
[5176/15000], training loss: 0.0596
[5184/15000], training loss: 0.0710
[5192/15000], training loss: 0.0813
[5200/15000], training loss: 0.0811
16
AVD_Home_010_1_traj4, ate: 65.7810111056247
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[5208/15000], training loss: 0.0852
[5216/15000], training loss: 0.0552
[5224/15000], training loss: 0.0897
[5232/15000], training loss: 0.0448
[5240/15000], training loss: 0.0695
16
AVD_Home_010_1_traj4, ate: 77.06135189732147
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[5248/15000], training loss: 0.0599
[5256/15000], training loss: 0.0560
[5264/15000], training loss: 0.0569
[5272/15000], training loss: 0.0710
[5280/15000], training loss: 0.0707
16
AVD_Home_010_1_traj4, ate: 72.86533030275265
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[5288/15000], training loss: 0.0644
[5296/15000], training loss: 0.0641
[5304/15000], training loss: 0.1056
[5312/15000], training loss: 0.0456
[5320/15000], training loss: 0.0794
16
AVD_Home_010_1_traj4, ate: 74.48311946658954
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[5328/15000], training loss: 0.0930
[5336/15000], training loss: 0.0696
[5344/15000], training loss: 0.0511
[5352/15000], training loss: 0.0758
[5360/15000], training loss: 0.0655
16
AVD_Home_010_1_traj4, ate: 74.15557055052685
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[5368/15000], training loss: 0.0748
[5376/15000], training loss: 0.0542
[5384/15000], training loss: 0.0776
[5392/15000], training loss: 0.0451
[5400/15000], training loss: 0.0627
16
AVD_Home_010_1_traj4, ate: 70.21987962218502
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[5408/15000], training loss: 0.0804
[5416/15000], training loss: 0.0584
[5424/15000], training loss: 0.0659
[5432/15000], training loss: 0.0421
[5440/15000], training loss: 0.0556
16
AVD_Home_010_1_traj4, ate: 75.38658883022993
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[5448/15000], training loss: 0.0813
[5456/15000], training loss: 0.0686
[5464/15000], training loss: 0.0664
[5472/15000], training loss: 0.0636
[5480/15000], training loss: 0.0765
16
AVD_Home_010_1_traj4, ate: 76.48281261907668
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[5488/15000], training loss: 0.0668
[5496/15000], training loss: 0.0518
[5504/15000], training loss: 0.0728
[5512/15000], training loss: 0.0491
[5520/15000], training loss: 0.0626
16
AVD_Home_010_1_traj4, ate: 71.46827766433417
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[5528/15000], training loss: 0.0716
[5536/15000], training loss: 0.0715
[5544/15000], training loss: 0.0430
[5552/15000], training loss: 0.0575
[5560/15000], training loss: 0.0657
16
AVD_Home_010_1_traj4, ate: 71.91907197614773
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[5568/15000], training loss: 0.0539
[5576/15000], training loss: 0.0612
[5584/15000], training loss: 0.0829
[5592/15000], training loss: 0.0803
[5600/15000], training loss: 0.0572
16
AVD_Home_010_1_traj4, ate: 72.85838179334945
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[5608/15000], training loss: 0.0504
[5616/15000], training loss: 0.0419
[5624/15000], training loss: 0.0723
[5632/15000], training loss: 0.0657
[5640/15000], training loss: 0.0531
16
AVD_Home_010_1_traj4, ate: 66.59211820097637
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[5648/15000], training loss: 0.0457
[5656/15000], training loss: 0.0672
[5664/15000], training loss: 0.0824
[5672/15000], training loss: 0.0589
[5680/15000], training loss: 0.0471
16
AVD_Home_010_1_traj4, ate: 76.16229629342345
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[5688/15000], training loss: 0.0642
[5696/15000], training loss: 0.0814
[5704/15000], training loss: 0.0526
[5712/15000], training loss: 0.0683
[5720/15000], training loss: 0.0597
16
AVD_Home_010_1_traj4, ate: 73.20461337773055
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[5728/15000], training loss: 0.0553
[5736/15000], training loss: 0.0544
[5744/15000], training loss: 0.0633
[5752/15000], training loss: 0.0694
[5760/15000], training loss: 0.0476
16
AVD_Home_010_1_traj4, ate: 71.2459019813552
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[5768/15000], training loss: 0.0766
[5776/15000], training loss: 0.0614
[5784/15000], training loss: 0.0574
[5792/15000], training loss: 0.0495
[5800/15000], training loss: 0.0678
16
AVD_Home_010_1_traj4, ate: 67.63710518082644
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[5808/15000], training loss: 0.0564
[5816/15000], training loss: 0.0757
[5824/15000], training loss: 0.0408
[5832/15000], training loss: 0.0502
[5840/15000], training loss: 0.0482
16
AVD_Home_010_1_traj4, ate: 68.94165868124311
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[5848/15000], training loss: 0.0574
[5856/15000], training loss: 0.0553
[5864/15000], training loss: 0.1052
[5872/15000], training loss: 0.0640
[5880/15000], training loss: 0.0492
16
AVD_Home_010_1_traj4, ate: 73.55250138732086
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[5888/15000], training loss: 0.0451
[5896/15000], training loss: 0.0545
[5904/15000], training loss: 0.0496
[5912/15000], training loss: 0.0454
[5920/15000], training loss: 0.0569
16
AVD_Home_010_1_traj4, ate: 70.25756417862225
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[5928/15000], training loss: 0.0706
[5936/15000], training loss: 0.0852
[5944/15000], training loss: 0.0638
[5952/15000], training loss: 0.0691
[5960/15000], training loss: 0.0747
16
AVD_Home_010_1_traj4, ate: 68.91922623395514
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[5968/15000], training loss: 0.0581
[5976/15000], training loss: 0.0728
[5984/15000], training loss: 0.0568
[5992/15000], training loss: 0.0465
[6000/15000], training loss: 0.0529
16
AVD_Home_010_1_traj4, ate: 69.95059073416158
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[6008/15000], training loss: 0.0497
[6016/15000], training loss: 0.0635
[6024/15000], training loss: 0.0627
[6032/15000], training loss: 0.0601
[6040/15000], training loss: 0.0552
16
AVD_Home_010_1_traj4, ate: 69.4217315538336
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[6048/15000], training loss: 0.0840
[6056/15000], training loss: 0.0453
[6064/15000], training loss: 0.0616
[6072/15000], training loss: 0.0631
[6080/15000], training loss: 0.0608
16
AVD_Home_010_1_traj4, ate: 70.42063962110967
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[6088/15000], training loss: 0.0487
[6096/15000], training loss: 0.0431
[6104/15000], training loss: 0.0614
[6112/15000], training loss: 0.0625
[6120/15000], training loss: 0.0795
16
AVD_Home_010_1_traj4, ate: 66.89611087013809
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[6128/15000], training loss: 0.1045
[6136/15000], training loss: 0.0612
[6144/15000], training loss: 0.0782
[6152/15000], training loss: 0.0440
[6160/15000], training loss: 0.0672
16
AVD_Home_010_1_traj4, ate: 68.1216033278617
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[6168/15000], training loss: 0.0465
[6176/15000], training loss: 0.0509
[6184/15000], training loss: 0.0613
[6192/15000], training loss: 0.0495
[6200/15000], training loss: 0.0490
16
AVD_Home_010_1_traj4, ate: 68.41066163078173
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[6208/15000], training loss: 0.0681
[6216/15000], training loss: 0.0426
[6224/15000], training loss: 0.0434
[6232/15000], training loss: 0.0577
[6240/15000], training loss: 0.0507
16
AVD_Home_010_1_traj4, ate: 68.36711492798268
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[6248/15000], training loss: 0.0606
[6256/15000], training loss: 0.0626
[6264/15000], training loss: 0.0406
[6272/15000], training loss: 0.0417
[6280/15000], training loss: 0.0708
16
AVD_Home_010_1_traj4, ate: 66.31021277050174
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[6288/15000], training loss: 0.0894
[6296/15000], training loss: 0.0554
[6304/15000], training loss: 0.0394
[6312/15000], training loss: 0.0653
[6320/15000], training loss: 0.0546
16
AVD_Home_010_1_traj4, ate: 66.97962713965995
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[6328/15000], training loss: 0.0422
[6336/15000], training loss: 0.0592
[6344/15000], training loss: 0.0597
[6352/15000], training loss: 0.0641
[6360/15000], training loss: 0.0418
16
AVD_Home_010_1_traj4, ate: 67.04059329762343
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[6368/15000], training loss: 0.0494
[6376/15000], training loss: 0.0461
[6384/15000], training loss: 0.0493
[6392/15000], training loss: 0.0633
[6400/15000], training loss: 0.0437
16
AVD_Home_010_1_traj4, ate: 68.15354290053261
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[6408/15000], training loss: 0.0548
[6416/15000], training loss: 0.0614
[6424/15000], training loss: 0.0497
[6432/15000], training loss: 0.0565
[6440/15000], training loss: 0.0570
16
AVD_Home_010_1_traj4, ate: 66.5403378634549
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[6448/15000], training loss: 0.0383
[6456/15000], training loss: 0.0485
[6464/15000], training loss: 0.0770
[6472/15000], training loss: 0.0678
[6480/15000], training loss: 0.0686
16
AVD_Home_010_1_traj4, ate: 71.06812279173029
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[6488/15000], training loss: 0.0542
[6496/15000], training loss: 0.0473
[6504/15000], training loss: 0.0589
[6512/15000], training loss: 0.0755
[6520/15000], training loss: 0.0629
16
AVD_Home_010_1_traj4, ate: 62.64991145450463
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[6528/15000], training loss: 0.0635
[6536/15000], training loss: 0.0448
[6544/15000], training loss: 0.0922
[6552/15000], training loss: 0.0378
[6560/15000], training loss: 0.0498
16
AVD_Home_010_1_traj4, ate: 69.5403111041401
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[6568/15000], training loss: 0.0873
[6576/15000], training loss: 0.0600
[6584/15000], training loss: 0.0533
[6592/15000], training loss: 0.0670
[6600/15000], training loss: 0.0635
16
AVD_Home_010_1_traj4, ate: 65.82441335384395
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[6608/15000], training loss: 0.0475
[6616/15000], training loss: 0.0605
[6624/15000], training loss: 0.0424
[6632/15000], training loss: 0.0636
[6640/15000], training loss: 0.0375
16
AVD_Home_010_1_traj4, ate: 68.53135601459118
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[6648/15000], training loss: 0.0846
[6656/15000], training loss: 0.0583
[6664/15000], training loss: 0.0400
[6672/15000], training loss: 0.0474
[6680/15000], training loss: 0.0516
16
AVD_Home_010_1_traj4, ate: 69.77787149881449
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[6688/15000], training loss: 0.0605
[6696/15000], training loss: 0.0404
[6704/15000], training loss: 0.0589
[6712/15000], training loss: 0.0624
[6720/15000], training loss: 0.0682
16
AVD_Home_010_1_traj4, ate: 69.0181607169727
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[6728/15000], training loss: 0.0653
[6736/15000], training loss: 0.0690
[6744/15000], training loss: 0.0605
[6752/15000], training loss: 0.0449
[6760/15000], training loss: 0.0418
16
AVD_Home_010_1_traj4, ate: 70.12787670602751
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[6768/15000], training loss: 0.0641
[6776/15000], training loss: 0.0909
[6784/15000], training loss: 0.0556
[6792/15000], training loss: 0.0472
[6800/15000], training loss: 0.0690
16
AVD_Home_010_1_traj4, ate: 69.70501384288843
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[6808/15000], training loss: 0.0603
[6816/15000], training loss: 0.0417
[6824/15000], training loss: 0.0451
[6832/15000], training loss: 0.0565
[6840/15000], training loss: 0.0463
16
AVD_Home_010_1_traj4, ate: 67.41074675838236
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[6848/15000], training loss: 0.0528
[6856/15000], training loss: 0.0581
[6864/15000], training loss: 0.0733
[6872/15000], training loss: 0.0493
[6880/15000], training loss: 0.0589
16
AVD_Home_010_1_traj4, ate: 67.00820401623605
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[6888/15000], training loss: 0.0568
[6896/15000], training loss: 0.0522
[6904/15000], training loss: 0.0529
[6912/15000], training loss: 0.0547
[6920/15000], training loss: 0.0749
16
AVD_Home_010_1_traj4, ate: 66.47837201494296
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[6928/15000], training loss: 0.0634
[6936/15000], training loss: 0.0462
[6944/15000], training loss: 0.0377
[6952/15000], training loss: 0.0475
[6960/15000], training loss: 0.0553
16
AVD_Home_010_1_traj4, ate: 66.29373879549856
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[6968/15000], training loss: 0.0524
[6976/15000], training loss: 0.0538
[6984/15000], training loss: 0.0515
[6992/15000], training loss: 0.0566
[7000/15000], training loss: 0.0894
16
AVD_Home_010_1_traj4, ate: 67.41214052654799
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[7008/15000], training loss: 0.0500
[7016/15000], training loss: 0.0438
[7024/15000], training loss: 0.0572
[7032/15000], training loss: 0.0405
[7040/15000], training loss: 0.0473
16
AVD_Home_010_1_traj4, ate: 66.04987372330706
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[7048/15000], training loss: 0.0570
[7056/15000], training loss: 0.0592
[7064/15000], training loss: 0.0679
[7072/15000], training loss: 0.0480
[7080/15000], training loss: 0.0465
16
AVD_Home_010_1_traj4, ate: 69.262452221638
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[7088/15000], training loss: 0.0753
[7096/15000], training loss: 0.0700
[7104/15000], training loss: 0.0847
[7112/15000], training loss: 0.0614
[7120/15000], training loss: 0.0444
16
AVD_Home_010_1_traj4, ate: 70.04152743418884
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[7128/15000], training loss: 0.0537
[7136/15000], training loss: 0.0865
[7144/15000], training loss: 0.0709
[7152/15000], training loss: 0.0440
[7160/15000], training loss: 0.0490
16
AVD_Home_010_1_traj4, ate: 67.92167802775
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[7168/15000], training loss: 0.0547
[7176/15000], training loss: 0.0638
[7184/15000], training loss: 0.0574
[7192/15000], training loss: 0.0655
[7200/15000], training loss: 0.0384
16
AVD_Home_010_1_traj4, ate: 67.95093520063119
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[7208/15000], training loss: 0.0505
[7216/15000], training loss: 0.0469
[7224/15000], training loss: 0.0653
[7232/15000], training loss: 0.0567
[7240/15000], training loss: 0.0506
16
AVD_Home_010_1_traj4, ate: 66.89178413979906
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[7248/15000], training loss: 0.0548
[7256/15000], training loss: 0.0467
[7264/15000], training loss: 0.0433
[7272/15000], training loss: 0.0602
[7280/15000], training loss: 0.0780
16
AVD_Home_010_1_traj4, ate: 70.35795669270215
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[7288/15000], training loss: 0.0738
[7296/15000], training loss: 0.0420
[7304/15000], training loss: 0.0626
[7312/15000], training loss: 0.0681
[7320/15000], training loss: 0.0754
16
AVD_Home_010_1_traj4, ate: 65.75426237621359
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[7328/15000], training loss: 0.0636
[7336/15000], training loss: 0.0604
[7344/15000], training loss: 0.0528
[7352/15000], training loss: 0.0543
[7360/15000], training loss: 0.0546
16
AVD_Home_010_1_traj4, ate: 69.41939003393563
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[7368/15000], training loss: 0.0648
[7376/15000], training loss: 0.0613
[7384/15000], training loss: 0.0548
[7392/15000], training loss: 0.0465
[7400/15000], training loss: 0.0475
16
AVD_Home_010_1_traj4, ate: 69.70362544751035
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[7408/15000], training loss: 0.0398
[7416/15000], training loss: 0.0388
[7424/15000], training loss: 0.0563
[7432/15000], training loss: 0.0673
[7440/15000], training loss: 0.0720
16
AVD_Home_010_1_traj4, ate: 67.36930855265425
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[7448/15000], training loss: 0.0832
[7456/15000], training loss: 0.0516
[7464/15000], training loss: 0.0550
[7472/15000], training loss: 0.0609
[7480/15000], training loss: 0.0439
16
AVD_Home_010_1_traj4, ate: 67.5870040440088
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[7488/15000], training loss: 0.0630
[7496/15000], training loss: 0.0468
[7504/15000], training loss: 0.0619
[7512/15000], training loss: 0.0428
[7520/15000], training loss: 0.0573
16
AVD_Home_010_1_traj4, ate: 66.7129708164946
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[7528/15000], training loss: 0.0676
[7536/15000], training loss: 0.0557
[7544/15000], training loss: 0.0744
[7552/15000], training loss: 0.0612
[7560/15000], training loss: 0.0515
16
AVD_Home_010_1_traj4, ate: 65.68266194427838
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[7568/15000], training loss: 0.0628
[7576/15000], training loss: 0.0635
[7584/15000], training loss: 0.0604
[7592/15000], training loss: 0.0468
[7600/15000], training loss: 0.0504
16
AVD_Home_010_1_traj4, ate: 66.26581733974007
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[7608/15000], training loss: 0.0522
[7616/15000], training loss: 0.0505
[7624/15000], training loss: 0.0530
[7632/15000], training loss: 0.0678
[7640/15000], training loss: 0.0827
16
AVD_Home_010_1_traj4, ate: 65.8039697374672
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[7648/15000], training loss: 0.0523
[7656/15000], training loss: 0.0511
[7664/15000], training loss: 0.0577
[7672/15000], training loss: 0.0649
[7680/15000], training loss: 0.0444
16
AVD_Home_010_1_traj4, ate: 65.98863244609106
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[7688/15000], training loss: 0.0918
[7696/15000], training loss: 0.0619
[7704/15000], training loss: 0.0691
[7712/15000], training loss: 0.0547
[7720/15000], training loss: 0.0497
16
AVD_Home_010_1_traj4, ate: 66.54512471405023
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[7728/15000], training loss: 0.0609
[7736/15000], training loss: 0.0407
[7744/15000], training loss: 0.0385
[7752/15000], training loss: 0.0450
[7760/15000], training loss: 0.0560
16
AVD_Home_010_1_traj4, ate: 63.56084597555572
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[7768/15000], training loss: 0.1014
[7776/15000], training loss: 0.0536
[7784/15000], training loss: 0.0415
[7792/15000], training loss: 0.0817
[7800/15000], training loss: 0.0440
16
AVD_Home_010_1_traj4, ate: 67.47993815679877
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[7808/15000], training loss: 0.0522
[7816/15000], training loss: 0.0634
[7824/15000], training loss: 0.0482
[7832/15000], training loss: 0.0398
[7840/15000], training loss: 0.0605
16
AVD_Home_010_1_traj4, ate: 67.28149125528986
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[7848/15000], training loss: 0.0405
[7856/15000], training loss: 0.0666
[7864/15000], training loss: 0.0883
[7872/15000], training loss: 0.0618
[7880/15000], training loss: 0.0442
16
AVD_Home_010_1_traj4, ate: 66.33567320035529
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[7888/15000], training loss: 0.0675
[7896/15000], training loss: 0.0731
[7904/15000], training loss: 0.0637
[7912/15000], training loss: 0.0409
[7920/15000], training loss: 0.0940
16
AVD_Home_010_1_traj4, ate: 67.81218530824785
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[7928/15000], training loss: 0.0459
[7936/15000], training loss: 0.0721
[7944/15000], training loss: 0.0575
[7952/15000], training loss: 0.0594
[7960/15000], training loss: 0.0579
16
AVD_Home_010_1_traj4, ate: 66.13951887751816
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[7968/15000], training loss: 0.1003
[7976/15000], training loss: 0.0443
[7984/15000], training loss: 0.0417
[7992/15000], training loss: 0.0713
[8000/15000], training loss: 0.0418
16
AVD_Home_010_1_traj4, ate: 68.17134686794667
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[8008/15000], training loss: 0.0619
[8016/15000], training loss: 0.0541
[8024/15000], training loss: 0.0433
[8032/15000], training loss: 0.0612
[8040/15000], training loss: 0.0421
16
AVD_Home_010_1_traj4, ate: 66.2228136351739
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[8048/15000], training loss: 0.0568
[8056/15000], training loss: 0.0509
[8064/15000], training loss: 0.0629
[8072/15000], training loss: 0.0450
[8080/15000], training loss: 0.0528
16
AVD_Home_010_1_traj4, ate: 66.54597096862325
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[8088/15000], training loss: 0.0594
[8096/15000], training loss: 0.0449
[8104/15000], training loss: 0.0821
[8112/15000], training loss: 0.0493
[8120/15000], training loss: 0.0971
16
AVD_Home_010_1_traj4, ate: 65.20773002455414
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[8128/15000], training loss: 0.0709
[8136/15000], training loss: 0.0645
[8144/15000], training loss: 0.0568
[8152/15000], training loss: 0.0546
[8160/15000], training loss: 0.0612
16
AVD_Home_010_1_traj4, ate: 67.44060973498243
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[8168/15000], training loss: 0.1063
[8176/15000], training loss: 0.0526
[8184/15000], training loss: 0.0729
[8192/15000], training loss: 0.0964
[8200/15000], training loss: 0.0488
16
AVD_Home_010_1_traj4, ate: 71.17193115463706
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[8208/15000], training loss: 0.0581
[8216/15000], training loss: 0.0442
[8224/15000], training loss: 0.0477
[8232/15000], training loss: 0.0555
[8240/15000], training loss: 0.0741
16
AVD_Home_010_1_traj4, ate: 65.7572330520676
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[8248/15000], training loss: 0.0471
[8256/15000], training loss: 0.0495
[8264/15000], training loss: 0.0476
[8272/15000], training loss: 0.0539
[8280/15000], training loss: 0.0635
16
AVD_Home_010_1_traj4, ate: 64.8905774123956
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[8288/15000], training loss: 0.0491
[8296/15000], training loss: 0.0613
[8304/15000], training loss: 0.0372
[8312/15000], training loss: 0.0732
[8320/15000], training loss: 0.0685
16
AVD_Home_010_1_traj4, ate: 67.82084793716979
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[8328/15000], training loss: 0.0825
[8336/15000], training loss: 0.0592
[8344/15000], training loss: 0.0754
[8352/15000], training loss: 0.0441
[8360/15000], training loss: 0.0477
16
AVD_Home_010_1_traj4, ate: 66.36021636318964
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[8368/15000], training loss: 0.0563
[8376/15000], training loss: 0.0470
[8384/15000], training loss: 0.0837
[8392/15000], training loss: 0.0580
[8400/15000], training loss: 0.0418
16
AVD_Home_010_1_traj4, ate: 70.81658194004294
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[8408/15000], training loss: 0.0650
[8416/15000], training loss: 0.0593
[8424/15000], training loss: 0.0589
[8432/15000], training loss: 0.0564
[8440/15000], training loss: 0.0477
16
AVD_Home_010_1_traj4, ate: 66.63486105647918
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[8448/15000], training loss: 0.0621
[8456/15000], training loss: 0.0402
[8464/15000], training loss: 0.0412
[8472/15000], training loss: 0.0544
[8480/15000], training loss: 0.0538
16
AVD_Home_010_1_traj4, ate: 64.01367696747802
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[8488/15000], training loss: 0.0675
[8496/15000], training loss: 0.0398
[8504/15000], training loss: 0.0651
[8512/15000], training loss: 0.0381
[8520/15000], training loss: 0.0695
16
AVD_Home_010_1_traj4, ate: 65.48484060220332
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[8528/15000], training loss: 0.0499
[8536/15000], training loss: 0.0425
[8544/15000], training loss: 0.0417
[8552/15000], training loss: 0.0582
[8560/15000], training loss: 0.0658
16
AVD_Home_010_1_traj4, ate: 68.28948998695458
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[8568/15000], training loss: 0.0420
[8576/15000], training loss: 0.0871
[8584/15000], training loss: 0.0458
[8592/15000], training loss: 0.0560
[8600/15000], training loss: 0.0519
16
AVD_Home_010_1_traj4, ate: 64.72343639909771
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[8608/15000], training loss: 0.0444
[8616/15000], training loss: 0.0459
[8624/15000], training loss: 0.0393
[8632/15000], training loss: 0.0473
[8640/15000], training loss: 0.0494
16
AVD_Home_010_1_traj4, ate: 65.31432541070558
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[8648/15000], training loss: 0.0475
[8656/15000], training loss: 0.0471
[8664/15000], training loss: 0.0656
[8672/15000], training loss: 0.0420
[8680/15000], training loss: 0.0667
16
AVD_Home_010_1_traj4, ate: 65.37010569309412
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[8688/15000], training loss: 0.0607
[8696/15000], training loss: 0.0470
[8704/15000], training loss: 0.0491
[8712/15000], training loss: 0.0646
[8720/15000], training loss: 0.0520
16
AVD_Home_010_1_traj4, ate: 69.28379643924642
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[8728/15000], training loss: 0.0430
[8736/15000], training loss: 0.0526
[8744/15000], training loss: 0.0520
[8752/15000], training loss: 0.0523
[8760/15000], training loss: 0.0648
16
AVD_Home_010_1_traj4, ate: 65.433339698727
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[8768/15000], training loss: 0.0672
[8776/15000], training loss: 0.0401
[8784/15000], training loss: 0.0435
[8792/15000], training loss: 0.0427
[8800/15000], training loss: 0.0647
16
AVD_Home_010_1_traj4, ate: 66.78190766609563
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[8808/15000], training loss: 0.0674
[8816/15000], training loss: 0.0471
[8824/15000], training loss: 0.0624
[8832/15000], training loss: 0.0446
[8840/15000], training loss: 0.0630
16
AVD_Home_010_1_traj4, ate: 67.09741483403099
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[8848/15000], training loss: 0.0601
[8856/15000], training loss: 0.0409
[8864/15000], training loss: 0.0469
[8872/15000], training loss: 0.0401
[8880/15000], training loss: 0.0501
16
AVD_Home_010_1_traj4, ate: 67.47595155300289
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[8888/15000], training loss: 0.0662
[8896/15000], training loss: 0.0786
[8904/15000], training loss: 0.0889
[8912/15000], training loss: 0.0781
[8920/15000], training loss: 0.0652
16
AVD_Home_010_1_traj4, ate: 62.60191276606766
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[8928/15000], training loss: 0.0597
[8936/15000], training loss: 0.0385
[8944/15000], training loss: 0.0493
[8952/15000], training loss: 0.0655
[8960/15000], training loss: 0.0437
16
AVD_Home_010_1_traj4, ate: 68.14219706921212
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[8968/15000], training loss: 0.0530
[8976/15000], training loss: 0.0554
[8984/15000], training loss: 0.0444
[8992/15000], training loss: 0.0473
[9000/15000], training loss: 0.0604
16
AVD_Home_010_1_traj4, ate: 64.64321569812694
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[9008/15000], training loss: 0.0449
[9016/15000], training loss: 0.0474
[9024/15000], training loss: 0.0449
[9032/15000], training loss: 0.0513
[9040/15000], training loss: 0.0492
16
AVD_Home_010_1_traj4, ate: 64.43541107647117
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[9048/15000], training loss: 0.0756
[9056/15000], training loss: 0.0682
[9064/15000], training loss: 0.0490
[9072/15000], training loss: 0.0478
[9080/15000], training loss: 0.0505
16
AVD_Home_010_1_traj4, ate: 64.84601227929443
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[9088/15000], training loss: 0.0425
[9096/15000], training loss: 0.0420
[9104/15000], training loss: 0.0490
[9112/15000], training loss: 0.0541
[9120/15000], training loss: 0.0630
16
AVD_Home_010_1_traj4, ate: 64.61661678461003
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[9128/15000], training loss: 0.0558
[9136/15000], training loss: 0.0592
[9144/15000], training loss: 0.0424
[9152/15000], training loss: 0.0721
[9160/15000], training loss: 0.0414
16
AVD_Home_010_1_traj4, ate: 64.50241279852077
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[9168/15000], training loss: 0.0409
[9176/15000], training loss: 0.0623
[9184/15000], training loss: 0.0492
[9192/15000], training loss: 0.0453
[9200/15000], training loss: 0.0414
16
AVD_Home_010_1_traj4, ate: 64.90371678586229
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[9208/15000], training loss: 0.0567
[9216/15000], training loss: 0.0490
[9224/15000], training loss: 0.0473
[9232/15000], training loss: 0.0587
[9240/15000], training loss: 0.0486
16
AVD_Home_010_1_traj4, ate: 64.20555808479068
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[9248/15000], training loss: 0.0839
[9256/15000], training loss: 0.0731
[9264/15000], training loss: 0.0582
[9272/15000], training loss: 0.0418
[9280/15000], training loss: 0.0505
16
AVD_Home_010_1_traj4, ate: 64.03452116905821
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[9288/15000], training loss: 0.0458
[9296/15000], training loss: 0.0442
[9304/15000], training loss: 0.0384
[9312/15000], training loss: 0.0457
[9320/15000], training loss: 0.0439
16
AVD_Home_010_1_traj4, ate: 64.4816869326622
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[9328/15000], training loss: 0.0746
[9336/15000], training loss: 0.0671
[9344/15000], training loss: 0.0435
[9352/15000], training loss: 0.0427
[9360/15000], training loss: 0.0465
16
AVD_Home_010_1_traj4, ate: 63.6923303261376
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[9368/15000], training loss: 0.0410
[9376/15000], training loss: 0.0408
[9384/15000], training loss: 0.0650
[9392/15000], training loss: 0.0423
[9400/15000], training loss: 0.0626
16
AVD_Home_010_1_traj4, ate: 62.14286577933912
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[9408/15000], training loss: 0.0646
[9416/15000], training loss: 0.0593
[9424/15000], training loss: 0.0409
[9432/15000], training loss: 0.0592
[9440/15000], training loss: 0.0391
16
AVD_Home_010_1_traj4, ate: 62.94125776578909
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[9448/15000], training loss: 0.0454
[9456/15000], training loss: 0.0446
[9464/15000], training loss: 0.0414
[9472/15000], training loss: 0.0600
[9480/15000], training loss: 0.0660
16
AVD_Home_010_1_traj4, ate: 63.3984303783378
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[9488/15000], training loss: 0.0411
[9496/15000], training loss: 0.0493
[9504/15000], training loss: 0.0434
[9512/15000], training loss: 0.0429
[9520/15000], training loss: 0.0462
16
AVD_Home_010_1_traj4, ate: 63.66338281594338
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[9528/15000], training loss: 0.0527
[9536/15000], training loss: 0.0523
[9544/15000], training loss: 0.0387
[9552/15000], training loss: 0.0615
[9560/15000], training loss: 0.0632
16
AVD_Home_010_1_traj4, ate: 63.07932541262179
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[9568/15000], training loss: 0.0602
[9576/15000], training loss: 0.0724
[9584/15000], training loss: 0.0457
[9592/15000], training loss: 0.0541
[9600/15000], training loss: 0.0636
16
AVD_Home_010_1_traj4, ate: 63.58533684223226
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[9608/15000], training loss: 0.0495
[9616/15000], training loss: 0.0519
[9624/15000], training loss: 0.0484
[9632/15000], training loss: 0.0476
[9640/15000], training loss: 0.0566
16
AVD_Home_010_1_traj4, ate: 65.39274892540574
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[9648/15000], training loss: 0.0592
[9656/15000], training loss: 0.0380
[9664/15000], training loss: 0.0567
[9672/15000], training loss: 0.0648
[9680/15000], training loss: 0.0400
16
AVD_Home_010_1_traj4, ate: 63.72336821374949
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[9688/15000], training loss: 0.0543
[9696/15000], training loss: 0.0418
[9704/15000], training loss: 0.0711
[9712/15000], training loss: 0.0492
[9720/15000], training loss: 0.0392
16
AVD_Home_010_1_traj4, ate: 63.599714002377326
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[9728/15000], training loss: 0.0389
[9736/15000], training loss: 0.0417
[9744/15000], training loss: 0.0629
[9752/15000], training loss: 0.0392
[9760/15000], training loss: 0.0496
16
AVD_Home_010_1_traj4, ate: 64.82750135563438
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[9768/15000], training loss: 0.0540
[9776/15000], training loss: 0.0617
[9784/15000], training loss: 0.0494
[9792/15000], training loss: 0.0387
[9800/15000], training loss: 0.0622
16
AVD_Home_010_1_traj4, ate: 65.2633301103504
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[9808/15000], training loss: 0.0578
[9816/15000], training loss: 0.0367
[9824/15000], training loss: 0.0422
[9832/15000], training loss: 0.0505
[9840/15000], training loss: 0.0400
16
AVD_Home_010_1_traj4, ate: 64.13949009551436
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[9848/15000], training loss: 0.0607
[9856/15000], training loss: 0.0802
[9864/15000], training loss: 0.0421
[9872/15000], training loss: 0.0520
[9880/15000], training loss: 0.0431
16
AVD_Home_010_1_traj4, ate: 63.25508160961525
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[9888/15000], training loss: 0.0333
[9896/15000], training loss: 0.0466
[9904/15000], training loss: 0.0582
[9912/15000], training loss: 0.0448
[9920/15000], training loss: 0.0634
16
AVD_Home_010_1_traj4, ate: 63.487705610026126
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[9928/15000], training loss: 0.0400
[9936/15000], training loss: 0.0437
[9944/15000], training loss: 0.0362
[9952/15000], training loss: 0.0394
[9960/15000], training loss: 0.0495
16
AVD_Home_010_1_traj4, ate: 63.06675575940374
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[9968/15000], training loss: 0.0563
[9976/15000], training loss: 0.0565
[9984/15000], training loss: 0.0749
[9992/15000], training loss: 0.0549
[10000/15000], training loss: 0.0654
16
AVD_Home_010_1_traj4, ate: 59.32911297630595
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[10008/15000], training loss: 0.0420
[10016/15000], training loss: 0.0425
[10024/15000], training loss: 0.0442
[10032/15000], training loss: 0.0436
[10040/15000], training loss: 0.0636
16
AVD_Home_010_1_traj4, ate: 62.04273055098493
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[10048/15000], training loss: 0.0485
[10056/15000], training loss: 0.0544
[10064/15000], training loss: 0.0486
[10072/15000], training loss: 0.0362
[10080/15000], training loss: 0.1086
16
AVD_Home_010_1_traj4, ate: 62.77855229723727
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[10088/15000], training loss: 0.0558
[10096/15000], training loss: 0.0639
[10104/15000], training loss: 0.0398
[10112/15000], training loss: 0.0540
[10120/15000], training loss: 0.0348
16
AVD_Home_010_1_traj4, ate: 61.45287760364638
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[10128/15000], training loss: 0.0542
[10136/15000], training loss: 0.0336
[10144/15000], training loss: 0.0517
[10152/15000], training loss: 0.0445
[10160/15000], training loss: 0.0406
16
AVD_Home_010_1_traj4, ate: 64.98059267212409
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[10168/15000], training loss: 0.0842
[10176/15000], training loss: 0.0785
[10184/15000], training loss: 0.0421
[10192/15000], training loss: 0.0504
[10200/15000], training loss: 0.0388
16
AVD_Home_010_1_traj4, ate: 64.99532363758172
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[10208/15000], training loss: 0.0595
[10216/15000], training loss: 0.0365
[10224/15000], training loss: 0.0843
[10232/15000], training loss: 0.1039
[10240/15000], training loss: 0.0607
16
AVD_Home_010_1_traj4, ate: 64.50559250597414
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[10248/15000], training loss: 0.0552
[10256/15000], training loss: 0.0519
[10264/15000], training loss: 0.0439
[10272/15000], training loss: 0.0638
[10280/15000], training loss: 0.0501
16
AVD_Home_010_1_traj4, ate: 63.63889307181795
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[10288/15000], training loss: 0.0582
[10296/15000], training loss: 0.0543
[10304/15000], training loss: 0.0579
[10312/15000], training loss: 0.0374
[10320/15000], training loss: 0.0526
16
AVD_Home_010_1_traj4, ate: 63.11258474948077
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[10328/15000], training loss: 0.0701
[10336/15000], training loss: 0.0864
[10344/15000], training loss: 0.0489
[10352/15000], training loss: 0.0532
[10360/15000], training loss: 0.0491
16
AVD_Home_010_1_traj4, ate: 63.93325954383176
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[10368/15000], training loss: 0.0624
[10376/15000], training loss: 0.0402
[10384/15000], training loss: 0.0430
[10392/15000], training loss: 0.0429
[10400/15000], training loss: 0.0375
16
AVD_Home_010_1_traj4, ate: 62.26041456317611
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[10408/15000], training loss: 0.0574
[10416/15000], training loss: 0.0443
[10424/15000], training loss: 0.0440
[10432/15000], training loss: 0.0418
[10440/15000], training loss: 0.0651
16
AVD_Home_010_1_traj4, ate: 61.34825830257197
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[10448/15000], training loss: 0.0474
[10456/15000], training loss: 0.0456
[10464/15000], training loss: 0.0507
[10472/15000], training loss: 0.0429
[10480/15000], training loss: 0.0545
16
AVD_Home_010_1_traj4, ate: 62.24747191711873
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[10488/15000], training loss: 0.0385
[10496/15000], training loss: 0.0384
[10504/15000], training loss: 0.0513
[10512/15000], training loss: 0.0419
[10520/15000], training loss: 0.0561
16
AVD_Home_010_1_traj4, ate: 63.98423492574697
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[10528/15000], training loss: 0.0355
[10536/15000], training loss: 0.0487
[10544/15000], training loss: 0.0564
[10552/15000], training loss: 0.0828
[10560/15000], training loss: 0.0566
16
AVD_Home_010_1_traj4, ate: 62.10682937748822
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[10568/15000], training loss: 0.0385
[10576/15000], training loss: 0.0559
[10584/15000], training loss: 0.0625
[10592/15000], training loss: 0.0452
[10600/15000], training loss: 0.0467
16
AVD_Home_010_1_traj4, ate: 64.61024813852009
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[10608/15000], training loss: 0.0768
[10616/15000], training loss: 0.0406
[10624/15000], training loss: 0.0370
[10632/15000], training loss: 0.0477
[10640/15000], training loss: 0.0452
16
AVD_Home_010_1_traj4, ate: 63.69279741702696
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[10648/15000], training loss: 0.0805
[10656/15000], training loss: 0.0618
[10664/15000], training loss: 0.0466
[10672/15000], training loss: 0.0461
[10680/15000], training loss: 0.0406
16
AVD_Home_010_1_traj4, ate: 63.42092176333651
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[10688/15000], training loss: 0.0512
[10696/15000], training loss: 0.0456
[10704/15000], training loss: 0.0403
[10712/15000], training loss: 0.0378
[10720/15000], training loss: 0.0393
16
AVD_Home_010_1_traj4, ate: 63.13564255995011
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[10728/15000], training loss: 0.0390
[10736/15000], training loss: 0.0544
[10744/15000], training loss: 0.0733
[10752/15000], training loss: 0.0741
[10760/15000], training loss: 0.0539
16
AVD_Home_010_1_traj4, ate: 64.00737269484104
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[10768/15000], training loss: 0.0398
[10776/15000], training loss: 0.0472
[10784/15000], training loss: 0.0521
[10792/15000], training loss: 0.0632
[10800/15000], training loss: 0.0440
16
AVD_Home_010_1_traj4, ate: 61.555973686467865
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[10808/15000], training loss: 0.0651
[10816/15000], training loss: 0.0660
[10824/15000], training loss: 0.0385
[10832/15000], training loss: 0.0563
[10840/15000], training loss: 0.0662
16
AVD_Home_010_1_traj4, ate: 63.196277626313076
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[10848/15000], training loss: 0.0635
[10856/15000], training loss: 0.0428
[10864/15000], training loss: 0.0559
[10872/15000], training loss: 0.0350
[10880/15000], training loss: 0.0424
16
AVD_Home_010_1_traj4, ate: 62.954420386468065
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[10888/15000], training loss: 0.0710
[10896/15000], training loss: 0.0606
[10904/15000], training loss: 0.0613
[10912/15000], training loss: 0.0456
[10920/15000], training loss: 0.0533
16
AVD_Home_010_1_traj4, ate: 62.252834531656625
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[10928/15000], training loss: 0.0480
[10936/15000], training loss: 0.0546
[10944/15000], training loss: 0.0575
[10952/15000], training loss: 0.0376
[10960/15000], training loss: 0.0407
16
AVD_Home_010_1_traj4, ate: 62.324784610370564
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[10968/15000], training loss: 0.0430
[10976/15000], training loss: 0.0684
[10984/15000], training loss: 0.0419
[10992/15000], training loss: 0.0649
[11000/15000], training loss: 0.0631
16
AVD_Home_010_1_traj4, ate: 62.34802362164741
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[11008/15000], training loss: 0.0686
[11016/15000], training loss: 0.0446
[11024/15000], training loss: 0.0620
[11032/15000], training loss: 0.0478
[11040/15000], training loss: 0.0735
16
AVD_Home_010_1_traj4, ate: 62.54417347418719
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[11048/15000], training loss: 0.0488
[11056/15000], training loss: 0.0461
[11064/15000], training loss: 0.0661
[11072/15000], training loss: 0.0701
[11080/15000], training loss: 0.0391
16
AVD_Home_010_1_traj4, ate: 62.62640538764236
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[11088/15000], training loss: 0.0428
[11096/15000], training loss: 0.0564
[11104/15000], training loss: 0.0458
[11112/15000], training loss: 0.0839
[11120/15000], training loss: 0.0551
16
AVD_Home_010_1_traj4, ate: 63.55950741420089
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[11128/15000], training loss: 0.0509
[11136/15000], training loss: 0.0700
[11144/15000], training loss: 0.0727
[11152/15000], training loss: 0.0363
[11160/15000], training loss: 0.0656
16
AVD_Home_010_1_traj4, ate: 62.653060121121044
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[11168/15000], training loss: 0.0655
[11176/15000], training loss: 0.0358
[11184/15000], training loss: 0.0468
[11192/15000], training loss: 0.0747
[11200/15000], training loss: 0.0881
16
AVD_Home_010_1_traj4, ate: 63.642906865747236
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[11208/15000], training loss: 0.0631
[11216/15000], training loss: 0.0497
[11224/15000], training loss: 0.0500
[11232/15000], training loss: 0.0520
[11240/15000], training loss: 0.0440
16
AVD_Home_010_1_traj4, ate: 65.18657813450245
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[11248/15000], training loss: 0.0583
[11256/15000], training loss: 0.0403
[11264/15000], training loss: 0.0520
[11272/15000], training loss: 0.0682
[11280/15000], training loss: 0.0537
16
AVD_Home_010_1_traj4, ate: 62.82870601216294
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[11288/15000], training loss: 0.0355
[11296/15000], training loss: 0.0491
[11304/15000], training loss: 0.0513
[11312/15000], training loss: 0.0434
[11320/15000], training loss: 0.0516
16
AVD_Home_010_1_traj4, ate: 64.10700945697019
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[11328/15000], training loss: 0.0490
[11336/15000], training loss: 0.0490
[11344/15000], training loss: 0.0467
[11352/15000], training loss: 0.0521
[11360/15000], training loss: 0.0557
16
AVD_Home_010_1_traj4, ate: 63.34691854266567
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[11368/15000], training loss: 0.0754
[11376/15000], training loss: 0.0535
[11384/15000], training loss: 0.0445
[11392/15000], training loss: 0.0391
[11400/15000], training loss: 0.0474
16
AVD_Home_010_1_traj4, ate: 63.10488422986499
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[11408/15000], training loss: 0.0424
[11416/15000], training loss: 0.0483
[11424/15000], training loss: 0.0560
[11432/15000], training loss: 0.0490
[11440/15000], training loss: 0.0438
16
AVD_Home_010_1_traj4, ate: 62.264597544119766
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[11448/15000], training loss: 0.0375
[11456/15000], training loss: 0.0651
[11464/15000], training loss: 0.0492
[11472/15000], training loss: 0.0607
[11480/15000], training loss: 0.0413
16
AVD_Home_010_1_traj4, ate: 62.739727065086186
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[11488/15000], training loss: 0.0434
[11496/15000], training loss: 0.0705
[11504/15000], training loss: 0.0510
[11512/15000], training loss: 0.0814
[11520/15000], training loss: 0.0549
16
AVD_Home_010_1_traj4, ate: 60.9025641003341
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[11528/15000], training loss: 0.0529
[11536/15000], training loss: 0.0654
[11544/15000], training loss: 0.0459
[11552/15000], training loss: 0.0439
[11560/15000], training loss: 0.0452
16
AVD_Home_010_1_traj4, ate: 62.73832619252553
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[11568/15000], training loss: 0.0473
[11576/15000], training loss: 0.0514
[11584/15000], training loss: 0.0405
[11592/15000], training loss: 0.0549
[11600/15000], training loss: 0.0408
16
AVD_Home_010_1_traj4, ate: 63.03034983080122
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[11608/15000], training loss: 0.0608
[11616/15000], training loss: 0.0605
[11624/15000], training loss: 0.0398
[11632/15000], training loss: 0.0420
[11640/15000], training loss: 0.0404
16
AVD_Home_010_1_traj4, ate: 63.95533206029268
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[11648/15000], training loss: 0.0588
[11656/15000], training loss: 0.0540
[11664/15000], training loss: 0.0476
[11672/15000], training loss: 0.0523
[11680/15000], training loss: 0.0361
16
AVD_Home_010_1_traj4, ate: 62.52095579453714
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[11688/15000], training loss: 0.0437
[11696/15000], training loss: 0.0650
[11704/15000], training loss: 0.0351
[11712/15000], training loss: 0.0535
[11720/15000], training loss: 0.0391
16
AVD_Home_010_1_traj4, ate: 62.510123484958406
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[11728/15000], training loss: 0.0491
[11736/15000], training loss: 0.0444
[11744/15000], training loss: 0.0650
[11752/15000], training loss: 0.0424
[11760/15000], training loss: 0.0666
16
AVD_Home_010_1_traj4, ate: 65.49651419594348
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[11768/15000], training loss: 0.0558
[11776/15000], training loss: 0.0442
[11784/15000], training loss: 0.0541
[11792/15000], training loss: 0.0555
[11800/15000], training loss: 0.0464
16
AVD_Home_010_1_traj4, ate: 60.76271843473819
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[11808/15000], training loss: 0.0420
[11816/15000], training loss: 0.0449
[11824/15000], training loss: 0.0675
[11832/15000], training loss: 0.0623
[11840/15000], training loss: 0.0658
16
AVD_Home_010_1_traj4, ate: 63.790588089200284
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[11848/15000], training loss: 0.0468
[11856/15000], training loss: 0.0422
[11864/15000], training loss: 0.0765
[11872/15000], training loss: 0.0489
[11880/15000], training loss: 0.0730
16
AVD_Home_010_1_traj4, ate: 59.43205983462238
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[11888/15000], training loss: 0.0406
[11896/15000], training loss: 0.0671
[11904/15000], training loss: 0.0401
[11912/15000], training loss: 0.0577
[11920/15000], training loss: 0.0597
16
AVD_Home_010_1_traj4, ate: 62.438192900592455
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[11928/15000], training loss: 0.0712
[11936/15000], training loss: 0.0497
[11944/15000], training loss: 0.0424
[11952/15000], training loss: 0.0445
[11960/15000], training loss: 0.0654
16
AVD_Home_010_1_traj4, ate: 61.233007771105896
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[11968/15000], training loss: 0.0753
[11976/15000], training loss: 0.0774
[11984/15000], training loss: 0.0783
[11992/15000], training loss: 0.0411
[12000/15000], training loss: 0.0631
16
AVD_Home_010_1_traj4, ate: 63.064977656942865
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[12008/15000], training loss: 0.0567
[12016/15000], training loss: 0.0557
[12024/15000], training loss: 0.0728
[12032/15000], training loss: 0.0361
[12040/15000], training loss: 0.0556
16
AVD_Home_010_1_traj4, ate: 62.5742032532438
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[12048/15000], training loss: 0.0697
[12056/15000], training loss: 0.0392
[12064/15000], training loss: 0.0611
[12072/15000], training loss: 0.0455
[12080/15000], training loss: 0.0420
16
AVD_Home_010_1_traj4, ate: 62.70695777346112
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[12088/15000], training loss: 0.0615
[12096/15000], training loss: 0.0595
[12104/15000], training loss: 0.0614
[12112/15000], training loss: 0.0578
[12120/15000], training loss: 0.0412
16
AVD_Home_010_1_traj4, ate: 62.929408942051424
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[12128/15000], training loss: 0.0634
[12136/15000], training loss: 0.0374
[12144/15000], training loss: 0.0445
[12152/15000], training loss: 0.0544
[12160/15000], training loss: 0.0596
16
AVD_Home_010_1_traj4, ate: 61.82872875714563
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[12168/15000], training loss: 0.0565
[12176/15000], training loss: 0.0435
[12184/15000], training loss: 0.0775
[12192/15000], training loss: 0.0616
[12200/15000], training loss: 0.0568
16
AVD_Home_010_1_traj4, ate: 62.239080323630766
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[12208/15000], training loss: 0.0516
[12216/15000], training loss: 0.0376
[12224/15000], training loss: 0.0463
[12232/15000], training loss: 0.0470
[12240/15000], training loss: 0.0419
16
AVD_Home_010_1_traj4, ate: 62.120832045548624
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[12248/15000], training loss: 0.0531
[12256/15000], training loss: 0.0476
[12264/15000], training loss: 0.0430
[12272/15000], training loss: 0.0427
[12280/15000], training loss: 0.0524
16
AVD_Home_010_1_traj4, ate: 62.20076102084381
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[12288/15000], training loss: 0.0405
[12296/15000], training loss: 0.0754
[12304/15000], training loss: 0.0449
[12312/15000], training loss: 0.0422
[12320/15000], training loss: 0.0490
16
AVD_Home_010_1_traj4, ate: 62.76904888778996
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[12328/15000], training loss: 0.0540
[12336/15000], training loss: 0.0355
[12344/15000], training loss: 0.0616
[12352/15000], training loss: 0.0551
[12360/15000], training loss: 0.0373
16
AVD_Home_010_1_traj4, ate: 62.55261539158865
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[12368/15000], training loss: 0.0380
[12376/15000], training loss: 0.0558
[12384/15000], training loss: 0.0475
[12392/15000], training loss: 0.0581
[12400/15000], training loss: 0.0506
16
AVD_Home_010_1_traj4, ate: 62.48386782192468
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[12408/15000], training loss: 0.0491
[12416/15000], training loss: 0.0469
[12424/15000], training loss: 0.0719
[12432/15000], training loss: 0.0493
[12440/15000], training loss: 0.0422
16
AVD_Home_010_1_traj4, ate: 61.85967944405082
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[12448/15000], training loss: 0.0521
[12456/15000], training loss: 0.0353
[12464/15000], training loss: 0.0592
[12472/15000], training loss: 0.0722
[12480/15000], training loss: 0.0624
16
AVD_Home_010_1_traj4, ate: 62.30123283951431
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[12488/15000], training loss: 0.0468
[12496/15000], training loss: 0.0519
[12504/15000], training loss: 0.0368
[12512/15000], training loss: 0.0371
[12520/15000], training loss: 0.0485
16
AVD_Home_010_1_traj4, ate: 62.67382357564667
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[12528/15000], training loss: 0.0527
[12536/15000], training loss: 0.0703
[12544/15000], training loss: 0.0691
[12552/15000], training loss: 0.0402
[12560/15000], training loss: 0.0577
16
AVD_Home_010_1_traj4, ate: 61.288368807388025
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[12568/15000], training loss: 0.0536
[12576/15000], training loss: 0.0562
[12584/15000], training loss: 0.0418
[12592/15000], training loss: 0.0456
[12600/15000], training loss: 0.0367
16
AVD_Home_010_1_traj4, ate: 62.44630226165329
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[12608/15000], training loss: 0.0382
[12616/15000], training loss: 0.0458
[12624/15000], training loss: 0.0397
[12632/15000], training loss: 0.0410
[12640/15000], training loss: 0.0854
16
AVD_Home_010_1_traj4, ate: 62.401398296226134
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[12648/15000], training loss: 0.0429
[12656/15000], training loss: 0.0399
[12664/15000], training loss: 0.0496
[12672/15000], training loss: 0.0378
[12680/15000], training loss: 0.0600
16
AVD_Home_010_1_traj4, ate: 61.88934174364708
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[12688/15000], training loss: 0.0558
[12696/15000], training loss: 0.0647
[12704/15000], training loss: 0.0394
[12712/15000], training loss: 0.0419
[12720/15000], training loss: 0.0448
16
AVD_Home_010_1_traj4, ate: 63.00273552327695
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[12728/15000], training loss: 0.0544
[12736/15000], training loss: 0.0471
[12744/15000], training loss: 0.0501
[12752/15000], training loss: 0.0419
[12760/15000], training loss: 0.0472
16
AVD_Home_010_1_traj4, ate: 61.84362502064234
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[12768/15000], training loss: 0.0349
[12776/15000], training loss: 0.0477
[12784/15000], training loss: 0.0432
[12792/15000], training loss: 0.0767
[12800/15000], training loss: 0.0482
16
AVD_Home_010_1_traj4, ate: 62.95755818567501
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[12808/15000], training loss: 0.0360
[12816/15000], training loss: 0.0441
[12824/15000], training loss: 0.0469
[12832/15000], training loss: 0.0822
[12840/15000], training loss: 0.0374
16
AVD_Home_010_1_traj4, ate: 62.42179324572859
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[12848/15000], training loss: 0.0452
[12856/15000], training loss: 0.0521
[12864/15000], training loss: 0.0368
[12872/15000], training loss: 0.0526
[12880/15000], training loss: 0.0527
16
AVD_Home_010_1_traj4, ate: 62.83521310314742
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[12888/15000], training loss: 0.0604
[12896/15000], training loss: 0.0616
[12904/15000], training loss: 0.0553
[12912/15000], training loss: 0.0700
[12920/15000], training loss: 0.1004
16
AVD_Home_010_1_traj4, ate: 62.600541564880004
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[12928/15000], training loss: 0.0408
[12936/15000], training loss: 0.0644
[12944/15000], training loss: 0.0468
[12952/15000], training loss: 0.0452
[12960/15000], training loss: 0.0868
16
AVD_Home_010_1_traj4, ate: 62.88410630512179
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[12968/15000], training loss: 0.0520
[12976/15000], training loss: 0.0437
[12984/15000], training loss: 0.0509
[12992/15000], training loss: 0.0395
[13000/15000], training loss: 0.0471
16
AVD_Home_010_1_traj4, ate: 62.60076978120737
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[13008/15000], training loss: 0.0469
[13016/15000], training loss: 0.0422
[13024/15000], training loss: 0.0342
[13032/15000], training loss: 0.0495
[13040/15000], training loss: 0.0418
16
AVD_Home_010_1_traj4, ate: 62.69282566276503
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[13048/15000], training loss: 0.0385
[13056/15000], training loss: 0.0612
[13064/15000], training loss: 0.0437
[13072/15000], training loss: 0.0368
[13080/15000], training loss: 0.0587
16
AVD_Home_010_1_traj4, ate: 62.44227559045562
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[13088/15000], training loss: 0.0476
[13096/15000], training loss: 0.0635
[13104/15000], training loss: 0.0489
[13112/15000], training loss: 0.0526
[13120/15000], training loss: 0.0411
16
AVD_Home_010_1_traj4, ate: 63.07358692785365
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[13128/15000], training loss: 0.0444
[13136/15000], training loss: 0.0581
[13144/15000], training loss: 0.0481
[13152/15000], training loss: 0.0386
[13160/15000], training loss: 0.0497
16
AVD_Home_010_1_traj4, ate: 63.22561904345963
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[13168/15000], training loss: 0.0644
[13176/15000], training loss: 0.0434
[13184/15000], training loss: 0.0336
[13192/15000], training loss: 0.0524
[13200/15000], training loss: 0.0648
16
AVD_Home_010_1_traj4, ate: 64.80465476042878
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[13208/15000], training loss: 0.0611
[13216/15000], training loss: 0.0614
[13224/15000], training loss: 0.0493
[13232/15000], training loss: 0.0424
[13240/15000], training loss: 0.0493
16
AVD_Home_010_1_traj4, ate: 63.288681563784806
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[13248/15000], training loss: 0.0384
[13256/15000], training loss: 0.0607
[13264/15000], training loss: 0.0731
[13272/15000], training loss: 0.0629
[13280/15000], training loss: 0.0389
16
AVD_Home_010_1_traj4, ate: 62.47501861439713
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[13288/15000], training loss: 0.0420
[13296/15000], training loss: 0.0493
[13304/15000], training loss: 0.0612
[13312/15000], training loss: 0.0345
[13320/15000], training loss: 0.0456
16
AVD_Home_010_1_traj4, ate: 61.098430243888274
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[13328/15000], training loss: 0.0728
[13336/15000], training loss: 0.0462
[13344/15000], training loss: 0.0946
[13352/15000], training loss: 0.0606
[13360/15000], training loss: 0.0355
16
AVD_Home_010_1_traj4, ate: 61.931830284188365
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[13368/15000], training loss: 0.0405
[13376/15000], training loss: 0.0462
[13384/15000], training loss: 0.0517
[13392/15000], training loss: 0.0390
[13400/15000], training loss: 0.0641
16
AVD_Home_010_1_traj4, ate: 61.30337763058062
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[13408/15000], training loss: 0.0522
[13416/15000], training loss: 0.0396
[13424/15000], training loss: 0.0600
[13432/15000], training loss: 0.0355
[13440/15000], training loss: 0.0502
16
AVD_Home_010_1_traj4, ate: 63.713980156424604
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[13448/15000], training loss: 0.0660
[13456/15000], training loss: 0.0556
[13464/15000], training loss: 0.0547
[13472/15000], training loss: 0.0457
[13480/15000], training loss: 0.0341
16
AVD_Home_010_1_traj4, ate: 63.39564664757087
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[13488/15000], training loss: 0.0548
[13496/15000], training loss: 0.0390
[13504/15000], training loss: 0.0379
[13512/15000], training loss: 0.0453
[13520/15000], training loss: 0.0416
16
AVD_Home_010_1_traj4, ate: 63.19686602761359
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[13528/15000], training loss: 0.0343
[13536/15000], training loss: 0.0369
[13544/15000], training loss: 0.0446
[13552/15000], training loss: 0.0391
[13560/15000], training loss: 0.0357
16
AVD_Home_010_1_traj4, ate: 62.02449135501542
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[13568/15000], training loss: 0.0475
[13576/15000], training loss: 0.0422
[13584/15000], training loss: 0.0513
[13592/15000], training loss: 0.0496
[13600/15000], training loss: 0.0493
16
AVD_Home_010_1_traj4, ate: 61.64563445840771
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[13608/15000], training loss: 0.0450
[13616/15000], training loss: 0.0607
[13624/15000], training loss: 0.0387
[13632/15000], training loss: 0.0676
[13640/15000], training loss: 0.0824
16
AVD_Home_010_1_traj4, ate: 64.10969250884551
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[13648/15000], training loss: 0.0523
[13656/15000], training loss: 0.0435
[13664/15000], training loss: 0.0630
[13672/15000], training loss: 0.0685
[13680/15000], training loss: 0.0410
16
AVD_Home_010_1_traj4, ate: 62.34428321435965
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[13688/15000], training loss: 0.0555
[13696/15000], training loss: 0.0532
[13704/15000], training loss: 0.0431
[13712/15000], training loss: 0.0724
[13720/15000], training loss: 0.0363
16
AVD_Home_010_1_traj4, ate: 62.53725354559908
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[13728/15000], training loss: 0.0524
[13736/15000], training loss: 0.0612
[13744/15000], training loss: 0.0387
[13752/15000], training loss: 0.0455
[13760/15000], training loss: 0.0628
16
AVD_Home_010_1_traj4, ate: 62.663656301252196
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[13768/15000], training loss: 0.0567
[13776/15000], training loss: 0.0432
[13784/15000], training loss: 0.0456
[13792/15000], training loss: 0.0607
[13800/15000], training loss: 0.0803
16
AVD_Home_010_1_traj4, ate: 62.71815904528547
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[13808/15000], training loss: 0.0674
[13816/15000], training loss: 0.0365
[13824/15000], training loss: 0.0507
[13832/15000], training loss: 0.0444
[13840/15000], training loss: 0.0744
16
AVD_Home_010_1_traj4, ate: 61.734978664188304
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[13848/15000], training loss: 0.0607
[13856/15000], training loss: 0.0358
[13864/15000], training loss: 0.0405
[13872/15000], training loss: 0.0580
[13880/15000], training loss: 0.0442
16
AVD_Home_010_1_traj4, ate: 61.69702344710278
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[13888/15000], training loss: 0.0365
[13896/15000], training loss: 0.0390
[13904/15000], training loss: 0.0410
[13912/15000], training loss: 0.0413
[13920/15000], training loss: 0.0559
16
AVD_Home_010_1_traj4, ate: 61.933498592605154
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[13928/15000], training loss: 0.0506
[13936/15000], training loss: 0.0584
[13944/15000], training loss: 0.0546
[13952/15000], training loss: 0.0986
[13960/15000], training loss: 0.0382
16
AVD_Home_010_1_traj4, ate: 61.27927126024137
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[13968/15000], training loss: 0.0546
[13976/15000], training loss: 0.0519
[13984/15000], training loss: 0.0647
[13992/15000], training loss: 0.0480
[14000/15000], training loss: 0.0419
16
AVD_Home_010_1_traj4, ate: 61.930930460876496
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[14008/15000], training loss: 0.0953
[14016/15000], training loss: 0.0384
[14024/15000], training loss: 0.0688
[14032/15000], training loss: 0.0910
[14040/15000], training loss: 0.0393
16
AVD_Home_010_1_traj4, ate: 61.29372181497225
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[14048/15000], training loss: 0.0479
[14056/15000], training loss: 0.0585
[14064/15000], training loss: 0.0385
[14072/15000], training loss: 0.0476
[14080/15000], training loss: 0.0586
16
AVD_Home_010_1_traj4, ate: 62.15755442540105
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[14088/15000], training loss: 0.0499
[14096/15000], training loss: 0.0571
[14104/15000], training loss: 0.0568
[14112/15000], training loss: 0.0414
[14120/15000], training loss: 0.0559
16
AVD_Home_010_1_traj4, ate: 62.946830000014174
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[14128/15000], training loss: 0.0465
[14136/15000], training loss: 0.0601
[14144/15000], training loss: 0.0641
[14152/15000], training loss: 0.0431
[14160/15000], training loss: 0.0603
16
AVD_Home_010_1_traj4, ate: 62.05207040653902
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[14168/15000], training loss: 0.0500
[14176/15000], training loss: 0.0370
[14184/15000], training loss: 0.0517
[14192/15000], training loss: 0.0372
[14200/15000], training loss: 0.0377
16
AVD_Home_010_1_traj4, ate: 60.50215346578579
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[14208/15000], training loss: 0.0624
[14216/15000], training loss: 0.0593
[14224/15000], training loss: 0.0368
[14232/15000], training loss: 0.0385
[14240/15000], training loss: 0.0411
16
AVD_Home_010_1_traj4, ate: 63.36424210788211
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[14248/15000], training loss: 0.0418
[14256/15000], training loss: 0.0373
[14264/15000], training loss: 0.0424
[14272/15000], training loss: 0.0824
[14280/15000], training loss: 0.0449
16
AVD_Home_010_1_traj4, ate: 63.119095746786634
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[14288/15000], training loss: 0.0543
[14296/15000], training loss: 0.0902
[14304/15000], training loss: 0.0457
[14312/15000], training loss: 0.0518
[14320/15000], training loss: 0.0557
16
AVD_Home_010_1_traj4, ate: 63.27231953951431
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[14328/15000], training loss: 0.0450
[14336/15000], training loss: 0.0661
[14344/15000], training loss: 0.0634
[14352/15000], training loss: 0.0512
[14360/15000], training loss: 0.0486
16
AVD_Home_010_1_traj4, ate: 60.74907820361344
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[14368/15000], training loss: 0.0416
[14376/15000], training loss: 0.0387
[14384/15000], training loss: 0.0617
[14392/15000], training loss: 0.0409
[14400/15000], training loss: 0.0537
16
AVD_Home_010_1_traj4, ate: 61.071882437481406
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[14408/15000], training loss: 0.0364
[14416/15000], training loss: 0.0442
[14424/15000], training loss: 0.0394
[14432/15000], training loss: 0.0648
[14440/15000], training loss: 0.0400
16
AVD_Home_010_1_traj4, ate: 63.2940077074984
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[14448/15000], training loss: 0.0400
[14456/15000], training loss: 0.0422
[14464/15000], training loss: 0.0390
[14472/15000], training loss: 0.0632
[14480/15000], training loss: 0.0678
16
AVD_Home_010_1_traj4, ate: 62.3445475980623
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[14488/15000], training loss: 0.0589
[14496/15000], training loss: 0.0415
[14504/15000], training loss: 0.0421
[14512/15000], training loss: 0.0382
[14520/15000], training loss: 0.0416
16
AVD_Home_010_1_traj4, ate: 62.16537601903435
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[14528/15000], training loss: 0.0727
[14536/15000], training loss: 0.0455
[14544/15000], training loss: 0.0452
[14552/15000], training loss: 0.0639
[14560/15000], training loss: 0.0372
16
AVD_Home_010_1_traj4, ate: 62.02247776980888
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[14568/15000], training loss: 0.0570
[14576/15000], training loss: 0.0392
[14584/15000], training loss: 0.0383
[14592/15000], training loss: 0.0554
[14600/15000], training loss: 0.0347
16
AVD_Home_010_1_traj4, ate: 61.84208365882358
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[14608/15000], training loss: 0.0398
[14616/15000], training loss: 0.0382
[14624/15000], training loss: 0.0621
[14632/15000], training loss: 0.0440
[14640/15000], training loss: 0.0753
16
AVD_Home_010_1_traj4, ate: 62.45757452364156
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[14648/15000], training loss: 0.0483
[14656/15000], training loss: 0.0434
[14664/15000], training loss: 0.0441
[14672/15000], training loss: 0.0469
[14680/15000], training loss: 0.0709
16
AVD_Home_010_1_traj4, ate: 61.89108788239931
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[14688/15000], training loss: 0.0380
[14696/15000], training loss: 0.0463
[14704/15000], training loss: 0.0600
[14712/15000], training loss: 0.0354
[14720/15000], training loss: 0.0483
16
AVD_Home_010_1_traj4, ate: 62.02139821750819
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[14728/15000], training loss: 0.0601
[14736/15000], training loss: 0.0379
[14744/15000], training loss: 0.0416
[14752/15000], training loss: 0.0434
[14760/15000], training loss: 0.0524
16
AVD_Home_010_1_traj4, ate: 62.58140363335124
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[14768/15000], training loss: 0.0327
[14776/15000], training loss: 0.0359
[14784/15000], training loss: 0.0648
[14792/15000], training loss: 0.0395
[14800/15000], training loss: 0.0668
16
AVD_Home_010_1_traj4, ate: 62.957659234136734
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[14808/15000], training loss: 0.0410
[14816/15000], training loss: 0.0549
[14824/15000], training loss: 0.0454
[14832/15000], training loss: 0.0374
[14840/15000], training loss: 0.0399
16
AVD_Home_010_1_traj4, ate: 63.59800634721254
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[14848/15000], training loss: 0.0416
[14856/15000], training loss: 0.0437
[14864/15000], training loss: 0.0465
[14872/15000], training loss: 0.0787
[14880/15000], training loss: 0.0392
16
AVD_Home_010_1_traj4, ate: 62.593327988984896
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[14888/15000], training loss: 0.0546
[14896/15000], training loss: 0.0467
[14904/15000], training loss: 0.0532
[14912/15000], training loss: 0.0573
[14920/15000], training loss: 0.1022
16
AVD_Home_010_1_traj4, ate: 62.165225995583306
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[14928/15000], training loss: 0.0382
[14936/15000], training loss: 0.0393
[14944/15000], training loss: 0.0495
[14952/15000], training loss: 0.0589
[14960/15000], training loss: 0.0438
16
AVD_Home_010_1_traj4, ate: 62.16943090896796
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
[14968/15000], training loss: 0.0378
[14976/15000], training loss: 0.0421
[14984/15000], training loss: 0.0767
[14992/15000], training loss: 0.0680
[15000/15000], training loss: 0.0535
16
AVD_Home_010_1_traj4, ate: 62.20473795247643
model saved to ../results/AVD/AVD_Home_010_1_traj4/model_best.pth
./lstm_run_train_AVD.sh: line 25: /home/mmvc: Is a directory
