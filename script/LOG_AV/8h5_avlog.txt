maxpool
latent size single: 16
loading dataset
16
pccppcpc1123 (16, 27, 48, 3)
creating model
start training
[8/15000], training loss: 0.1814
[16/15000], training loss: 0.1472
[24/15000], training loss: 0.1382
[32/15000], training loss: 0.1347
[40/15000], training loss: 0.1282
16
AVD_Home_008_1_traj5, ate: 445.3713737057348
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[48/15000], training loss: 0.1321
[56/15000], training loss: 0.1331
[64/15000], training loss: 0.1282
[72/15000], training loss: 0.1317
[80/15000], training loss: 0.1315
16
AVD_Home_008_1_traj5, ate: 456.4764636048786
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[88/15000], training loss: 0.1317
[96/15000], training loss: 0.1270
[104/15000], training loss: 0.1239
[112/15000], training loss: 0.1286
[120/15000], training loss: 0.1271
16
AVD_Home_008_1_traj5, ate: 440.5393718878384
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[128/15000], training loss: 0.1271
[136/15000], training loss: 0.1217
[144/15000], training loss: 0.1287
[152/15000], training loss: 0.1283
[160/15000], training loss: 0.1264
16
AVD_Home_008_1_traj5, ate: 404.9358824477308
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[168/15000], training loss: 0.1251
[176/15000], training loss: 0.1259
[184/15000], training loss: 0.1264
[192/15000], training loss: 0.1241
[200/15000], training loss: 0.1156
16
AVD_Home_008_1_traj5, ate: 323.5916407538098
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[208/15000], training loss: 0.1231
[216/15000], training loss: 0.1156
[224/15000], training loss: 0.1187
[232/15000], training loss: 0.1241
[240/15000], training loss: 0.1289
16
AVD_Home_008_1_traj5, ate: 332.2495899235802
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[248/15000], training loss: 0.1206
[256/15000], training loss: 0.1147
[264/15000], training loss: 0.1171
[272/15000], training loss: 0.1195
[280/15000], training loss: 0.1070
16
AVD_Home_008_1_traj5, ate: 301.57118264346803
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[288/15000], training loss: 0.1166
[296/15000], training loss: 0.1127
[304/15000], training loss: 0.1119
[312/15000], training loss: 0.1204
[320/15000], training loss: 0.1093
16
AVD_Home_008_1_traj5, ate: 294.28775653829877
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[328/15000], training loss: 0.1157
[336/15000], training loss: 0.1124
[344/15000], training loss: 0.1013
[352/15000], training loss: 0.1032
[360/15000], training loss: 0.1217
16
AVD_Home_008_1_traj5, ate: 294.01350614677153
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[368/15000], training loss: 0.1117
[376/15000], training loss: 0.1149
[384/15000], training loss: 0.1091
[392/15000], training loss: 0.1188
[400/15000], training loss: 0.1125
16
AVD_Home_008_1_traj5, ate: 300.42617729050073
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[408/15000], training loss: 0.1037
[416/15000], training loss: 0.1175
[424/15000], training loss: 0.1192
[432/15000], training loss: 0.1092
[440/15000], training loss: 0.1072
16
AVD_Home_008_1_traj5, ate: 295.8642960039013
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[448/15000], training loss: 0.1092
[456/15000], training loss: 0.1148
[464/15000], training loss: 0.0989
[472/15000], training loss: 0.1083
[480/15000], training loss: 0.1086
16
AVD_Home_008_1_traj5, ate: 286.99910833371
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[488/15000], training loss: 0.1063
[496/15000], training loss: 0.1084
[504/15000], training loss: 0.0942
[512/15000], training loss: 0.1034
[520/15000], training loss: 0.1207
16
AVD_Home_008_1_traj5, ate: 288.3083244752787
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[528/15000], training loss: 0.1231
[536/15000], training loss: 0.0996
[544/15000], training loss: 0.1043
[552/15000], training loss: 0.1097
[560/15000], training loss: 0.1038
16
AVD_Home_008_1_traj5, ate: 282.9106057014691
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[568/15000], training loss: 0.1030
[576/15000], training loss: 0.1067
[584/15000], training loss: 0.1095
[592/15000], training loss: 0.1144
[600/15000], training loss: 0.1140
16
AVD_Home_008_1_traj5, ate: 280.4653181534804
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[608/15000], training loss: 0.1101
[616/15000], training loss: 0.0999
[624/15000], training loss: 0.1107
[632/15000], training loss: 0.0971
[640/15000], training loss: 0.1019
16
AVD_Home_008_1_traj5, ate: 280.41491893433795
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[648/15000], training loss: 0.0971
[656/15000], training loss: 0.1006
[664/15000], training loss: 0.1086
[672/15000], training loss: 0.1128
[680/15000], training loss: 0.1101
16
AVD_Home_008_1_traj5, ate: 289.5817355326713
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[688/15000], training loss: 0.1077
[696/15000], training loss: 0.1029
[704/15000], training loss: 0.0994
[712/15000], training loss: 0.1027
[720/15000], training loss: 0.0942
16
AVD_Home_008_1_traj5, ate: 291.2150866917046
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[728/15000], training loss: 0.1055
[736/15000], training loss: 0.1048
[744/15000], training loss: 0.1062
[752/15000], training loss: 0.1117
[760/15000], training loss: 0.0980
16
AVD_Home_008_1_traj5, ate: 275.02059402885516
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[768/15000], training loss: 0.1045
[776/15000], training loss: 0.1069
[784/15000], training loss: 0.1039
[792/15000], training loss: 0.1064
[800/15000], training loss: 0.1037
16
AVD_Home_008_1_traj5, ate: 274.02707900556055
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[808/15000], training loss: 0.0947
[816/15000], training loss: 0.1022
[824/15000], training loss: 0.0968
[832/15000], training loss: 0.0953
[840/15000], training loss: 0.0927
16
AVD_Home_008_1_traj5, ate: 280.05042197541474
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[848/15000], training loss: 0.1082
[856/15000], training loss: 0.1038
[864/15000], training loss: 0.0983
[872/15000], training loss: 0.1049
[880/15000], training loss: 0.1096
16
AVD_Home_008_1_traj5, ate: 268.9875594422129
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[888/15000], training loss: 0.1069
[896/15000], training loss: 0.0990
[904/15000], training loss: 0.0911
[912/15000], training loss: 0.0981
[920/15000], training loss: 0.1002
16
AVD_Home_008_1_traj5, ate: 273.82699653807066
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[928/15000], training loss: 0.0886
[936/15000], training loss: 0.1008
[944/15000], training loss: 0.1043
[952/15000], training loss: 0.0941
[960/15000], training loss: 0.0881
16
AVD_Home_008_1_traj5, ate: 274.752268636621
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[968/15000], training loss: 0.1027
[976/15000], training loss: 0.0932
[984/15000], training loss: 0.1044
[992/15000], training loss: 0.1107
[1000/15000], training loss: 0.0978
16
AVD_Home_008_1_traj5, ate: 270.1649022654179
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[1008/15000], training loss: 0.1046
[1016/15000], training loss: 0.0943
[1024/15000], training loss: 0.0905
[1032/15000], training loss: 0.0960
[1040/15000], training loss: 0.0948
16
AVD_Home_008_1_traj5, ate: 264.0590794108603
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[1048/15000], training loss: 0.0962
[1056/15000], training loss: 0.0970
[1064/15000], training loss: 0.0983
[1072/15000], training loss: 0.0907
[1080/15000], training loss: 0.1043
16
AVD_Home_008_1_traj5, ate: 276.5489644504427
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[1088/15000], training loss: 0.1090
[1096/15000], training loss: 0.0958
[1104/15000], training loss: 0.1083
[1112/15000], training loss: 0.0914
[1120/15000], training loss: 0.0969
16
AVD_Home_008_1_traj5, ate: 262.72029200042437
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[1128/15000], training loss: 0.1184
[1136/15000], training loss: 0.0979
[1144/15000], training loss: 0.0962
[1152/15000], training loss: 0.1043
[1160/15000], training loss: 0.1128
16
AVD_Home_008_1_traj5, ate: 262.52807062464944
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[1168/15000], training loss: 0.0944
[1176/15000], training loss: 0.1044
[1184/15000], training loss: 0.0998
[1192/15000], training loss: 0.0974
[1200/15000], training loss: 0.0964
16
AVD_Home_008_1_traj5, ate: 261.6519477271071
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[1208/15000], training loss: 0.0986
[1216/15000], training loss: 0.0934
[1224/15000], training loss: 0.0916
[1232/15000], training loss: 0.0893
[1240/15000], training loss: 0.0935
16
AVD_Home_008_1_traj5, ate: 263.1817368439399
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[1248/15000], training loss: 0.1035
[1256/15000], training loss: 0.0864
[1264/15000], training loss: 0.0929
[1272/15000], training loss: 0.0954
[1280/15000], training loss: 0.0912
16
AVD_Home_008_1_traj5, ate: 256.91947284249994
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[1288/15000], training loss: 0.0923
[1296/15000], training loss: 0.1078
[1304/15000], training loss: 0.0988
[1312/15000], training loss: 0.1023
[1320/15000], training loss: 0.1021
16
AVD_Home_008_1_traj5, ate: 258.90089940659095
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[1328/15000], training loss: 0.0831
[1336/15000], training loss: 0.1011
[1344/15000], training loss: 0.0946
[1352/15000], training loss: 0.1097
[1360/15000], training loss: 0.0882
16
AVD_Home_008_1_traj5, ate: 249.0199924746009
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[1368/15000], training loss: 0.0981
[1376/15000], training loss: 0.0957
[1384/15000], training loss: 0.0910
[1392/15000], training loss: 0.0893
[1400/15000], training loss: 0.1129
16
AVD_Home_008_1_traj5, ate: 251.7078920705709
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[1408/15000], training loss: 0.0914
[1416/15000], training loss: 0.0823
[1424/15000], training loss: 0.1036
[1432/15000], training loss: 0.1068
[1440/15000], training loss: 0.1033
16
AVD_Home_008_1_traj5, ate: 262.53665091868453
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[1448/15000], training loss: 0.0967
[1456/15000], training loss: 0.0933
[1464/15000], training loss: 0.0901
[1472/15000], training loss: 0.0854
[1480/15000], training loss: 0.0835
16
AVD_Home_008_1_traj5, ate: 248.614324116219
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[1488/15000], training loss: 0.0934
[1496/15000], training loss: 0.0851
[1504/15000], training loss: 0.0923
[1512/15000], training loss: 0.0882
[1520/15000], training loss: 0.0876
16
AVD_Home_008_1_traj5, ate: 255.6406683832166
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[1528/15000], training loss: 0.0937
[1536/15000], training loss: 0.0963
[1544/15000], training loss: 0.0964
[1552/15000], training loss: 0.0878
[1560/15000], training loss: 0.0869
16
AVD_Home_008_1_traj5, ate: 253.60029286533947
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[1568/15000], training loss: 0.0961
[1576/15000], training loss: 0.1095
[1584/15000], training loss: 0.0920
[1592/15000], training loss: 0.0855
[1600/15000], training loss: 0.1081
16
AVD_Home_008_1_traj5, ate: 252.4572203855169
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[1608/15000], training loss: 0.0903
[1616/15000], training loss: 0.0834
[1624/15000], training loss: 0.0837
[1632/15000], training loss: 0.1001
[1640/15000], training loss: 0.0876
16
AVD_Home_008_1_traj5, ate: 250.14417358025182
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[1648/15000], training loss: 0.0962
[1656/15000], training loss: 0.1122
[1664/15000], training loss: 0.0943
[1672/15000], training loss: 0.0916
[1680/15000], training loss: 0.0863
16
AVD_Home_008_1_traj5, ate: 251.12146918575823
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[1688/15000], training loss: 0.0953
[1696/15000], training loss: 0.0879
[1704/15000], training loss: 0.0903
[1712/15000], training loss: 0.0965
[1720/15000], training loss: 0.1055
16
AVD_Home_008_1_traj5, ate: 245.57727083140617
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[1728/15000], training loss: 0.0889
[1736/15000], training loss: 0.0824
[1744/15000], training loss: 0.0913
[1752/15000], training loss: 0.1026
[1760/15000], training loss: 0.0838
16
AVD_Home_008_1_traj5, ate: 245.5009128807383
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[1768/15000], training loss: 0.0990
[1776/15000], training loss: 0.0842
[1784/15000], training loss: 0.0897
[1792/15000], training loss: 0.0853
[1800/15000], training loss: 0.1012
16
AVD_Home_008_1_traj5, ate: 245.72176720650248
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[1808/15000], training loss: 0.0975
[1816/15000], training loss: 0.1064
[1824/15000], training loss: 0.1040
[1832/15000], training loss: 0.0993
[1840/15000], training loss: 0.1026
16
AVD_Home_008_1_traj5, ate: 246.81268470191213
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[1848/15000], training loss: 0.1093
[1856/15000], training loss: 0.0920
[1864/15000], training loss: 0.0771
[1872/15000], training loss: 0.0909
[1880/15000], training loss: 0.0915
16
AVD_Home_008_1_traj5, ate: 250.95759433349102
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[1888/15000], training loss: 0.0989
[1896/15000], training loss: 0.0953
[1904/15000], training loss: 0.0820
[1912/15000], training loss: 0.0838
[1920/15000], training loss: 0.0939
16
AVD_Home_008_1_traj5, ate: 248.51461062760902
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[1928/15000], training loss: 0.0938
[1936/15000], training loss: 0.1029
[1944/15000], training loss: 0.1047
[1952/15000], training loss: 0.0962
[1960/15000], training loss: 0.0914
16
AVD_Home_008_1_traj5, ate: 250.6826049735838
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[1968/15000], training loss: 0.1030
[1976/15000], training loss: 0.0997
[1984/15000], training loss: 0.0988
[1992/15000], training loss: 0.1089
[2000/15000], training loss: 0.0840
16
AVD_Home_008_1_traj5, ate: 250.36437786300195
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[2008/15000], training loss: 0.0910
[2016/15000], training loss: 0.1077
[2024/15000], training loss: 0.0819
[2032/15000], training loss: 0.0886
[2040/15000], training loss: 0.1047
16
AVD_Home_008_1_traj5, ate: 251.0081314789029
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[2048/15000], training loss: 0.0883
[2056/15000], training loss: 0.0785
[2064/15000], training loss: 0.0990
[2072/15000], training loss: 0.1033
[2080/15000], training loss: 0.1042
16
AVD_Home_008_1_traj5, ate: 249.70864088516808
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[2088/15000], training loss: 0.1022
[2096/15000], training loss: 0.1018
[2104/15000], training loss: 0.0914
[2112/15000], training loss: 0.0796
[2120/15000], training loss: 0.0965
16
AVD_Home_008_1_traj5, ate: 251.31406888413602
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[2128/15000], training loss: 0.0926
[2136/15000], training loss: 0.0863
[2144/15000], training loss: 0.0912
[2152/15000], training loss: 0.0961
[2160/15000], training loss: 0.0949
16
AVD_Home_008_1_traj5, ate: 252.50252008205428
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[2168/15000], training loss: 0.0745
[2176/15000], training loss: 0.0908
[2184/15000], training loss: 0.0962
[2192/15000], training loss: 0.0831
[2200/15000], training loss: 0.0864
16
AVD_Home_008_1_traj5, ate: 245.48934212806745
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[2208/15000], training loss: 0.0700
[2216/15000], training loss: 0.0796
[2224/15000], training loss: 0.0759
[2232/15000], training loss: 0.0827
[2240/15000], training loss: 0.0883
16
AVD_Home_008_1_traj5, ate: 250.82922113476343
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[2248/15000], training loss: 0.0860
[2256/15000], training loss: 0.0941
[2264/15000], training loss: 0.0920
[2272/15000], training loss: 0.0745
[2280/15000], training loss: 0.0794
16
AVD_Home_008_1_traj5, ate: 252.8511629111039
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[2288/15000], training loss: 0.0900
[2296/15000], training loss: 0.1170
[2304/15000], training loss: 0.1041
[2312/15000], training loss: 0.0798
[2320/15000], training loss: 0.0931
16
AVD_Home_008_1_traj5, ate: 244.5039887969882
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[2328/15000], training loss: 0.0990
[2336/15000], training loss: 0.0927
[2344/15000], training loss: 0.0863
[2352/15000], training loss: 0.0854
[2360/15000], training loss: 0.1012
16
AVD_Home_008_1_traj5, ate: 251.1413583101039
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[2368/15000], training loss: 0.0736
[2376/15000], training loss: 0.0955
[2384/15000], training loss: 0.0948
[2392/15000], training loss: 0.0824
[2400/15000], training loss: 0.0791
16
AVD_Home_008_1_traj5, ate: 248.94272323801218
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[2408/15000], training loss: 0.0842
[2416/15000], training loss: 0.0763
[2424/15000], training loss: 0.0910
[2432/15000], training loss: 0.0894
[2440/15000], training loss: 0.0886
16
AVD_Home_008_1_traj5, ate: 249.50432124383147
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[2448/15000], training loss: 0.0902
[2456/15000], training loss: 0.0821
[2464/15000], training loss: 0.0966
[2472/15000], training loss: 0.0712
[2480/15000], training loss: 0.0835
16
AVD_Home_008_1_traj5, ate: 251.667142878488
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[2488/15000], training loss: 0.0873
[2496/15000], training loss: 0.0908
[2504/15000], training loss: 0.0914
[2512/15000], training loss: 0.0895
[2520/15000], training loss: 0.0880
16
AVD_Home_008_1_traj5, ate: 250.21101461535312
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[2528/15000], training loss: 0.0875
[2536/15000], training loss: 0.0802
[2544/15000], training loss: 0.0819
[2552/15000], training loss: 0.0779
[2560/15000], training loss: 0.0835
16
AVD_Home_008_1_traj5, ate: 245.70977660246527
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[2568/15000], training loss: 0.0923
[2576/15000], training loss: 0.0790
[2584/15000], training loss: 0.0939
[2592/15000], training loss: 0.0968
[2600/15000], training loss: 0.0877
16
AVD_Home_008_1_traj5, ate: 244.91631053537162
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[2608/15000], training loss: 0.0875
[2616/15000], training loss: 0.0840
[2624/15000], training loss: 0.0798
[2632/15000], training loss: 0.0878
[2640/15000], training loss: 0.0920
16
AVD_Home_008_1_traj5, ate: 252.07984849545153
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[2648/15000], training loss: 0.0791
[2656/15000], training loss: 0.1057
[2664/15000], training loss: 0.0911
[2672/15000], training loss: 0.0867
[2680/15000], training loss: 0.0988
16
AVD_Home_008_1_traj5, ate: 247.53926613455857
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[2688/15000], training loss: 0.0966
[2696/15000], training loss: 0.0942
[2704/15000], training loss: 0.0774
[2712/15000], training loss: 0.0983
[2720/15000], training loss: 0.1087
16
AVD_Home_008_1_traj5, ate: 250.0218121008992
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[2728/15000], training loss: 0.0819
[2736/15000], training loss: 0.0803
[2744/15000], training loss: 0.0748
[2752/15000], training loss: 0.1037
[2760/15000], training loss: 0.1010
16
AVD_Home_008_1_traj5, ate: 248.2913533091574
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[2768/15000], training loss: 0.0829
[2776/15000], training loss: 0.0855
[2784/15000], training loss: 0.0952
[2792/15000], training loss: 0.0902
[2800/15000], training loss: 0.0751
16
AVD_Home_008_1_traj5, ate: 249.75981378909174
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[2808/15000], training loss: 0.0892
[2816/15000], training loss: 0.0684
[2824/15000], training loss: 0.0733
[2832/15000], training loss: 0.0883
[2840/15000], training loss: 0.0976
16
AVD_Home_008_1_traj5, ate: 251.50789353348847
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[2848/15000], training loss: 0.0714
[2856/15000], training loss: 0.0728
[2864/15000], training loss: 0.0938
[2872/15000], training loss: 0.0819
[2880/15000], training loss: 0.0843
16
AVD_Home_008_1_traj5, ate: 248.78426818431555
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[2888/15000], training loss: 0.0827
[2896/15000], training loss: 0.1024
[2904/15000], training loss: 0.0841
[2912/15000], training loss: 0.0717
[2920/15000], training loss: 0.0971
16
AVD_Home_008_1_traj5, ate: 244.07925306415746
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[2928/15000], training loss: 0.0857
[2936/15000], training loss: 0.0727
[2944/15000], training loss: 0.0865
[2952/15000], training loss: 0.0910
[2960/15000], training loss: 0.0856
16
AVD_Home_008_1_traj5, ate: 254.37861382015083
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[2968/15000], training loss: 0.0961
[2976/15000], training loss: 0.1094
[2984/15000], training loss: 0.0875
[2992/15000], training loss: 0.0817
[3000/15000], training loss: 0.0757
16
AVD_Home_008_1_traj5, ate: 253.10014575260783
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[3008/15000], training loss: 0.0698
[3016/15000], training loss: 0.0747
[3024/15000], training loss: 0.0729
[3032/15000], training loss: 0.0715
[3040/15000], training loss: 0.0831
16
AVD_Home_008_1_traj5, ate: 250.5214918378554
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[3048/15000], training loss: 0.0744
[3056/15000], training loss: 0.0712
[3064/15000], training loss: 0.0926
[3072/15000], training loss: 0.0949
[3080/15000], training loss: 0.0921
16
AVD_Home_008_1_traj5, ate: 249.17544058550942
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[3088/15000], training loss: 0.0954
[3096/15000], training loss: 0.0757
[3104/15000], training loss: 0.0812
[3112/15000], training loss: 0.0792
[3120/15000], training loss: 0.0773
16
AVD_Home_008_1_traj5, ate: 248.98827640760027
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[3128/15000], training loss: 0.0727
[3136/15000], training loss: 0.0598
[3144/15000], training loss: 0.0786
[3152/15000], training loss: 0.0885
[3160/15000], training loss: 0.0870
16
AVD_Home_008_1_traj5, ate: 251.21230026607566
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[3168/15000], training loss: 0.0769
[3176/15000], training loss: 0.0635
[3184/15000], training loss: 0.1026
[3192/15000], training loss: 0.0802
[3200/15000], training loss: 0.0747
16
AVD_Home_008_1_traj5, ate: 252.36525009331956
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[3208/15000], training loss: 0.0690
[3216/15000], training loss: 0.1045
[3224/15000], training loss: 0.0978
[3232/15000], training loss: 0.0911
[3240/15000], training loss: 0.0811
16
AVD_Home_008_1_traj5, ate: 247.40364351704787
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[3248/15000], training loss: 0.0735
[3256/15000], training loss: 0.0734
[3264/15000], training loss: 0.0873
[3272/15000], training loss: 0.0851
[3280/15000], training loss: 0.0627
16
AVD_Home_008_1_traj5, ate: 249.5722101120149
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[3288/15000], training loss: 0.0746
[3296/15000], training loss: 0.0870
[3304/15000], training loss: 0.0712
[3312/15000], training loss: 0.0837
[3320/15000], training loss: 0.0773
16
AVD_Home_008_1_traj5, ate: 251.41329585874945
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[3328/15000], training loss: 0.0835
[3336/15000], training loss: 0.0718
[3344/15000], training loss: 0.0883
[3352/15000], training loss: 0.0845
[3360/15000], training loss: 0.0876
16
AVD_Home_008_1_traj5, ate: 250.61562148969142
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[3368/15000], training loss: 0.0884
[3376/15000], training loss: 0.0685
[3384/15000], training loss: 0.0734
[3392/15000], training loss: 0.0901
[3400/15000], training loss: 0.0756
16
AVD_Home_008_1_traj5, ate: 250.2509270684545
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[3408/15000], training loss: 0.0716
[3416/15000], training loss: 0.0763
[3424/15000], training loss: 0.0802
[3432/15000], training loss: 0.0871
[3440/15000], training loss: 0.0828
16
AVD_Home_008_1_traj5, ate: 247.12727155518937
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[3448/15000], training loss: 0.0925
[3456/15000], training loss: 0.1194
[3464/15000], training loss: 0.0822
[3472/15000], training loss: 0.0887
[3480/15000], training loss: 0.0730
16
AVD_Home_008_1_traj5, ate: 249.34776340977544
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[3488/15000], training loss: 0.0833
[3496/15000], training loss: 0.0968
[3504/15000], training loss: 0.0907
[3512/15000], training loss: 0.0658
[3520/15000], training loss: 0.0641
16
AVD_Home_008_1_traj5, ate: 246.31979962358457
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[3528/15000], training loss: 0.0725
[3536/15000], training loss: 0.0703
[3544/15000], training loss: 0.0872
[3552/15000], training loss: 0.0788
[3560/15000], training loss: 0.1028
16
AVD_Home_008_1_traj5, ate: 252.63858430397266
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[3568/15000], training loss: 0.0819
[3576/15000], training loss: 0.0806
[3584/15000], training loss: 0.0767
[3592/15000], training loss: 0.0806
[3600/15000], training loss: 0.0796
16
AVD_Home_008_1_traj5, ate: 253.74097142474966
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[3608/15000], training loss: 0.0795
[3616/15000], training loss: 0.0759
[3624/15000], training loss: 0.0851
[3632/15000], training loss: 0.0836
[3640/15000], training loss: 0.0877
16
AVD_Home_008_1_traj5, ate: 246.12930194839572
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[3648/15000], training loss: 0.0802
[3656/15000], training loss: 0.0869
[3664/15000], training loss: 0.0783
[3672/15000], training loss: 0.0853
[3680/15000], training loss: 0.0878
16
AVD_Home_008_1_traj5, ate: 249.72058808306275
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[3688/15000], training loss: 0.0691
[3696/15000], training loss: 0.0840
[3704/15000], training loss: 0.0864
[3712/15000], training loss: 0.0834
[3720/15000], training loss: 0.0770
16
AVD_Home_008_1_traj5, ate: 246.8221469049387
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[3728/15000], training loss: 0.0744
[3736/15000], training loss: 0.0726
[3744/15000], training loss: 0.0749
[3752/15000], training loss: 0.0699
[3760/15000], training loss: 0.0714
16
AVD_Home_008_1_traj5, ate: 249.12520909323106
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[3768/15000], training loss: 0.0702
[3776/15000], training loss: 0.0639
[3784/15000], training loss: 0.0765
[3792/15000], training loss: 0.0703
[3800/15000], training loss: 0.0703
16
AVD_Home_008_1_traj5, ate: 247.59364314823594
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[3808/15000], training loss: 0.0826
[3816/15000], training loss: 0.0823
[3824/15000], training loss: 0.0755
[3832/15000], training loss: 0.0720
[3840/15000], training loss: 0.0921
16
AVD_Home_008_1_traj5, ate: 247.85616202602228
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[3848/15000], training loss: 0.0815
[3856/15000], training loss: 0.0782
[3864/15000], training loss: 0.0719
[3872/15000], training loss: 0.0954
[3880/15000], training loss: 0.0859
16
AVD_Home_008_1_traj5, ate: 248.2409739465853
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[3888/15000], training loss: 0.0690
[3896/15000], training loss: 0.0689
[3904/15000], training loss: 0.0824
[3912/15000], training loss: 0.0730
[3920/15000], training loss: 0.1024
16
AVD_Home_008_1_traj5, ate: 248.76303178004196
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[3928/15000], training loss: 0.1000
[3936/15000], training loss: 0.0889
[3944/15000], training loss: 0.1070
[3952/15000], training loss: 0.0769
[3960/15000], training loss: 0.0703
16
AVD_Home_008_1_traj5, ate: 246.95617374309862
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[3968/15000], training loss: 0.0868
[3976/15000], training loss: 0.0972
[3984/15000], training loss: 0.0744
[3992/15000], training loss: 0.0685
[4000/15000], training loss: 0.0791
16
AVD_Home_008_1_traj5, ate: 248.3722119695059
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[4008/15000], training loss: 0.0691
[4016/15000], training loss: 0.0776
[4024/15000], training loss: 0.0759
[4032/15000], training loss: 0.0796
[4040/15000], training loss: 0.0807
16
AVD_Home_008_1_traj5, ate: 247.031962440003
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[4048/15000], training loss: 0.0663
[4056/15000], training loss: 0.0841
[4064/15000], training loss: 0.0757
[4072/15000], training loss: 0.0881
[4080/15000], training loss: 0.0616
16
AVD_Home_008_1_traj5, ate: 248.35850059294245
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[4088/15000], training loss: 0.0772
[4096/15000], training loss: 0.0670
[4104/15000], training loss: 0.0807
[4112/15000], training loss: 0.0845
[4120/15000], training loss: 0.0929
16
AVD_Home_008_1_traj5, ate: 246.35321083279467
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[4128/15000], training loss: 0.0664
[4136/15000], training loss: 0.0701
[4144/15000], training loss: 0.0804
[4152/15000], training loss: 0.0937
[4160/15000], training loss: 0.0738
16
AVD_Home_008_1_traj5, ate: 248.94271498546186
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[4168/15000], training loss: 0.0655
[4176/15000], training loss: 0.0797
[4184/15000], training loss: 0.0761
[4192/15000], training loss: 0.0623
[4200/15000], training loss: 0.0751
16
AVD_Home_008_1_traj5, ate: 247.15412516860064
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[4208/15000], training loss: 0.0814
[4216/15000], training loss: 0.0692
[4224/15000], training loss: 0.0795
[4232/15000], training loss: 0.0867
[4240/15000], training loss: 0.0653
16
AVD_Home_008_1_traj5, ate: 250.30289562000712
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[4248/15000], training loss: 0.1228
[4256/15000], training loss: 0.0949
[4264/15000], training loss: 0.0951
[4272/15000], training loss: 0.0971
[4280/15000], training loss: 0.1282
16
AVD_Home_008_1_traj5, ate: 247.13710749378942
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[4288/15000], training loss: 0.0767
[4296/15000], training loss: 0.0847
[4304/15000], training loss: 0.0861
[4312/15000], training loss: 0.0887
[4320/15000], training loss: 0.0859
16
AVD_Home_008_1_traj5, ate: 246.5621946903982
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[4328/15000], training loss: 0.0737
[4336/15000], training loss: 0.0782
[4344/15000], training loss: 0.0789
[4352/15000], training loss: 0.0761
[4360/15000], training loss: 0.0721
16
AVD_Home_008_1_traj5, ate: 248.28812933706033
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[4368/15000], training loss: 0.0880
[4376/15000], training loss: 0.0725
[4384/15000], training loss: 0.0742
[4392/15000], training loss: 0.0716
[4400/15000], training loss: 0.0727
16
AVD_Home_008_1_traj5, ate: 248.61754084075855
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[4408/15000], training loss: 0.0755
[4416/15000], training loss: 0.0742
[4424/15000], training loss: 0.0725
[4432/15000], training loss: 0.0776
[4440/15000], training loss: 0.0837
16
AVD_Home_008_1_traj5, ate: 248.97760123357148
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[4448/15000], training loss: 0.0763
[4456/15000], training loss: 0.0760
[4464/15000], training loss: 0.1029
[4472/15000], training loss: 0.0830
[4480/15000], training loss: 0.0887
16
AVD_Home_008_1_traj5, ate: 247.45924467513882
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[4488/15000], training loss: 0.0855
[4496/15000], training loss: 0.1189
[4504/15000], training loss: 0.0966
[4512/15000], training loss: 0.0759
[4520/15000], training loss: 0.0707
16
AVD_Home_008_1_traj5, ate: 244.82673569382933
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[4528/15000], training loss: 0.0668
[4536/15000], training loss: 0.0638
[4544/15000], training loss: 0.0752
[4552/15000], training loss: 0.0617
[4560/15000], training loss: 0.0864
16
AVD_Home_008_1_traj5, ate: 245.8343197265969
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[4568/15000], training loss: 0.0716
[4576/15000], training loss: 0.0871
[4584/15000], training loss: 0.0855
[4592/15000], training loss: 0.0678
[4600/15000], training loss: 0.0740
16
AVD_Home_008_1_traj5, ate: 252.57368189915
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[4608/15000], training loss: 0.0730
[4616/15000], training loss: 0.0638
[4624/15000], training loss: 0.0708
[4632/15000], training loss: 0.0787
[4640/15000], training loss: 0.0855
16
AVD_Home_008_1_traj5, ate: 254.6777863777386
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[4648/15000], training loss: 0.0892
[4656/15000], training loss: 0.0780
[4664/15000], training loss: 0.0962
[4672/15000], training loss: 0.0746
[4680/15000], training loss: 0.0801
16
AVD_Home_008_1_traj5, ate: 247.255566539703
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[4688/15000], training loss: 0.0859
[4696/15000], training loss: 0.0886
[4704/15000], training loss: 0.0805
[4712/15000], training loss: 0.0612
[4720/15000], training loss: 0.0564
16
AVD_Home_008_1_traj5, ate: 247.87426531492213
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[4728/15000], training loss: 0.0845
[4736/15000], training loss: 0.0991
[4744/15000], training loss: 0.0719
[4752/15000], training loss: 0.0730
[4760/15000], training loss: 0.0878
16
AVD_Home_008_1_traj5, ate: 245.4256688171758
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[4768/15000], training loss: 0.0727
[4776/15000], training loss: 0.0593
[4784/15000], training loss: 0.1019
[4792/15000], training loss: 0.0786
[4800/15000], training loss: 0.0761
16
AVD_Home_008_1_traj5, ate: 248.18485341180042
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[4808/15000], training loss: 0.0734
[4816/15000], training loss: 0.0790
[4824/15000], training loss: 0.1065
[4832/15000], training loss: 0.0679
[4840/15000], training loss: 0.0842
16
AVD_Home_008_1_traj5, ate: 247.90923158671552
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[4848/15000], training loss: 0.0905
[4856/15000], training loss: 0.0739
[4864/15000], training loss: 0.0620
[4872/15000], training loss: 0.0831
[4880/15000], training loss: 0.0709
16
AVD_Home_008_1_traj5, ate: 252.43557362292336
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[4888/15000], training loss: 0.0768
[4896/15000], training loss: 0.0624
[4904/15000], training loss: 0.0697
[4912/15000], training loss: 0.0710
[4920/15000], training loss: 0.0721
16
AVD_Home_008_1_traj5, ate: 244.81088190163726
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[4928/15000], training loss: 0.1090
[4936/15000], training loss: 0.0770
[4944/15000], training loss: 0.0998
[4952/15000], training loss: 0.0683
[4960/15000], training loss: 0.0795
16
AVD_Home_008_1_traj5, ate: 248.5483807372227
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[4968/15000], training loss: 0.0885
[4976/15000], training loss: 0.0988
[4984/15000], training loss: 0.0770
[4992/15000], training loss: 0.0586
[5000/15000], training loss: 0.0885
16
AVD_Home_008_1_traj5, ate: 249.1603678079033
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[5008/15000], training loss: 0.0768
[5016/15000], training loss: 0.0749
[5024/15000], training loss: 0.0799
[5032/15000], training loss: 0.0645
[5040/15000], training loss: 0.0687
16
AVD_Home_008_1_traj5, ate: 250.3143206440447
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[5048/15000], training loss: 0.0837
[5056/15000], training loss: 0.0925
[5064/15000], training loss: 0.0688
[5072/15000], training loss: 0.0658
[5080/15000], training loss: 0.0719
16
AVD_Home_008_1_traj5, ate: 249.3503639861595
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[5088/15000], training loss: 0.0738
[5096/15000], training loss: 0.0702
[5104/15000], training loss: 0.0628
[5112/15000], training loss: 0.0906
[5120/15000], training loss: 0.0878
16
AVD_Home_008_1_traj5, ate: 249.3279435624535
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[5128/15000], training loss: 0.0819
[5136/15000], training loss: 0.1015
[5144/15000], training loss: 0.0711
[5152/15000], training loss: 0.0755
[5160/15000], training loss: 0.0771
16
AVD_Home_008_1_traj5, ate: 249.13667304913946
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[5168/15000], training loss: 0.0683
[5176/15000], training loss: 0.0770
[5184/15000], training loss: 0.0856
[5192/15000], training loss: 0.0976
[5200/15000], training loss: 0.0880
16
AVD_Home_008_1_traj5, ate: 244.3685509982516
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[5208/15000], training loss: 0.0912
[5216/15000], training loss: 0.0735
[5224/15000], training loss: 0.0946
[5232/15000], training loss: 0.0578
[5240/15000], training loss: 0.0819
16
AVD_Home_008_1_traj5, ate: 248.47735865346348
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[5248/15000], training loss: 0.0768
[5256/15000], training loss: 0.0677
[5264/15000], training loss: 0.0721
[5272/15000], training loss: 0.0906
[5280/15000], training loss: 0.0854
16
AVD_Home_008_1_traj5, ate: 249.19290828485535
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[5288/15000], training loss: 0.0761
[5296/15000], training loss: 0.0802
[5304/15000], training loss: 0.1266
[5312/15000], training loss: 0.0599
[5320/15000], training loss: 0.0863
16
AVD_Home_008_1_traj5, ate: 248.58694422367455
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[5328/15000], training loss: 0.1046
[5336/15000], training loss: 0.0814
[5344/15000], training loss: 0.0666
[5352/15000], training loss: 0.0877
[5360/15000], training loss: 0.0821
16
AVD_Home_008_1_traj5, ate: 250.19218563903112
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[5368/15000], training loss: 0.0893
[5376/15000], training loss: 0.0688
[5384/15000], training loss: 0.0901
[5392/15000], training loss: 0.0630
[5400/15000], training loss: 0.0807
16
AVD_Home_008_1_traj5, ate: 246.66670799281303
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[5408/15000], training loss: 0.0860
[5416/15000], training loss: 0.0857
[5424/15000], training loss: 0.0845
[5432/15000], training loss: 0.0669
[5440/15000], training loss: 0.0786
16
AVD_Home_008_1_traj5, ate: 248.56803946634687
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[5448/15000], training loss: 0.1016
[5456/15000], training loss: 0.0834
[5464/15000], training loss: 0.0854
[5472/15000], training loss: 0.0720
[5480/15000], training loss: 0.0876
16
AVD_Home_008_1_traj5, ate: 249.61349190999715
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[5488/15000], training loss: 0.0809
[5496/15000], training loss: 0.0689
[5504/15000], training loss: 0.0789
[5512/15000], training loss: 0.0678
[5520/15000], training loss: 0.0807
16
AVD_Home_008_1_traj5, ate: 249.50853571237323
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[5528/15000], training loss: 0.0895
[5536/15000], training loss: 0.0843
[5544/15000], training loss: 0.0610
[5552/15000], training loss: 0.0726
[5560/15000], training loss: 0.0826
16
AVD_Home_008_1_traj5, ate: 246.2496264782515
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[5568/15000], training loss: 0.0722
[5576/15000], training loss: 0.0767
[5584/15000], training loss: 0.0877
[5592/15000], training loss: 0.0830
[5600/15000], training loss: 0.0709
16
AVD_Home_008_1_traj5, ate: 248.74748257432833
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[5608/15000], training loss: 0.0683
[5616/15000], training loss: 0.0593
[5624/15000], training loss: 0.0966
[5632/15000], training loss: 0.0916
[5640/15000], training loss: 0.0707
16
AVD_Home_008_1_traj5, ate: 246.4404152409661
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[5648/15000], training loss: 0.0714
[5656/15000], training loss: 0.0854
[5664/15000], training loss: 0.0953
[5672/15000], training loss: 0.0756
[5680/15000], training loss: 0.0629
16
AVD_Home_008_1_traj5, ate: 249.26641689590926
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[5688/15000], training loss: 0.0750
[5696/15000], training loss: 0.0880
[5704/15000], training loss: 0.0707
[5712/15000], training loss: 0.0818
[5720/15000], training loss: 0.0779
16
AVD_Home_008_1_traj5, ate: 249.333053554062
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[5728/15000], training loss: 0.0729
[5736/15000], training loss: 0.0726
[5744/15000], training loss: 0.0797
[5752/15000], training loss: 0.0824
[5760/15000], training loss: 0.0658
16
AVD_Home_008_1_traj5, ate: 249.44516623802045
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[5768/15000], training loss: 0.0922
[5776/15000], training loss: 0.0763
[5784/15000], training loss: 0.0720
[5792/15000], training loss: 0.0675
[5800/15000], training loss: 0.0784
16
AVD_Home_008_1_traj5, ate: 246.9844891811511
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[5808/15000], training loss: 0.0745
[5816/15000], training loss: 0.0842
[5824/15000], training loss: 0.0600
[5832/15000], training loss: 0.0724
[5840/15000], training loss: 0.0663
16
AVD_Home_008_1_traj5, ate: 247.26686784956397
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[5848/15000], training loss: 0.0723
[5856/15000], training loss: 0.0691
[5864/15000], training loss: 0.1061
[5872/15000], training loss: 0.0712
[5880/15000], training loss: 0.0627
16
AVD_Home_008_1_traj5, ate: 250.42851124050577
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[5888/15000], training loss: 0.0664
[5896/15000], training loss: 0.0694
[5904/15000], training loss: 0.0632
[5912/15000], training loss: 0.0638
[5920/15000], training loss: 0.0715
16
AVD_Home_008_1_traj5, ate: 247.769230071709
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[5928/15000], training loss: 0.0920
[5936/15000], training loss: 0.1123
[5944/15000], training loss: 0.0739
[5952/15000], training loss: 0.0845
[5960/15000], training loss: 0.0873
16
AVD_Home_008_1_traj5, ate: 244.81771233960905
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[5968/15000], training loss: 0.0733
[5976/15000], training loss: 0.0803
[5984/15000], training loss: 0.0670
[5992/15000], training loss: 0.0616
[6000/15000], training loss: 0.0690
16
AVD_Home_008_1_traj5, ate: 247.4584782347724
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[6008/15000], training loss: 0.0618
[6016/15000], training loss: 0.0797
[6024/15000], training loss: 0.0783
[6032/15000], training loss: 0.0760
[6040/15000], training loss: 0.0739
16
AVD_Home_008_1_traj5, ate: 246.5697072206515
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[6048/15000], training loss: 0.0949
[6056/15000], training loss: 0.0617
[6064/15000], training loss: 0.0784
[6072/15000], training loss: 0.0765
[6080/15000], training loss: 0.0759
16
AVD_Home_008_1_traj5, ate: 247.21068351866458
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[6088/15000], training loss: 0.0650
[6096/15000], training loss: 0.0614
[6104/15000], training loss: 0.0765
[6112/15000], training loss: 0.0733
[6120/15000], training loss: 0.0872
16
AVD_Home_008_1_traj5, ate: 247.33796126324825
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[6128/15000], training loss: 0.0982
[6136/15000], training loss: 0.0734
[6144/15000], training loss: 0.0829
[6152/15000], training loss: 0.0595
[6160/15000], training loss: 0.0837
16
AVD_Home_008_1_traj5, ate: 250.92457731669276
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[6168/15000], training loss: 0.0617
[6176/15000], training loss: 0.0650
[6184/15000], training loss: 0.0695
[6192/15000], training loss: 0.0747
[6200/15000], training loss: 0.0657
16
AVD_Home_008_1_traj5, ate: 247.65451220956624
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[6208/15000], training loss: 0.0821
[6216/15000], training loss: 0.0575
[6224/15000], training loss: 0.0609
[6232/15000], training loss: 0.0765
[6240/15000], training loss: 0.0682
16
AVD_Home_008_1_traj5, ate: 248.04505979464426
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[6248/15000], training loss: 0.0764
[6256/15000], training loss: 0.0753
[6264/15000], training loss: 0.0566
[6272/15000], training loss: 0.0614
[6280/15000], training loss: 0.0848
16
AVD_Home_008_1_traj5, ate: 248.76256101309423
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[6288/15000], training loss: 0.0930
[6296/15000], training loss: 0.0682
[6304/15000], training loss: 0.0558
[6312/15000], training loss: 0.0802
[6320/15000], training loss: 0.0774
16
AVD_Home_008_1_traj5, ate: 247.26991865994572
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[6328/15000], training loss: 0.0621
[6336/15000], training loss: 0.0778
[6344/15000], training loss: 0.0752
[6352/15000], training loss: 0.0759
[6360/15000], training loss: 0.0579
16
AVD_Home_008_1_traj5, ate: 247.09495029117517
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[6368/15000], training loss: 0.0655
[6376/15000], training loss: 0.0647
[6384/15000], training loss: 0.0675
[6392/15000], training loss: 0.0742
[6400/15000], training loss: 0.0633
16
AVD_Home_008_1_traj5, ate: 248.26816462831442
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[6408/15000], training loss: 0.0709
[6416/15000], training loss: 0.0781
[6424/15000], training loss: 0.0655
[6432/15000], training loss: 0.0747
[6440/15000], training loss: 0.0723
16
AVD_Home_008_1_traj5, ate: 247.98921310672333
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[6448/15000], training loss: 0.0558
[6456/15000], training loss: 0.0663
[6464/15000], training loss: 0.0891
[6472/15000], training loss: 0.0849
[6480/15000], training loss: 0.0815
16
AVD_Home_008_1_traj5, ate: 248.45178795604795
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[6488/15000], training loss: 0.0674
[6496/15000], training loss: 0.0633
[6504/15000], training loss: 0.0721
[6512/15000], training loss: 0.0912
[6520/15000], training loss: 0.0742
16
AVD_Home_008_1_traj5, ate: 246.71453076894457
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[6528/15000], training loss: 0.0786
[6536/15000], training loss: 0.0636
[6544/15000], training loss: 0.0988
[6552/15000], training loss: 0.0547
[6560/15000], training loss: 0.0658
16
AVD_Home_008_1_traj5, ate: 249.91231703531685
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[6568/15000], training loss: 0.0918
[6576/15000], training loss: 0.0726
[6584/15000], training loss: 0.0652
[6592/15000], training loss: 0.0849
[6600/15000], training loss: 0.0774
16
AVD_Home_008_1_traj5, ate: 247.17269007624677
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[6608/15000], training loss: 0.0639
[6616/15000], training loss: 0.0751
[6624/15000], training loss: 0.0671
[6632/15000], training loss: 0.0766
[6640/15000], training loss: 0.0545
16
AVD_Home_008_1_traj5, ate: 246.74377500846728
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[6648/15000], training loss: 0.0927
[6656/15000], training loss: 0.0725
[6664/15000], training loss: 0.0558
[6672/15000], training loss: 0.0652
[6680/15000], training loss: 0.0688
16
AVD_Home_008_1_traj5, ate: 249.13649007763337
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[6688/15000], training loss: 0.0743
[6696/15000], training loss: 0.0552
[6704/15000], training loss: 0.0732
[6712/15000], training loss: 0.0748
[6720/15000], training loss: 0.0830
16
AVD_Home_008_1_traj5, ate: 246.81696012785042
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[6728/15000], training loss: 0.0871
[6736/15000], training loss: 0.0839
[6744/15000], training loss: 0.0741
[6752/15000], training loss: 0.0623
[6760/15000], training loss: 0.0587
16
AVD_Home_008_1_traj5, ate: 248.02863668249884
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[6768/15000], training loss: 0.0778
[6776/15000], training loss: 0.0921
[6784/15000], training loss: 0.0706
[6792/15000], training loss: 0.0584
[6800/15000], training loss: 0.0794
16
AVD_Home_008_1_traj5, ate: 247.69643417104186
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[6808/15000], training loss: 0.0724
[6816/15000], training loss: 0.0556
[6824/15000], training loss: 0.0612
[6832/15000], training loss: 0.0713
[6840/15000], training loss: 0.0660
16
AVD_Home_008_1_traj5, ate: 247.38727259658606
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[6848/15000], training loss: 0.0675
[6856/15000], training loss: 0.0680
[6864/15000], training loss: 0.0843
[6872/15000], training loss: 0.0630
[6880/15000], training loss: 0.0733
16
AVD_Home_008_1_traj5, ate: 248.4597765291859
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[6888/15000], training loss: 0.0717
[6896/15000], training loss: 0.0678
[6904/15000], training loss: 0.0655
[6912/15000], training loss: 0.0728
[6920/15000], training loss: 0.0847
16
AVD_Home_008_1_traj5, ate: 246.58510987057295
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[6928/15000], training loss: 0.0737
[6936/15000], training loss: 0.0630
[6944/15000], training loss: 0.0537
[6952/15000], training loss: 0.0643
[6960/15000], training loss: 0.0702
16
AVD_Home_008_1_traj5, ate: 247.6497677448866
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[6968/15000], training loss: 0.0678
[6976/15000], training loss: 0.0670
[6984/15000], training loss: 0.0678
[6992/15000], training loss: 0.0728
[7000/15000], training loss: 0.0926
16
AVD_Home_008_1_traj5, ate: 247.51044214534872
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[7008/15000], training loss: 0.0653
[7016/15000], training loss: 0.0581
[7024/15000], training loss: 0.0648
[7032/15000], training loss: 0.0554
[7040/15000], training loss: 0.0675
16
AVD_Home_008_1_traj5, ate: 247.8892087070853
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[7048/15000], training loss: 0.0784
[7056/15000], training loss: 0.0719
[7064/15000], training loss: 0.0809
[7072/15000], training loss: 0.0621
[7080/15000], training loss: 0.0637
16
AVD_Home_008_1_traj5, ate: 247.80982869861427
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[7088/15000], training loss: 0.0901
[7096/15000], training loss: 0.0817
[7104/15000], training loss: 0.1048
[7112/15000], training loss: 0.0767
[7120/15000], training loss: 0.0633
16
AVD_Home_008_1_traj5, ate: 248.16052447179234
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[7128/15000], training loss: 0.0729
[7136/15000], training loss: 0.0992
[7144/15000], training loss: 0.0887
[7152/15000], training loss: 0.0629
[7160/15000], training loss: 0.0657
16
AVD_Home_008_1_traj5, ate: 248.792625977229
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[7168/15000], training loss: 0.0738
[7176/15000], training loss: 0.0727
[7184/15000], training loss: 0.0677
[7192/15000], training loss: 0.0814
[7200/15000], training loss: 0.0545
16
AVD_Home_008_1_traj5, ate: 248.27395033731386
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[7208/15000], training loss: 0.0653
[7216/15000], training loss: 0.0647
[7224/15000], training loss: 0.0808
[7232/15000], training loss: 0.0722
[7240/15000], training loss: 0.0666
16
AVD_Home_008_1_traj5, ate: 248.87585598242032
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[7248/15000], training loss: 0.0702
[7256/15000], training loss: 0.0671
[7264/15000], training loss: 0.0590
[7272/15000], training loss: 0.0716
[7280/15000], training loss: 0.0872
16
AVD_Home_008_1_traj5, ate: 247.30670034560822
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[7288/15000], training loss: 0.0848
[7296/15000], training loss: 0.0584
[7304/15000], training loss: 0.0785
[7312/15000], training loss: 0.0807
[7320/15000], training loss: 0.0904
16
AVD_Home_008_1_traj5, ate: 247.19938950198102
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[7328/15000], training loss: 0.0795
[7336/15000], training loss: 0.0730
[7344/15000], training loss: 0.0646
[7352/15000], training loss: 0.0725
[7360/15000], training loss: 0.0701
16
AVD_Home_008_1_traj5, ate: 246.68486599863482
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[7368/15000], training loss: 0.0817
[7376/15000], training loss: 0.0761
[7384/15000], training loss: 0.0663
[7392/15000], training loss: 0.0659
[7400/15000], training loss: 0.0647
16
AVD_Home_008_1_traj5, ate: 246.9611406277604
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[7408/15000], training loss: 0.0557
[7416/15000], training loss: 0.0540
[7424/15000], training loss: 0.0726
[7432/15000], training loss: 0.0807
[7440/15000], training loss: 0.0938
16
AVD_Home_008_1_traj5, ate: 245.9510516741901
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[7448/15000], training loss: 0.0896
[7456/15000], training loss: 0.0697
[7464/15000], training loss: 0.0709
[7472/15000], training loss: 0.0720
[7480/15000], training loss: 0.0623
16
AVD_Home_008_1_traj5, ate: 248.07382598186481
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[7488/15000], training loss: 0.0776
[7496/15000], training loss: 0.0688
[7504/15000], training loss: 0.0737
[7512/15000], training loss: 0.0589
[7520/15000], training loss: 0.0681
16
AVD_Home_008_1_traj5, ate: 247.42105987066034
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[7528/15000], training loss: 0.0822
[7536/15000], training loss: 0.0710
[7544/15000], training loss: 0.0864
[7552/15000], training loss: 0.0742
[7560/15000], training loss: 0.0715
16
AVD_Home_008_1_traj5, ate: 246.3649775483919
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[7568/15000], training loss: 0.0825
[7576/15000], training loss: 0.0808
[7584/15000], training loss: 0.0774
[7592/15000], training loss: 0.0655
[7600/15000], training loss: 0.0684
16
AVD_Home_008_1_traj5, ate: 245.28305119604377
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[7608/15000], training loss: 0.0687
[7616/15000], training loss: 0.0670
[7624/15000], training loss: 0.0734
[7632/15000], training loss: 0.0813
[7640/15000], training loss: 0.0928
16
AVD_Home_008_1_traj5, ate: 245.32965819171383
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[7648/15000], training loss: 0.0665
[7656/15000], training loss: 0.0672
[7664/15000], training loss: 0.0735
[7672/15000], training loss: 0.0740
[7680/15000], training loss: 0.0648
16
AVD_Home_008_1_traj5, ate: 246.8063516373785
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[7688/15000], training loss: 0.0930
[7696/15000], training loss: 0.0748
[7704/15000], training loss: 0.0805
[7712/15000], training loss: 0.0692
[7720/15000], training loss: 0.0645
16
AVD_Home_008_1_traj5, ate: 247.7944126495392
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[7728/15000], training loss: 0.0738
[7736/15000], training loss: 0.0643
[7744/15000], training loss: 0.0539
[7752/15000], training loss: 0.0635
[7760/15000], training loss: 0.0709
16
AVD_Home_008_1_traj5, ate: 247.7868176723306
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[7768/15000], training loss: 0.1078
[7776/15000], training loss: 0.0694
[7784/15000], training loss: 0.0605
[7792/15000], training loss: 0.0869
[7800/15000], training loss: 0.0615
16
AVD_Home_008_1_traj5, ate: 248.45608377615414
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[7808/15000], training loss: 0.0692
[7816/15000], training loss: 0.0739
[7824/15000], training loss: 0.0661
[7832/15000], training loss: 0.0577
[7840/15000], training loss: 0.0746
16
AVD_Home_008_1_traj5, ate: 247.94898800562476
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[7848/15000], training loss: 0.0550
[7856/15000], training loss: 0.0837
[7864/15000], training loss: 0.0897
[7872/15000], training loss: 0.0736
[7880/15000], training loss: 0.0592
16
AVD_Home_008_1_traj5, ate: 247.92853548190809
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[7888/15000], training loss: 0.0766
[7896/15000], training loss: 0.0832
[7904/15000], training loss: 0.0770
[7912/15000], training loss: 0.0554
[7920/15000], training loss: 0.1062
16
AVD_Home_008_1_traj5, ate: 246.55808024945728
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[7928/15000], training loss: 0.0686
[7936/15000], training loss: 0.0825
[7944/15000], training loss: 0.0795
[7952/15000], training loss: 0.0737
[7960/15000], training loss: 0.0733
16
AVD_Home_008_1_traj5, ate: 248.30263818864324
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[7968/15000], training loss: 0.1059
[7976/15000], training loss: 0.0609
[7984/15000], training loss: 0.0639
[7992/15000], training loss: 0.0823
[8000/15000], training loss: 0.0593
16
AVD_Home_008_1_traj5, ate: 248.44597331312121
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[8008/15000], training loss: 0.0780
[8016/15000], training loss: 0.0701
[8024/15000], training loss: 0.0613
[8032/15000], training loss: 0.0758
[8040/15000], training loss: 0.0605
16
AVD_Home_008_1_traj5, ate: 248.3563457996765
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[8048/15000], training loss: 0.0688
[8056/15000], training loss: 0.0709
[8064/15000], training loss: 0.0771
[8072/15000], training loss: 0.0610
[8080/15000], training loss: 0.0714
16
AVD_Home_008_1_traj5, ate: 246.5082471053232
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[8088/15000], training loss: 0.0775
[8096/15000], training loss: 0.0627
[8104/15000], training loss: 0.0883
[8112/15000], training loss: 0.0669
[8120/15000], training loss: 0.0995
16
AVD_Home_008_1_traj5, ate: 248.02271145417697
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[8128/15000], training loss: 0.0836
[8136/15000], training loss: 0.0818
[8144/15000], training loss: 0.0698
[8152/15000], training loss: 0.0714
[8160/15000], training loss: 0.0803
16
AVD_Home_008_1_traj5, ate: 247.38592730826173
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[8168/15000], training loss: 0.1108
[8176/15000], training loss: 0.0674
[8184/15000], training loss: 0.0802
[8192/15000], training loss: 0.1007
[8200/15000], training loss: 0.0633
16
AVD_Home_008_1_traj5, ate: 244.97013527284324
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[8208/15000], training loss: 0.0683
[8216/15000], training loss: 0.0598
[8224/15000], training loss: 0.0591
[8232/15000], training loss: 0.0629
[8240/15000], training loss: 0.0824
16
AVD_Home_008_1_traj5, ate: 246.34013323060734
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[8248/15000], training loss: 0.0622
[8256/15000], training loss: 0.0689
[8264/15000], training loss: 0.0663
[8272/15000], training loss: 0.0684
[8280/15000], training loss: 0.0688
16
AVD_Home_008_1_traj5, ate: 247.52146338508993
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[8288/15000], training loss: 0.0666
[8296/15000], training loss: 0.0751
[8304/15000], training loss: 0.0554
[8312/15000], training loss: 0.0781
[8320/15000], training loss: 0.0768
16
AVD_Home_008_1_traj5, ate: 248.75503473773017
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[8328/15000], training loss: 0.0968
[8336/15000], training loss: 0.0738
[8344/15000], training loss: 0.0929
[8352/15000], training loss: 0.0595
[8360/15000], training loss: 0.0644
16
AVD_Home_008_1_traj5, ate: 246.54693661951436
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[8368/15000], training loss: 0.0710
[8376/15000], training loss: 0.0626
[8384/15000], training loss: 0.0960
[8392/15000], training loss: 0.0681
[8400/15000], training loss: 0.0557
16
AVD_Home_008_1_traj5, ate: 247.18783077668925
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[8408/15000], training loss: 0.0796
[8416/15000], training loss: 0.0707
[8424/15000], training loss: 0.0693
[8432/15000], training loss: 0.0735
[8440/15000], training loss: 0.0639
16
AVD_Home_008_1_traj5, ate: 246.99544064777527
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[8448/15000], training loss: 0.0753
[8456/15000], training loss: 0.0583
[8464/15000], training loss: 0.0579
[8472/15000], training loss: 0.0695
[8480/15000], training loss: 0.0715
16
AVD_Home_008_1_traj5, ate: 247.47596397507562
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[8488/15000], training loss: 0.0829
[8496/15000], training loss: 0.0600
[8504/15000], training loss: 0.0745
[8512/15000], training loss: 0.0543
[8520/15000], training loss: 0.0886
16
AVD_Home_008_1_traj5, ate: 247.86448162422698
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[8528/15000], training loss: 0.0693
[8536/15000], training loss: 0.0615
[8544/15000], training loss: 0.0616
[8552/15000], training loss: 0.0719
[8560/15000], training loss: 0.0724
16
AVD_Home_008_1_traj5, ate: 247.36628739625954
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[8568/15000], training loss: 0.0580
[8576/15000], training loss: 0.0946
[8584/15000], training loss: 0.0595
[8592/15000], training loss: 0.0680
[8600/15000], training loss: 0.0699
16
AVD_Home_008_1_traj5, ate: 246.13071584901647
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[8608/15000], training loss: 0.0622
[8616/15000], training loss: 0.0629
[8624/15000], training loss: 0.0596
[8632/15000], training loss: 0.0678
[8640/15000], training loss: 0.0672
16
AVD_Home_008_1_traj5, ate: 245.88150561533507
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[8648/15000], training loss: 0.0642
[8656/15000], training loss: 0.0642
[8664/15000], training loss: 0.0809
[8672/15000], training loss: 0.0589
[8680/15000], training loss: 0.0872
16
AVD_Home_008_1_traj5, ate: 245.62735927852714
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[8688/15000], training loss: 0.0686
[8696/15000], training loss: 0.0596
[8704/15000], training loss: 0.0645
[8712/15000], training loss: 0.0790
[8720/15000], training loss: 0.0651
16
AVD_Home_008_1_traj5, ate: 248.25848254234796
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[8728/15000], training loss: 0.0589
[8736/15000], training loss: 0.0704
[8744/15000], training loss: 0.0673
[8752/15000], training loss: 0.0694
[8760/15000], training loss: 0.0790
16
AVD_Home_008_1_traj5, ate: 247.01638736206468
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[8768/15000], training loss: 0.0800
[8776/15000], training loss: 0.0555
[8784/15000], training loss: 0.0651
[8792/15000], training loss: 0.0560
[8800/15000], training loss: 0.0773
16
AVD_Home_008_1_traj5, ate: 245.83418405463374
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[8808/15000], training loss: 0.0791
[8816/15000], training loss: 0.0654
[8824/15000], training loss: 0.0752
[8832/15000], training loss: 0.0642
[8840/15000], training loss: 0.0791
16
AVD_Home_008_1_traj5, ate: 244.57705972611342
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[8848/15000], training loss: 0.0727
[8856/15000], training loss: 0.0586
[8864/15000], training loss: 0.0686
[8872/15000], training loss: 0.0577
[8880/15000], training loss: 0.0688
16
AVD_Home_008_1_traj5, ate: 246.514609164048
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[8888/15000], training loss: 0.0805
[8896/15000], training loss: 0.0906
[8904/15000], training loss: 0.0975
[8912/15000], training loss: 0.0926
[8920/15000], training loss: 0.0792
16
AVD_Home_008_1_traj5, ate: 247.00952333444863
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[8928/15000], training loss: 0.0744
[8936/15000], training loss: 0.0562
[8944/15000], training loss: 0.0672
[8952/15000], training loss: 0.0801
[8960/15000], training loss: 0.0588
16
AVD_Home_008_1_traj5, ate: 246.1609143843597
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[8968/15000], training loss: 0.0689
[8976/15000], training loss: 0.0681
[8984/15000], training loss: 0.0588
[8992/15000], training loss: 0.0651
[9000/15000], training loss: 0.0749
16
AVD_Home_008_1_traj5, ate: 246.9276947307215
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[9008/15000], training loss: 0.0621
[9016/15000], training loss: 0.0654
[9024/15000], training loss: 0.0637
[9032/15000], training loss: 0.0653
[9040/15000], training loss: 0.0660
16
AVD_Home_008_1_traj5, ate: 246.60244546817626
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[9048/15000], training loss: 0.0801
[9056/15000], training loss: 0.0819
[9064/15000], training loss: 0.0640
[9072/15000], training loss: 0.0658
[9080/15000], training loss: 0.0654
16
AVD_Home_008_1_traj5, ate: 247.65554306208463
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[9088/15000], training loss: 0.0576
[9096/15000], training loss: 0.0597
[9104/15000], training loss: 0.0636
[9112/15000], training loss: 0.0684
[9120/15000], training loss: 0.0753
16
AVD_Home_008_1_traj5, ate: 246.7183713702146
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[9128/15000], training loss: 0.0729
[9136/15000], training loss: 0.0738
[9144/15000], training loss: 0.0607
[9152/15000], training loss: 0.0845
[9160/15000], training loss: 0.0580
16
AVD_Home_008_1_traj5, ate: 246.71331476746548
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[9168/15000], training loss: 0.0580
[9176/15000], training loss: 0.0736
[9184/15000], training loss: 0.0642
[9192/15000], training loss: 0.0606
[9200/15000], training loss: 0.0572
16
AVD_Home_008_1_traj5, ate: 246.96086492056799
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[9208/15000], training loss: 0.0734
[9216/15000], training loss: 0.0660
[9224/15000], training loss: 0.0628
[9232/15000], training loss: 0.0697
[9240/15000], training loss: 0.0647
16
AVD_Home_008_1_traj5, ate: 246.5754434720784
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[9248/15000], training loss: 0.1020
[9256/15000], training loss: 0.0844
[9264/15000], training loss: 0.0688
[9272/15000], training loss: 0.0557
[9280/15000], training loss: 0.0664
16
AVD_Home_008_1_traj5, ate: 246.72752672364848
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[9288/15000], training loss: 0.0621
[9296/15000], training loss: 0.0608
[9304/15000], training loss: 0.0542
[9312/15000], training loss: 0.0627
[9320/15000], training loss: 0.0602
16
AVD_Home_008_1_traj5, ate: 245.8827488776805
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[9328/15000], training loss: 0.0865
[9336/15000], training loss: 0.0810
[9344/15000], training loss: 0.0609
[9352/15000], training loss: 0.0614
[9360/15000], training loss: 0.0632
16
AVD_Home_008_1_traj5, ate: 245.489649261893
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[9368/15000], training loss: 0.0590
[9376/15000], training loss: 0.0579
[9384/15000], training loss: 0.0792
[9392/15000], training loss: 0.0574
[9400/15000], training loss: 0.0770
16
AVD_Home_008_1_traj5, ate: 248.0046776660065
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[9408/15000], training loss: 0.0793
[9416/15000], training loss: 0.0710
[9424/15000], training loss: 0.0600
[9432/15000], training loss: 0.0739
[9440/15000], training loss: 0.0575
16
AVD_Home_008_1_traj5, ate: 246.5075107614117
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[9448/15000], training loss: 0.0638
[9456/15000], training loss: 0.0600
[9464/15000], training loss: 0.0599
[9472/15000], training loss: 0.0764
[9480/15000], training loss: 0.0792
16
AVD_Home_008_1_traj5, ate: 246.70260213408517
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[9488/15000], training loss: 0.0552
[9496/15000], training loss: 0.0640
[9504/15000], training loss: 0.0604
[9512/15000], training loss: 0.0617
[9520/15000], training loss: 0.0723
16
AVD_Home_008_1_traj5, ate: 247.83746917455474
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[9528/15000], training loss: 0.0670
[9536/15000], training loss: 0.0686
[9544/15000], training loss: 0.0569
[9552/15000], training loss: 0.0741
[9560/15000], training loss: 0.0809
16
AVD_Home_008_1_traj5, ate: 247.3709689844109
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[9568/15000], training loss: 0.0754
[9576/15000], training loss: 0.0802
[9584/15000], training loss: 0.0653
[9592/15000], training loss: 0.0682
[9600/15000], training loss: 0.0768
16
AVD_Home_008_1_traj5, ate: 247.1561758179415
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[9608/15000], training loss: 0.0650
[9616/15000], training loss: 0.0645
[9624/15000], training loss: 0.0591
[9632/15000], training loss: 0.0637
[9640/15000], training loss: 0.0677
16
AVD_Home_008_1_traj5, ate: 246.5022132106334
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[9648/15000], training loss: 0.0757
[9656/15000], training loss: 0.0546
[9664/15000], training loss: 0.0721
[9672/15000], training loss: 0.0789
[9680/15000], training loss: 0.0560
16
AVD_Home_008_1_traj5, ate: 246.77721033577131
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[9688/15000], training loss: 0.0667
[9696/15000], training loss: 0.0571
[9704/15000], training loss: 0.0887
[9712/15000], training loss: 0.0591
[9720/15000], training loss: 0.0572
16
AVD_Home_008_1_traj5, ate: 247.59369243451656
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[9728/15000], training loss: 0.0564
[9736/15000], training loss: 0.0558
[9744/15000], training loss: 0.0782
[9752/15000], training loss: 0.0562
[9760/15000], training loss: 0.0645
16
AVD_Home_008_1_traj5, ate: 246.78381071469553
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[9768/15000], training loss: 0.0690
[9776/15000], training loss: 0.0896
[9784/15000], training loss: 0.0687
[9792/15000], training loss: 0.0580
[9800/15000], training loss: 0.0749
16
AVD_Home_008_1_traj5, ate: 247.55607947338467
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[9808/15000], training loss: 0.0713
[9816/15000], training loss: 0.0526
[9824/15000], training loss: 0.0568
[9832/15000], training loss: 0.0667
[9840/15000], training loss: 0.0566
16
AVD_Home_008_1_traj5, ate: 247.0871072949304
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[9848/15000], training loss: 0.0760
[9856/15000], training loss: 0.0908
[9864/15000], training loss: 0.0590
[9872/15000], training loss: 0.0714
[9880/15000], training loss: 0.0603
16
AVD_Home_008_1_traj5, ate: 246.66101654783293
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[9888/15000], training loss: 0.0502
[9896/15000], training loss: 0.0663
[9904/15000], training loss: 0.0735
[9912/15000], training loss: 0.0618
[9920/15000], training loss: 0.0793
16
AVD_Home_008_1_traj5, ate: 246.83926407656188
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[9928/15000], training loss: 0.0593
[9936/15000], training loss: 0.0602
[9944/15000], training loss: 0.0518
[9952/15000], training loss: 0.0581
[9960/15000], training loss: 0.0660
16
AVD_Home_008_1_traj5, ate: 245.79812303466667
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[9968/15000], training loss: 0.0698
[9976/15000], training loss: 0.0814
[9984/15000], training loss: 0.0861
[9992/15000], training loss: 0.0728
[10000/15000], training loss: 0.0766
16
AVD_Home_008_1_traj5, ate: 248.45555927487925
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[10008/15000], training loss: 0.0603
[10016/15000], training loss: 0.0595
[10024/15000], training loss: 0.0591
[10032/15000], training loss: 0.0609
[10040/15000], training loss: 0.0760
16
AVD_Home_008_1_traj5, ate: 247.15263039814428
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[10048/15000], training loss: 0.0650
[10056/15000], training loss: 0.0712
[10064/15000], training loss: 0.0620
[10072/15000], training loss: 0.0542
[10080/15000], training loss: 0.1155
16
AVD_Home_008_1_traj5, ate: 248.4451836642207
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[10088/15000], training loss: 0.0750
[10096/15000], training loss: 0.0815
[10104/15000], training loss: 0.0573
[10112/15000], training loss: 0.0675
[10120/15000], training loss: 0.0525
16
AVD_Home_008_1_traj5, ate: 246.92570194771005
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[10128/15000], training loss: 0.0679
[10136/15000], training loss: 0.0482
[10144/15000], training loss: 0.0655
[10152/15000], training loss: 0.0610
[10160/15000], training loss: 0.0595
16
AVD_Home_008_1_traj5, ate: 246.75577231466747
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[10168/15000], training loss: 0.0970
[10176/15000], training loss: 0.0865
[10184/15000], training loss: 0.0625
[10192/15000], training loss: 0.0620
[10200/15000], training loss: 0.0570
16
AVD_Home_008_1_traj5, ate: 245.83788623580134
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[10208/15000], training loss: 0.0724
[10216/15000], training loss: 0.0540
[10224/15000], training loss: 0.0891
[10232/15000], training loss: 0.1041
[10240/15000], training loss: 0.0718
16
AVD_Home_008_1_traj5, ate: 248.70978960742877
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[10248/15000], training loss: 0.0672
[10256/15000], training loss: 0.0683
[10264/15000], training loss: 0.0623
[10272/15000], training loss: 0.0796
[10280/15000], training loss: 0.0656
16
AVD_Home_008_1_traj5, ate: 245.59227736243298
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[10288/15000], training loss: 0.0719
[10296/15000], training loss: 0.0672
[10304/15000], training loss: 0.0730
[10312/15000], training loss: 0.0536
[10320/15000], training loss: 0.0670
16
AVD_Home_008_1_traj5, ate: 246.8056951410416
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[10328/15000], training loss: 0.0830
[10336/15000], training loss: 0.0875
[10344/15000], training loss: 0.0666
[10352/15000], training loss: 0.0725
[10360/15000], training loss: 0.0667
16
AVD_Home_008_1_traj5, ate: 245.912758760944
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[10368/15000], training loss: 0.0762
[10376/15000], training loss: 0.0575
[10384/15000], training loss: 0.0600
[10392/15000], training loss: 0.0612
[10400/15000], training loss: 0.0547
16
AVD_Home_008_1_traj5, ate: 246.77304725106458
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[10408/15000], training loss: 0.0760
[10416/15000], training loss: 0.0626
[10424/15000], training loss: 0.0699
[10432/15000], training loss: 0.0604
[10440/15000], training loss: 0.0786
16
AVD_Home_008_1_traj5, ate: 247.39563339444453
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[10448/15000], training loss: 0.0697
[10456/15000], training loss: 0.0636
[10464/15000], training loss: 0.0669
[10472/15000], training loss: 0.0614
[10480/15000], training loss: 0.0705
16
AVD_Home_008_1_traj5, ate: 247.19065723786696
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[10488/15000], training loss: 0.0570
[10496/15000], training loss: 0.0548
[10504/15000], training loss: 0.0666
[10512/15000], training loss: 0.0608
[10520/15000], training loss: 0.0816
16
AVD_Home_008_1_traj5, ate: 246.07930927924596
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[10528/15000], training loss: 0.0542
[10536/15000], training loss: 0.0641
[10544/15000], training loss: 0.0743
[10552/15000], training loss: 0.0887
[10560/15000], training loss: 0.0727
16
AVD_Home_008_1_traj5, ate: 246.89397310610568
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[10568/15000], training loss: 0.0573
[10576/15000], training loss: 0.0744
[10584/15000], training loss: 0.0813
[10592/15000], training loss: 0.0646
[10600/15000], training loss: 0.0621
16
AVD_Home_008_1_traj5, ate: 246.58713734322404
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[10608/15000], training loss: 0.0809
[10616/15000], training loss: 0.0624
[10624/15000], training loss: 0.0540
[10632/15000], training loss: 0.0643
[10640/15000], training loss: 0.0640
16
AVD_Home_008_1_traj5, ate: 246.19709148069666
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[10648/15000], training loss: 0.0926
[10656/15000], training loss: 0.0793
[10664/15000], training loss: 0.0646
[10672/15000], training loss: 0.0597
[10680/15000], training loss: 0.0579
16
AVD_Home_008_1_traj5, ate: 246.74574383117437
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[10688/15000], training loss: 0.0689
[10696/15000], training loss: 0.0637
[10704/15000], training loss: 0.0610
[10712/15000], training loss: 0.0527
[10720/15000], training loss: 0.0633
16
AVD_Home_008_1_traj5, ate: 247.46827930396822
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[10728/15000], training loss: 0.0580
[10736/15000], training loss: 0.0674
[10744/15000], training loss: 0.0842
[10752/15000], training loss: 0.0801
[10760/15000], training loss: 0.0669
16
AVD_Home_008_1_traj5, ate: 247.44267461700724
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[10768/15000], training loss: 0.0572
[10776/15000], training loss: 0.0637
[10784/15000], training loss: 0.0665
[10792/15000], training loss: 0.0736
[10800/15000], training loss: 0.0565
16
AVD_Home_008_1_traj5, ate: 247.17951982704216
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[10808/15000], training loss: 0.0779
[10816/15000], training loss: 0.0794
[10824/15000], training loss: 0.0542
[10832/15000], training loss: 0.0737
[10840/15000], training loss: 0.0806
16
AVD_Home_008_1_traj5, ate: 245.71195100685895
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[10848/15000], training loss: 0.0737
[10856/15000], training loss: 0.0587
[10864/15000], training loss: 0.0694
[10872/15000], training loss: 0.0501
[10880/15000], training loss: 0.0611
16
AVD_Home_008_1_traj5, ate: 247.3719422570525
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[10888/15000], training loss: 0.0907
[10896/15000], training loss: 0.0755
[10904/15000], training loss: 0.0740
[10912/15000], training loss: 0.0620
[10920/15000], training loss: 0.0680
16
AVD_Home_008_1_traj5, ate: 245.56183870552934
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[10928/15000], training loss: 0.0633
[10936/15000], training loss: 0.0715
[10944/15000], training loss: 0.0712
[10952/15000], training loss: 0.0537
[10960/15000], training loss: 0.0604
16
AVD_Home_008_1_traj5, ate: 246.38218881716085
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[10968/15000], training loss: 0.0616
[10976/15000], training loss: 0.0801
[10984/15000], training loss: 0.0592
[10992/15000], training loss: 0.0808
[11000/15000], training loss: 0.0747
16
AVD_Home_008_1_traj5, ate: 246.51964548627814
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[11008/15000], training loss: 0.0881
[11016/15000], training loss: 0.0642
[11024/15000], training loss: 0.0754
[11032/15000], training loss: 0.0642
[11040/15000], training loss: 0.0818
16
AVD_Home_008_1_traj5, ate: 247.38727361569056
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[11048/15000], training loss: 0.0630
[11056/15000], training loss: 0.0621
[11064/15000], training loss: 0.0783
[11072/15000], training loss: 0.0769
[11080/15000], training loss: 0.0584
16
AVD_Home_008_1_traj5, ate: 246.5123407631463
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[11088/15000], training loss: 0.0570
[11096/15000], training loss: 0.0761
[11104/15000], training loss: 0.0615
[11112/15000], training loss: 0.0963
[11120/15000], training loss: 0.0700
16
AVD_Home_008_1_traj5, ate: 246.82410481805272
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[11128/15000], training loss: 0.0659
[11136/15000], training loss: 0.0839
[11144/15000], training loss: 0.0874
[11152/15000], training loss: 0.0555
[11160/15000], training loss: 0.0798
16
AVD_Home_008_1_traj5, ate: 246.6955284486321
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[11168/15000], training loss: 0.0774
[11176/15000], training loss: 0.0510
[11184/15000], training loss: 0.0625
[11192/15000], training loss: 0.0842
[11200/15000], training loss: 0.0874
16
AVD_Home_008_1_traj5, ate: 245.75773802956618
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[11208/15000], training loss: 0.0814
[11216/15000], training loss: 0.0656
[11224/15000], training loss: 0.0661
[11232/15000], training loss: 0.0678
[11240/15000], training loss: 0.0614
16
AVD_Home_008_1_traj5, ate: 246.168630897192
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[11248/15000], training loss: 0.0746
[11256/15000], training loss: 0.0580
[11264/15000], training loss: 0.0660
[11272/15000], training loss: 0.0827
[11280/15000], training loss: 0.0690
16
AVD_Home_008_1_traj5, ate: 244.8728460020979
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[11288/15000], training loss: 0.0515
[11296/15000], training loss: 0.0649
[11304/15000], training loss: 0.0662
[11312/15000], training loss: 0.0614
[11320/15000], training loss: 0.0675
16
AVD_Home_008_1_traj5, ate: 246.5466380351541
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[11328/15000], training loss: 0.0643
[11336/15000], training loss: 0.0653
[11344/15000], training loss: 0.0625
[11352/15000], training loss: 0.0660
[11360/15000], training loss: 0.0663
16
AVD_Home_008_1_traj5, ate: 246.73530841424855
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[11368/15000], training loss: 0.0809
[11376/15000], training loss: 0.0693
[11384/15000], training loss: 0.0578
[11392/15000], training loss: 0.0570
[11400/15000], training loss: 0.0632
16
AVD_Home_008_1_traj5, ate: 246.13875031077205
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[11408/15000], training loss: 0.0568
[11416/15000], training loss: 0.0668
[11424/15000], training loss: 0.0720
[11432/15000], training loss: 0.0608
[11440/15000], training loss: 0.0616
16
AVD_Home_008_1_traj5, ate: 247.10411800225629
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[11448/15000], training loss: 0.0559
[11456/15000], training loss: 0.0785
[11464/15000], training loss: 0.0655
[11472/15000], training loss: 0.0743
[11480/15000], training loss: 0.0570
16
AVD_Home_008_1_traj5, ate: 247.14015912962805
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[11488/15000], training loss: 0.0622
[11496/15000], training loss: 0.0870
[11504/15000], training loss: 0.0685
[11512/15000], training loss: 0.0885
[11520/15000], training loss: 0.0725
16
AVD_Home_008_1_traj5, ate: 248.46664531453473
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[11528/15000], training loss: 0.0679
[11536/15000], training loss: 0.0818
[11544/15000], training loss: 0.0628
[11552/15000], training loss: 0.0605
[11560/15000], training loss: 0.0606
16
AVD_Home_008_1_traj5, ate: 246.89080757325985
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[11568/15000], training loss: 0.0639
[11576/15000], training loss: 0.0664
[11584/15000], training loss: 0.0586
[11592/15000], training loss: 0.0707
[11600/15000], training loss: 0.0568
16
AVD_Home_008_1_traj5, ate: 247.12211230463734
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[11608/15000], training loss: 0.0702
[11616/15000], training loss: 0.0700
[11624/15000], training loss: 0.0574
[11632/15000], training loss: 0.0575
[11640/15000], training loss: 0.0570
16
AVD_Home_008_1_traj5, ate: 247.5772173673543
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[11648/15000], training loss: 0.0737
[11656/15000], training loss: 0.0699
[11664/15000], training loss: 0.0642
[11672/15000], training loss: 0.0687
[11680/15000], training loss: 0.0528
16
AVD_Home_008_1_traj5, ate: 247.23914919622433
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[11688/15000], training loss: 0.0606
[11696/15000], training loss: 0.0742
[11704/15000], training loss: 0.0518
[11712/15000], training loss: 0.0623
[11720/15000], training loss: 0.0569
16
AVD_Home_008_1_traj5, ate: 247.0466770622573
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[11728/15000], training loss: 0.0639
[11736/15000], training loss: 0.0593
[11744/15000], training loss: 0.0771
[11752/15000], training loss: 0.0561
[11760/15000], training loss: 0.0878
16
AVD_Home_008_1_traj5, ate: 247.9457573154463
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[11768/15000], training loss: 0.0700
[11776/15000], training loss: 0.0666
[11784/15000], training loss: 0.0665
[11792/15000], training loss: 0.0669
[11800/15000], training loss: 0.0614
16
AVD_Home_008_1_traj5, ate: 247.22072241852493
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[11808/15000], training loss: 0.0579
[11816/15000], training loss: 0.0610
[11824/15000], training loss: 0.0807
[11832/15000], training loss: 0.0764
[11840/15000], training loss: 0.0810
16
AVD_Home_008_1_traj5, ate: 246.91499178019959
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[11848/15000], training loss: 0.0659
[11856/15000], training loss: 0.0621
[11864/15000], training loss: 0.0884
[11872/15000], training loss: 0.0603
[11880/15000], training loss: 0.0831
16
AVD_Home_008_1_traj5, ate: 246.26174930691386
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[11888/15000], training loss: 0.0583
[11896/15000], training loss: 0.0785
[11904/15000], training loss: 0.0548
[11912/15000], training loss: 0.0786
[11920/15000], training loss: 0.0706
16
AVD_Home_008_1_traj5, ate: 246.6770076531889
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[11928/15000], training loss: 0.0849
[11936/15000], training loss: 0.0669
[11944/15000], training loss: 0.0584
[11952/15000], training loss: 0.0622
[11960/15000], training loss: 0.0800
16
AVD_Home_008_1_traj5, ate: 246.30862956150438
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[11968/15000], training loss: 0.0825
[11976/15000], training loss: 0.0858
[11984/15000], training loss: 0.0862
[11992/15000], training loss: 0.0587
[12000/15000], training loss: 0.0778
16
AVD_Home_008_1_traj5, ate: 247.5727541118649
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[12008/15000], training loss: 0.0731
[12016/15000], training loss: 0.0701
[12024/15000], training loss: 0.0869
[12032/15000], training loss: 0.0536
[12040/15000], training loss: 0.0694
16
AVD_Home_008_1_traj5, ate: 246.82274672803896
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[12048/15000], training loss: 0.0844
[12056/15000], training loss: 0.0551
[12064/15000], training loss: 0.0786
[12072/15000], training loss: 0.0642
[12080/15000], training loss: 0.0576
16
AVD_Home_008_1_traj5, ate: 247.10357932961293
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[12088/15000], training loss: 0.0748
[12096/15000], training loss: 0.0789
[12104/15000], training loss: 0.0739
[12112/15000], training loss: 0.0755
[12120/15000], training loss: 0.0573
16
AVD_Home_008_1_traj5, ate: 247.17381154661547
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[12128/15000], training loss: 0.0768
[12136/15000], training loss: 0.0540
[12144/15000], training loss: 0.0624
[12152/15000], training loss: 0.0725
[12160/15000], training loss: 0.0747
16
AVD_Home_008_1_traj5, ate: 247.50038267591265
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[12168/15000], training loss: 0.0704
[12176/15000], training loss: 0.0612
[12184/15000], training loss: 0.0958
[12192/15000], training loss: 0.0719
[12200/15000], training loss: 0.0681
16
AVD_Home_008_1_traj5, ate: 247.54732009533217
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[12208/15000], training loss: 0.0678
[12216/15000], training loss: 0.0547
[12224/15000], training loss: 0.0629
[12232/15000], training loss: 0.0643
[12240/15000], training loss: 0.0619
16
AVD_Home_008_1_traj5, ate: 246.03399562578568
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[12248/15000], training loss: 0.0710
[12256/15000], training loss: 0.0654
[12264/15000], training loss: 0.0605
[12272/15000], training loss: 0.0615
[12280/15000], training loss: 0.0691
16
AVD_Home_008_1_traj5, ate: 246.7616567161156
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[12288/15000], training loss: 0.0577
[12296/15000], training loss: 0.0873
[12304/15000], training loss: 0.0623
[12312/15000], training loss: 0.0598
[12320/15000], training loss: 0.0635
16
AVD_Home_008_1_traj5, ate: 246.69491448374635
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[12328/15000], training loss: 0.0706
[12336/15000], training loss: 0.0531
[12344/15000], training loss: 0.0744
[12352/15000], training loss: 0.0717
[12360/15000], training loss: 0.0534
16
AVD_Home_008_1_traj5, ate: 247.9779940314287
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[12368/15000], training loss: 0.0539
[12376/15000], training loss: 0.0724
[12384/15000], training loss: 0.0660
[12392/15000], training loss: 0.0809
[12400/15000], training loss: 0.0671
16
AVD_Home_008_1_traj5, ate: 247.73113093030491
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[12408/15000], training loss: 0.0674
[12416/15000], training loss: 0.0656
[12424/15000], training loss: 0.0874
[12432/15000], training loss: 0.0663
[12440/15000], training loss: 0.0612
16
AVD_Home_008_1_traj5, ate: 246.1320088573286
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[12448/15000], training loss: 0.0674
[12456/15000], training loss: 0.0524
[12464/15000], training loss: 0.0734
[12472/15000], training loss: 0.0848
[12480/15000], training loss: 0.0744
16
AVD_Home_008_1_traj5, ate: 247.7891115853063
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[12488/15000], training loss: 0.0650
[12496/15000], training loss: 0.0709
[12504/15000], training loss: 0.0534
[12512/15000], training loss: 0.0557
[12520/15000], training loss: 0.0636
16
AVD_Home_008_1_traj5, ate: 246.96650584075553
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[12528/15000], training loss: 0.0674
[12536/15000], training loss: 0.0764
[12544/15000], training loss: 0.0837
[12552/15000], training loss: 0.0607
[12560/15000], training loss: 0.0716
16
AVD_Home_008_1_traj5, ate: 247.47215462072822
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[12568/15000], training loss: 0.0698
[12576/15000], training loss: 0.0728
[12584/15000], training loss: 0.0606
[12592/15000], training loss: 0.0621
[12600/15000], training loss: 0.0542
16
AVD_Home_008_1_traj5, ate: 247.58953601825326
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[12608/15000], training loss: 0.0560
[12616/15000], training loss: 0.0615
[12624/15000], training loss: 0.0577
[12632/15000], training loss: 0.0586
[12640/15000], training loss: 0.0948
16
AVD_Home_008_1_traj5, ate: 246.85501591949952
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[12648/15000], training loss: 0.0640
[12656/15000], training loss: 0.0572
[12664/15000], training loss: 0.0663
[12672/15000], training loss: 0.0541
[12680/15000], training loss: 0.0731
16
AVD_Home_008_1_traj5, ate: 246.61438283456727
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[12688/15000], training loss: 0.0686
[12696/15000], training loss: 0.0773
[12704/15000], training loss: 0.0555
[12712/15000], training loss: 0.0594
[12720/15000], training loss: 0.0618
16
AVD_Home_008_1_traj5, ate: 247.56462687286992
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[12728/15000], training loss: 0.0710
[12736/15000], training loss: 0.0640
[12744/15000], training loss: 0.0609
[12752/15000], training loss: 0.0601
[12760/15000], training loss: 0.0679
16
AVD_Home_008_1_traj5, ate: 247.05757571783457
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[12768/15000], training loss: 0.0540
[12776/15000], training loss: 0.0589
[12784/15000], training loss: 0.0611
[12792/15000], training loss: 0.0883
[12800/15000], training loss: 0.0642
16
AVD_Home_008_1_traj5, ate: 246.83539037491607
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[12808/15000], training loss: 0.0531
[12816/15000], training loss: 0.0614
[12824/15000], training loss: 0.0649
[12832/15000], training loss: 0.0963
[12840/15000], training loss: 0.0579
16
AVD_Home_008_1_traj5, ate: 246.68714609509755
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[12848/15000], training loss: 0.0673
[12856/15000], training loss: 0.0687
[12864/15000], training loss: 0.0548
[12872/15000], training loss: 0.0665
[12880/15000], training loss: 0.0690
16
AVD_Home_008_1_traj5, ate: 246.51464178622138
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[12888/15000], training loss: 0.0748
[12896/15000], training loss: 0.0772
[12904/15000], training loss: 0.0753
[12912/15000], training loss: 0.0839
[12920/15000], training loss: 0.0998
16
AVD_Home_008_1_traj5, ate: 246.9581789494077
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[12928/15000], training loss: 0.0579
[12936/15000], training loss: 0.0805
[12944/15000], training loss: 0.0632
[12952/15000], training loss: 0.0609
[12960/15000], training loss: 0.0916
16
AVD_Home_008_1_traj5, ate: 247.12677235761922
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[12968/15000], training loss: 0.0706
[12976/15000], training loss: 0.0593
[12984/15000], training loss: 0.0658
[12992/15000], training loss: 0.0572
[13000/15000], training loss: 0.0637
16
AVD_Home_008_1_traj5, ate: 246.69120157093167
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[13008/15000], training loss: 0.0659
[13016/15000], training loss: 0.0584
[13024/15000], training loss: 0.0490
[13032/15000], training loss: 0.0686
[13040/15000], training loss: 0.0588
16
AVD_Home_008_1_traj5, ate: 246.1803574145129
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[13048/15000], training loss: 0.0558
[13056/15000], training loss: 0.0753
[13064/15000], training loss: 0.0621
[13072/15000], training loss: 0.0529
[13080/15000], training loss: 0.0748
16
AVD_Home_008_1_traj5, ate: 246.65681089103163
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[13088/15000], training loss: 0.0665
[13096/15000], training loss: 0.0803
[13104/15000], training loss: 0.0623
[13112/15000], training loss: 0.0674
[13120/15000], training loss: 0.0553
16
AVD_Home_008_1_traj5, ate: 246.85911364107304
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[13128/15000], training loss: 0.0628
[13136/15000], training loss: 0.0752
[13144/15000], training loss: 0.0642
[13152/15000], training loss: 0.0549
[13160/15000], training loss: 0.0644
16
AVD_Home_008_1_traj5, ate: 247.34860879346962
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[13168/15000], training loss: 0.0808
[13176/15000], training loss: 0.0603
[13184/15000], training loss: 0.0510
[13192/15000], training loss: 0.0677
[13200/15000], training loss: 0.0750
16
AVD_Home_008_1_traj5, ate: 246.28057420945248
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[13208/15000], training loss: 0.0722
[13216/15000], training loss: 0.0758
[13224/15000], training loss: 0.0649
[13232/15000], training loss: 0.0612
[13240/15000], training loss: 0.0652
16
AVD_Home_008_1_traj5, ate: 246.91875088718035
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[13248/15000], training loss: 0.0564
[13256/15000], training loss: 0.0728
[13264/15000], training loss: 0.0910
[13272/15000], training loss: 0.0771
[13280/15000], training loss: 0.0565
16
AVD_Home_008_1_traj5, ate: 247.77877456996148
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[13288/15000], training loss: 0.0602
[13296/15000], training loss: 0.0633
[13304/15000], training loss: 0.0753
[13312/15000], training loss: 0.0512
[13320/15000], training loss: 0.0578
16
AVD_Home_008_1_traj5, ate: 247.18032553837702
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[13328/15000], training loss: 0.0849
[13336/15000], training loss: 0.0634
[13344/15000], training loss: 0.0977
[13352/15000], training loss: 0.0741
[13360/15000], training loss: 0.0528
16
AVD_Home_008_1_traj5, ate: 246.98640205655414
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[13368/15000], training loss: 0.0561
[13376/15000], training loss: 0.0650
[13384/15000], training loss: 0.0667
[13392/15000], training loss: 0.0552
[13400/15000], training loss: 0.0748
16
AVD_Home_008_1_traj5, ate: 246.85170534819585
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[13408/15000], training loss: 0.0680
[13416/15000], training loss: 0.0559
[13424/15000], training loss: 0.0771
[13432/15000], training loss: 0.0513
[13440/15000], training loss: 0.0678
16
AVD_Home_008_1_traj5, ate: 247.523072729227
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[13448/15000], training loss: 0.0803
[13456/15000], training loss: 0.0716
[13464/15000], training loss: 0.0681
[13472/15000], training loss: 0.0634
[13480/15000], training loss: 0.0498
16
AVD_Home_008_1_traj5, ate: 246.82018592684787
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[13488/15000], training loss: 0.0684
[13496/15000], training loss: 0.0566
[13504/15000], training loss: 0.0563
[13512/15000], training loss: 0.0628
[13520/15000], training loss: 0.0582
16
AVD_Home_008_1_traj5, ate: 247.18292053605205
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[13528/15000], training loss: 0.0516
[13536/15000], training loss: 0.0538
[13544/15000], training loss: 0.0623
[13552/15000], training loss: 0.0565
[13560/15000], training loss: 0.0521
16
AVD_Home_008_1_traj5, ate: 246.49367429475254
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[13568/15000], training loss: 0.0684
[13576/15000], training loss: 0.0561
[13584/15000], training loss: 0.0637
[13592/15000], training loss: 0.0634
[13600/15000], training loss: 0.0659
16
AVD_Home_008_1_traj5, ate: 246.86926425998834
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[13608/15000], training loss: 0.0630
[13616/15000], training loss: 0.0776
[13624/15000], training loss: 0.0561
[13632/15000], training loss: 0.0791
[13640/15000], training loss: 0.0882
16
AVD_Home_008_1_traj5, ate: 246.34120125112244
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[13648/15000], training loss: 0.0665
[13656/15000], training loss: 0.0629
[13664/15000], training loss: 0.0741
[13672/15000], training loss: 0.0842
[13680/15000], training loss: 0.0590
16
AVD_Home_008_1_traj5, ate: 246.81029946491608
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[13688/15000], training loss: 0.0709
[13696/15000], training loss: 0.0672
[13704/15000], training loss: 0.0602
[13712/15000], training loss: 0.0863
[13720/15000], training loss: 0.0542
16
AVD_Home_008_1_traj5, ate: 247.37623233397926
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[13728/15000], training loss: 0.0674
[13736/15000], training loss: 0.0728
[13744/15000], training loss: 0.0551
[13752/15000], training loss: 0.0632
[13760/15000], training loss: 0.0771
16
AVD_Home_008_1_traj5, ate: 247.20159873567678
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[13768/15000], training loss: 0.0755
[13776/15000], training loss: 0.0605
[13784/15000], training loss: 0.0616
[13792/15000], training loss: 0.0726
[13800/15000], training loss: 0.0886
16
AVD_Home_008_1_traj5, ate: 247.77466344912403
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[13808/15000], training loss: 0.0828
[13816/15000], training loss: 0.0555
[13824/15000], training loss: 0.0667
[13832/15000], training loss: 0.0631
[13840/15000], training loss: 0.0828
16
AVD_Home_008_1_traj5, ate: 247.09399044067462
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[13848/15000], training loss: 0.0764
[13856/15000], training loss: 0.0530
[13864/15000], training loss: 0.0618
[13872/15000], training loss: 0.0737
[13880/15000], training loss: 0.0562
16
AVD_Home_008_1_traj5, ate: 247.74261464794102
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[13888/15000], training loss: 0.0572
[13896/15000], training loss: 0.0554
[13904/15000], training loss: 0.0622
[13912/15000], training loss: 0.0582
[13920/15000], training loss: 0.0697
16
AVD_Home_008_1_traj5, ate: 246.34956276144626
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[13928/15000], training loss: 0.0652
[13936/15000], training loss: 0.0767
[13944/15000], training loss: 0.0696
[13952/15000], training loss: 0.0926
[13960/15000], training loss: 0.0507
16
AVD_Home_008_1_traj5, ate: 247.74653798590697
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[13968/15000], training loss: 0.0720
[13976/15000], training loss: 0.0670
[13984/15000], training loss: 0.0760
[13992/15000], training loss: 0.0670
[14000/15000], training loss: 0.0596
16
AVD_Home_008_1_traj5, ate: 247.36914250051777
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[14008/15000], training loss: 0.1043
[14016/15000], training loss: 0.0546
[14024/15000], training loss: 0.0725
[14032/15000], training loss: 0.1005
[14040/15000], training loss: 0.0560
16
AVD_Home_008_1_traj5, ate: 247.45335633933297
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[14048/15000], training loss: 0.0616
[14056/15000], training loss: 0.0733
[14064/15000], training loss: 0.0560
[14072/15000], training loss: 0.0665
[14080/15000], training loss: 0.0742
16
AVD_Home_008_1_traj5, ate: 246.97760333652113
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[14088/15000], training loss: 0.0673
[14096/15000], training loss: 0.0694
[14104/15000], training loss: 0.0679
[14112/15000], training loss: 0.0600
[14120/15000], training loss: 0.0694
16
AVD_Home_008_1_traj5, ate: 247.4696569230614
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[14128/15000], training loss: 0.0644
[14136/15000], training loss: 0.0746
[14144/15000], training loss: 0.0777
[14152/15000], training loss: 0.0594
[14160/15000], training loss: 0.0731
16
AVD_Home_008_1_traj5, ate: 247.80030013862046
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[14168/15000], training loss: 0.0662
[14176/15000], training loss: 0.0533
[14184/15000], training loss: 0.0628
[14192/15000], training loss: 0.0536
[14200/15000], training loss: 0.0534
16
AVD_Home_008_1_traj5, ate: 246.8694590296369
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[14208/15000], training loss: 0.0752
[14216/15000], training loss: 0.0729
[14224/15000], training loss: 0.0497
[14232/15000], training loss: 0.0556
[14240/15000], training loss: 0.0603
16
AVD_Home_008_1_traj5, ate: 247.38876181828522
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[14248/15000], training loss: 0.0545
[14256/15000], training loss: 0.0548
[14264/15000], training loss: 0.0587
[14272/15000], training loss: 0.0931
[14280/15000], training loss: 0.0628
16
AVD_Home_008_1_traj5, ate: 247.08429350849747
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[14288/15000], training loss: 0.0687
[14296/15000], training loss: 0.0959
[14304/15000], training loss: 0.0577
[14312/15000], training loss: 0.0631
[14320/15000], training loss: 0.0660
16
AVD_Home_008_1_traj5, ate: 246.91968339416567
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[14328/15000], training loss: 0.0573
[14336/15000], training loss: 0.0801
[14344/15000], training loss: 0.0732
[14352/15000], training loss: 0.0671
[14360/15000], training loss: 0.0650
16
AVD_Home_008_1_traj5, ate: 247.0775912250062
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[14368/15000], training loss: 0.0595
[14376/15000], training loss: 0.0554
[14384/15000], training loss: 0.0750
[14392/15000], training loss: 0.0598
[14400/15000], training loss: 0.0700
16
AVD_Home_008_1_traj5, ate: 247.6387362362575
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[14408/15000], training loss: 0.0542
[14416/15000], training loss: 0.0612
[14424/15000], training loss: 0.0544
[14432/15000], training loss: 0.0812
[14440/15000], training loss: 0.0563
16
AVD_Home_008_1_traj5, ate: 246.79721843766256
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[14448/15000], training loss: 0.0610
[14456/15000], training loss: 0.0572
[14464/15000], training loss: 0.0524
[14472/15000], training loss: 0.0758
[14480/15000], training loss: 0.0818
16
AVD_Home_008_1_traj5, ate: 247.69427069307693
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[14488/15000], training loss: 0.0730
[14496/15000], training loss: 0.0603
[14504/15000], training loss: 0.0602
[14512/15000], training loss: 0.0530
[14520/15000], training loss: 0.0596
16
AVD_Home_008_1_traj5, ate: 247.19585186274736
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[14528/15000], training loss: 0.0853
[14536/15000], training loss: 0.0635
[14544/15000], training loss: 0.0642
[14552/15000], training loss: 0.0817
[14560/15000], training loss: 0.0535
16
AVD_Home_008_1_traj5, ate: 246.86174533632953
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[14568/15000], training loss: 0.0698
[14576/15000], training loss: 0.0556
[14584/15000], training loss: 0.0546
[14592/15000], training loss: 0.0709
[14600/15000], training loss: 0.0504
16
AVD_Home_008_1_traj5, ate: 247.54615528000772
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[14608/15000], training loss: 0.0572
[14616/15000], training loss: 0.0557
[14624/15000], training loss: 0.0743
[14632/15000], training loss: 0.0628
[14640/15000], training loss: 0.0917
16
AVD_Home_008_1_traj5, ate: 247.1785949088201
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[14648/15000], training loss: 0.0683
[14656/15000], training loss: 0.0614
[14664/15000], training loss: 0.0614
[14672/15000], training loss: 0.0656
[14680/15000], training loss: 0.0839
16
AVD_Home_008_1_traj5, ate: 247.58372802613772
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[14688/15000], training loss: 0.0555
[14696/15000], training loss: 0.0603
[14704/15000], training loss: 0.0728
[14712/15000], training loss: 0.0504
[14720/15000], training loss: 0.0633
16
AVD_Home_008_1_traj5, ate: 247.1013443286381
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[14728/15000], training loss: 0.0722
[14736/15000], training loss: 0.0545
[14744/15000], training loss: 0.0568
[14752/15000], training loss: 0.0619
[14760/15000], training loss: 0.0681
16
AVD_Home_008_1_traj5, ate: 247.36530787192538
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[14768/15000], training loss: 0.0489
[14776/15000], training loss: 0.0544
[14784/15000], training loss: 0.0789
[14792/15000], training loss: 0.0572
[14800/15000], training loss: 0.0850
16
AVD_Home_008_1_traj5, ate: 247.41482850196402
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[14808/15000], training loss: 0.0576
[14816/15000], training loss: 0.0676
[14824/15000], training loss: 0.0620
[14832/15000], training loss: 0.0513
[14840/15000], training loss: 0.0592
16
AVD_Home_008_1_traj5, ate: 247.53511952468946
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[14848/15000], training loss: 0.0566
[14856/15000], training loss: 0.0591
[14864/15000], training loss: 0.0630
[14872/15000], training loss: 0.0887
[14880/15000], training loss: 0.0640
16
AVD_Home_008_1_traj5, ate: 248.4382419373527
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[14888/15000], training loss: 0.0754
[14896/15000], training loss: 0.0654
[14904/15000], training loss: 0.0657
[14912/15000], training loss: 0.0713
[14920/15000], training loss: 0.1076
16
AVD_Home_008_1_traj5, ate: 247.5716626562189
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[14928/15000], training loss: 0.0535
[14936/15000], training loss: 0.0531
[14944/15000], training loss: 0.0655
[14952/15000], training loss: 0.0677
[14960/15000], training loss: 0.0595
16
AVD_Home_008_1_traj5, ate: 247.14769734717734
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
[14968/15000], training loss: 0.0548
[14976/15000], training loss: 0.0541
[14984/15000], training loss: 0.0901
[14992/15000], training loss: 0.0764
[15000/15000], training loss: 0.0670
16
AVD_Home_008_1_traj5, ate: 247.65841921971864
model saved to ../results/AVD/AVD_Home_008_1_traj5/model_best.pth
./lstm_run_train_AVD.sh: line 25: /home/mmvc: Is a directory
