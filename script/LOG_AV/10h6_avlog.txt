maxpool
latent size single: 16
loading dataset
16
pccppcpc1123 (16, 27, 48, 3)
creating model
start training
[8/15000], training loss: 0.1729
[16/15000], training loss: 0.1249
[24/15000], training loss: 0.1247
[32/15000], training loss: 0.1209
[40/15000], training loss: 0.1111
16
AVD_Home_010_1_traj6, ate: 458.1845453440132
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[48/15000], training loss: 0.1146
[56/15000], training loss: 0.1155
[64/15000], training loss: 0.1149
[72/15000], training loss: 0.1148
[80/15000], training loss: 0.1140
16
AVD_Home_010_1_traj6, ate: 324.3611332813208
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[88/15000], training loss: 0.1173
[96/15000], training loss: 0.1133
[104/15000], training loss: 0.1052
[112/15000], training loss: 0.1139
[120/15000], training loss: 0.1187
16
AVD_Home_010_1_traj6, ate: 309.10952853128686
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[128/15000], training loss: 0.1147
[136/15000], training loss: 0.1064
[144/15000], training loss: 0.1140
[152/15000], training loss: 0.1112
[160/15000], training loss: 0.1052
16
AVD_Home_010_1_traj6, ate: 276.8108175742054
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[168/15000], training loss: 0.1129
[176/15000], training loss: 0.1056
[184/15000], training loss: 0.1148
[192/15000], training loss: 0.1116
[200/15000], training loss: 0.1023
16
AVD_Home_010_1_traj6, ate: 310.9519518772772
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[208/15000], training loss: 0.1119
[216/15000], training loss: 0.1054
[224/15000], training loss: 0.1142
[232/15000], training loss: 0.1089
[240/15000], training loss: 0.1077
16
AVD_Home_010_1_traj6, ate: 319.9113668433888
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[248/15000], training loss: 0.1044
[256/15000], training loss: 0.1027
[264/15000], training loss: 0.1140
[272/15000], training loss: 0.1096
[280/15000], training loss: 0.0983
16
AVD_Home_010_1_traj6, ate: 306.2005833870974
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[288/15000], training loss: 0.1068
[296/15000], training loss: 0.1004
[304/15000], training loss: 0.1041
[312/15000], training loss: 0.1114
[320/15000], training loss: 0.0993
16
AVD_Home_010_1_traj6, ate: 297.10688220425794
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[328/15000], training loss: 0.1078
[336/15000], training loss: 0.1027
[344/15000], training loss: 0.0995
[352/15000], training loss: 0.1055
[360/15000], training loss: 0.1166
16
AVD_Home_010_1_traj6, ate: 295.2163696455405
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[368/15000], training loss: 0.1019
[376/15000], training loss: 0.1013
[384/15000], training loss: 0.1028
[392/15000], training loss: 0.1102
[400/15000], training loss: 0.1010
16
AVD_Home_010_1_traj6, ate: 269.98056906723724
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[408/15000], training loss: 0.0974
[416/15000], training loss: 0.1067
[424/15000], training loss: 0.1103
[432/15000], training loss: 0.0976
[440/15000], training loss: 0.0868
16
AVD_Home_010_1_traj6, ate: 183.16482387911682
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[448/15000], training loss: 0.1035
[456/15000], training loss: 0.0944
[464/15000], training loss: 0.0820
[472/15000], training loss: 0.0924
[480/15000], training loss: 0.0962
16
AVD_Home_010_1_traj6, ate: 150.00414463401788
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[488/15000], training loss: 0.0920
[496/15000], training loss: 0.0994
[504/15000], training loss: 0.0839
[512/15000], training loss: 0.0935
[520/15000], training loss: 0.1050
16
AVD_Home_010_1_traj6, ate: 173.0345427516739
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[528/15000], training loss: 0.1059
[536/15000], training loss: 0.0846
[544/15000], training loss: 0.0965
[552/15000], training loss: 0.1152
[560/15000], training loss: 0.0904
16
AVD_Home_010_1_traj6, ate: 153.48139751898367
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[568/15000], training loss: 0.0898
[576/15000], training loss: 0.0913
[584/15000], training loss: 0.0909
[592/15000], training loss: 0.0961
[600/15000], training loss: 0.1004
16
AVD_Home_010_1_traj6, ate: 136.14670746265608
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[608/15000], training loss: 0.0884
[616/15000], training loss: 0.0748
[624/15000], training loss: 0.0929
[632/15000], training loss: 0.0733
[640/15000], training loss: 0.0810
16
AVD_Home_010_1_traj6, ate: 150.72700214815333
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[648/15000], training loss: 0.0766
[656/15000], training loss: 0.0794
[664/15000], training loss: 0.0965
[672/15000], training loss: 0.0917
[680/15000], training loss: 0.0887
16
AVD_Home_010_1_traj6, ate: 123.08281573037975
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[688/15000], training loss: 0.0927
[696/15000], training loss: 0.0798
[704/15000], training loss: 0.0804
[712/15000], training loss: 0.0779
[720/15000], training loss: 0.0740
16
AVD_Home_010_1_traj6, ate: 128.8754373230253
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[728/15000], training loss: 0.0876
[736/15000], training loss: 0.0830
[744/15000], training loss: 0.0872
[752/15000], training loss: 0.0887
[760/15000], training loss: 0.0792
16
AVD_Home_010_1_traj6, ate: 148.85195199636493
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[768/15000], training loss: 0.0880
[776/15000], training loss: 0.0881
[784/15000], training loss: 0.0915
[792/15000], training loss: 0.0842
[800/15000], training loss: 0.0854
16
AVD_Home_010_1_traj6, ate: 144.2133834624493
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[808/15000], training loss: 0.0745
[816/15000], training loss: 0.0967
[824/15000], training loss: 0.0870
[832/15000], training loss: 0.0703
[840/15000], training loss: 0.0738
16
AVD_Home_010_1_traj6, ate: 145.62267929098607
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[848/15000], training loss: 0.0876
[856/15000], training loss: 0.0843
[864/15000], training loss: 0.0796
[872/15000], training loss: 0.0852
[880/15000], training loss: 0.0872
16
AVD_Home_010_1_traj6, ate: 123.38806639544728
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[888/15000], training loss: 0.0904
[896/15000], training loss: 0.0782
[904/15000], training loss: 0.0688
[912/15000], training loss: 0.0745
[920/15000], training loss: 0.0783
16
AVD_Home_010_1_traj6, ate: 131.61841079280435
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[928/15000], training loss: 0.0660
[936/15000], training loss: 0.0780
[944/15000], training loss: 0.0794
[952/15000], training loss: 0.0743
[960/15000], training loss: 0.0648
16
AVD_Home_010_1_traj6, ate: 119.77464683107522
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[968/15000], training loss: 0.0907
[976/15000], training loss: 0.0732
[984/15000], training loss: 0.0807
[992/15000], training loss: 0.0807
[1000/15000], training loss: 0.0780
16
AVD_Home_010_1_traj6, ate: 130.19250896039938
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[1008/15000], training loss: 0.0870
[1016/15000], training loss: 0.0695
[1024/15000], training loss: 0.0724
[1032/15000], training loss: 0.0752
[1040/15000], training loss: 0.0760
16
AVD_Home_010_1_traj6, ate: 117.13241434869965
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[1048/15000], training loss: 0.0775
[1056/15000], training loss: 0.0760
[1064/15000], training loss: 0.0788
[1072/15000], training loss: 0.0713
[1080/15000], training loss: 0.0930
16
AVD_Home_010_1_traj6, ate: 118.56960816482813
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[1088/15000], training loss: 0.0810
[1096/15000], training loss: 0.0707
[1104/15000], training loss: 0.0852
[1112/15000], training loss: 0.0688
[1120/15000], training loss: 0.0707
16
AVD_Home_010_1_traj6, ate: 118.82172223399124
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[1128/15000], training loss: 0.1033
[1136/15000], training loss: 0.0736
[1144/15000], training loss: 0.0734
[1152/15000], training loss: 0.0867
[1160/15000], training loss: 0.0879
16
AVD_Home_010_1_traj6, ate: 124.4449518967358
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[1168/15000], training loss: 0.0794
[1176/15000], training loss: 0.0860
[1184/15000], training loss: 0.0834
[1192/15000], training loss: 0.0776
[1200/15000], training loss: 0.0718
16
AVD_Home_010_1_traj6, ate: 129.05981207177234
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[1208/15000], training loss: 0.0737
[1216/15000], training loss: 0.0691
[1224/15000], training loss: 0.0710
[1232/15000], training loss: 0.0734
[1240/15000], training loss: 0.0726
16
AVD_Home_010_1_traj6, ate: 109.58578618013469
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[1248/15000], training loss: 0.0843
[1256/15000], training loss: 0.0682
[1264/15000], training loss: 0.0802
[1272/15000], training loss: 0.0696
[1280/15000], training loss: 0.0627
16
AVD_Home_010_1_traj6, ate: 139.73203758228152
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[1288/15000], training loss: 0.0658
[1296/15000], training loss: 0.0877
[1304/15000], training loss: 0.0845
[1312/15000], training loss: 0.0778
[1320/15000], training loss: 0.0817
16
AVD_Home_010_1_traj6, ate: 112.96116456195885
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[1328/15000], training loss: 0.0584
[1336/15000], training loss: 0.0795
[1344/15000], training loss: 0.0761
[1352/15000], training loss: 0.0912
[1360/15000], training loss: 0.0727
16
AVD_Home_010_1_traj6, ate: 111.2487925132461
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[1368/15000], training loss: 0.0754
[1376/15000], training loss: 0.0849
[1384/15000], training loss: 0.0719
[1392/15000], training loss: 0.0688
[1400/15000], training loss: 0.0929
16
AVD_Home_010_1_traj6, ate: 116.69780882212306
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[1408/15000], training loss: 0.0714
[1416/15000], training loss: 0.0633
[1424/15000], training loss: 0.0876
[1432/15000], training loss: 0.0877
[1440/15000], training loss: 0.0850
16
AVD_Home_010_1_traj6, ate: 107.57957264947372
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[1448/15000], training loss: 0.0789
[1456/15000], training loss: 0.0702
[1464/15000], training loss: 0.0662
[1472/15000], training loss: 0.0765
[1480/15000], training loss: 0.0686
16
AVD_Home_010_1_traj6, ate: 133.30119822308075
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[1488/15000], training loss: 0.0716
[1496/15000], training loss: 0.0623
[1504/15000], training loss: 0.0724
[1512/15000], training loss: 0.0681
[1520/15000], training loss: 0.0632
16
AVD_Home_010_1_traj6, ate: 109.61831546140289
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[1528/15000], training loss: 0.0719
[1536/15000], training loss: 0.0739
[1544/15000], training loss: 0.0765
[1552/15000], training loss: 0.0677
[1560/15000], training loss: 0.0673
16
AVD_Home_010_1_traj6, ate: 131.85667976530274
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[1568/15000], training loss: 0.0780
[1576/15000], training loss: 0.0916
[1584/15000], training loss: 0.0647
[1592/15000], training loss: 0.0870
[1600/15000], training loss: 0.0840
16
AVD_Home_010_1_traj6, ate: 119.71415545931094
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[1608/15000], training loss: 0.0710
[1616/15000], training loss: 0.0578
[1624/15000], training loss: 0.0715
[1632/15000], training loss: 0.0819
[1640/15000], training loss: 0.0658
16
AVD_Home_010_1_traj6, ate: 107.93009101285283
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[1648/15000], training loss: 0.0761
[1656/15000], training loss: 0.0899
[1664/15000], training loss: 0.0877
[1672/15000], training loss: 0.0737
[1680/15000], training loss: 0.0623
16
AVD_Home_010_1_traj6, ate: 126.94859135194814
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[1688/15000], training loss: 0.0683
[1696/15000], training loss: 0.0613
[1704/15000], training loss: 0.0741
[1712/15000], training loss: 0.0782
[1720/15000], training loss: 0.1080
16
AVD_Home_010_1_traj6, ate: 109.75171581164665
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[1728/15000], training loss: 0.0680
[1736/15000], training loss: 0.0599
[1744/15000], training loss: 0.0690
[1752/15000], training loss: 0.0867
[1760/15000], training loss: 0.0625
16
AVD_Home_010_1_traj6, ate: 122.86642293850302
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[1768/15000], training loss: 0.0830
[1776/15000], training loss: 0.0747
[1784/15000], training loss: 0.0673
[1792/15000], training loss: 0.0727
[1800/15000], training loss: 0.0829
16
AVD_Home_010_1_traj6, ate: 113.83805578854263
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[1808/15000], training loss: 0.0987
[1816/15000], training loss: 0.0891
[1824/15000], training loss: 0.0815
[1832/15000], training loss: 0.0879
[1840/15000], training loss: 0.0946
16
AVD_Home_010_1_traj6, ate: 121.25119662381
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[1848/15000], training loss: 0.0806
[1856/15000], training loss: 0.0703
[1864/15000], training loss: 0.0574
[1872/15000], training loss: 0.0745
[1880/15000], training loss: 0.0733
16
AVD_Home_010_1_traj6, ate: 131.24902969340602
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[1888/15000], training loss: 0.0905
[1896/15000], training loss: 0.0634
[1904/15000], training loss: 0.0575
[1912/15000], training loss: 0.0610
[1920/15000], training loss: 0.0766
16
AVD_Home_010_1_traj6, ate: 113.5152393868876
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[1928/15000], training loss: 0.0717
[1936/15000], training loss: 0.0879
[1944/15000], training loss: 0.0876
[1952/15000], training loss: 0.0663
[1960/15000], training loss: 0.0744
16
AVD_Home_010_1_traj6, ate: 135.07512667998694
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[1968/15000], training loss: 0.0861
[1976/15000], training loss: 0.0828
[1984/15000], training loss: 0.0778
[1992/15000], training loss: 0.0890
[2000/15000], training loss: 0.0687
16
AVD_Home_010_1_traj6, ate: 133.91759546389017
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[2008/15000], training loss: 0.0663
[2016/15000], training loss: 0.0969
[2024/15000], training loss: 0.0597
[2032/15000], training loss: 0.0710
[2040/15000], training loss: 0.0932
16
AVD_Home_010_1_traj6, ate: 114.60834340717996
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[2048/15000], training loss: 0.0712
[2056/15000], training loss: 0.0593
[2064/15000], training loss: 0.0745
[2072/15000], training loss: 0.0896
[2080/15000], training loss: 0.0964
16
AVD_Home_010_1_traj6, ate: 109.80380784876989
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[2088/15000], training loss: 0.0942
[2096/15000], training loss: 0.0889
[2104/15000], training loss: 0.0768
[2112/15000], training loss: 0.0599
[2120/15000], training loss: 0.0851
16
AVD_Home_010_1_traj6, ate: 125.21052040934251
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[2128/15000], training loss: 0.0789
[2136/15000], training loss: 0.0749
[2144/15000], training loss: 0.0711
[2152/15000], training loss: 0.0746
[2160/15000], training loss: 0.0752
16
AVD_Home_010_1_traj6, ate: 123.71437071693286
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[2168/15000], training loss: 0.0551
[2176/15000], training loss: 0.0674
[2184/15000], training loss: 0.0695
[2192/15000], training loss: 0.0693
[2200/15000], training loss: 0.0715
16
AVD_Home_010_1_traj6, ate: 121.23674746164102
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[2208/15000], training loss: 0.0495
[2216/15000], training loss: 0.0604
[2224/15000], training loss: 0.0528
[2232/15000], training loss: 0.0649
[2240/15000], training loss: 0.0679
16
AVD_Home_010_1_traj6, ate: 117.3510619683263
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[2248/15000], training loss: 0.0648
[2256/15000], training loss: 0.0759
[2264/15000], training loss: 0.0750
[2272/15000], training loss: 0.0568
[2280/15000], training loss: 0.0566
16
AVD_Home_010_1_traj6, ate: 124.57785404650762
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[2288/15000], training loss: 0.0652
[2296/15000], training loss: 0.0944
[2304/15000], training loss: 0.0808
[2312/15000], training loss: 0.0660
[2320/15000], training loss: 0.0736
16
AVD_Home_010_1_traj6, ate: 114.69687768641157
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[2328/15000], training loss: 0.0746
[2336/15000], training loss: 0.0750
[2344/15000], training loss: 0.0703
[2352/15000], training loss: 0.0661
[2360/15000], training loss: 0.0858
16
AVD_Home_010_1_traj6, ate: 126.6035356713373
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[2368/15000], training loss: 0.0490
[2376/15000], training loss: 0.0808
[2384/15000], training loss: 0.0700
[2392/15000], training loss: 0.0622
[2400/15000], training loss: 0.0590
16
AVD_Home_010_1_traj6, ate: 115.98954732323988
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[2408/15000], training loss: 0.0731
[2416/15000], training loss: 0.0640
[2424/15000], training loss: 0.0680
[2432/15000], training loss: 0.0700
[2440/15000], training loss: 0.0707
16
AVD_Home_010_1_traj6, ate: 121.10070791679061
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[2448/15000], training loss: 0.0725
[2456/15000], training loss: 0.0678
[2464/15000], training loss: 0.0793
[2472/15000], training loss: 0.0583
[2480/15000], training loss: 0.0667
16
AVD_Home_010_1_traj6, ate: 134.7616033226679
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[2488/15000], training loss: 0.0630
[2496/15000], training loss: 0.0673
[2504/15000], training loss: 0.0755
[2512/15000], training loss: 0.0709
[2520/15000], training loss: 0.0652
16
AVD_Home_010_1_traj6, ate: 127.91823455829662
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[2528/15000], training loss: 0.0687
[2536/15000], training loss: 0.0653
[2544/15000], training loss: 0.0520
[2552/15000], training loss: 0.0596
[2560/15000], training loss: 0.0585
16
AVD_Home_010_1_traj6, ate: 121.58007580549813
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[2568/15000], training loss: 0.0843
[2576/15000], training loss: 0.0531
[2584/15000], training loss: 0.0790
[2592/15000], training loss: 0.0765
[2600/15000], training loss: 0.0685
16
AVD_Home_010_1_traj6, ate: 127.26470516760126
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[2608/15000], training loss: 0.0685
[2616/15000], training loss: 0.0720
[2624/15000], training loss: 0.0621
[2632/15000], training loss: 0.0753
[2640/15000], training loss: 0.0759
16
AVD_Home_010_1_traj6, ate: 116.55235105869602
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[2648/15000], training loss: 0.0569
[2656/15000], training loss: 0.0818
[2664/15000], training loss: 0.0748
[2672/15000], training loss: 0.0723
[2680/15000], training loss: 0.0735
16
AVD_Home_010_1_traj6, ate: 136.38783712781682
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[2688/15000], training loss: 0.0804
[2696/15000], training loss: 0.0664
[2704/15000], training loss: 0.0583
[2712/15000], training loss: 0.0809
[2720/15000], training loss: 0.1089
16
AVD_Home_010_1_traj6, ate: 108.92015363372106
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[2728/15000], training loss: 0.0608
[2736/15000], training loss: 0.0658
[2744/15000], training loss: 0.0556
[2752/15000], training loss: 0.0973
[2760/15000], training loss: 0.0901
16
AVD_Home_010_1_traj6, ate: 148.00624922841243
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[2768/15000], training loss: 0.0585
[2776/15000], training loss: 0.0741
[2784/15000], training loss: 0.0807
[2792/15000], training loss: 0.0731
[2800/15000], training loss: 0.0565
16
AVD_Home_010_1_traj6, ate: 130.57690030592101
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[2808/15000], training loss: 0.0684
[2816/15000], training loss: 0.0508
[2824/15000], training loss: 0.0526
[2832/15000], training loss: 0.0665
[2840/15000], training loss: 0.0788
16
AVD_Home_010_1_traj6, ate: 125.79188339832528
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[2848/15000], training loss: 0.0541
[2856/15000], training loss: 0.0501
[2864/15000], training loss: 0.0832
[2872/15000], training loss: 0.0644
[2880/15000], training loss: 0.0619
16
AVD_Home_010_1_traj6, ate: 122.51427279129769
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[2888/15000], training loss: 0.0622
[2896/15000], training loss: 0.0896
[2904/15000], training loss: 0.0661
[2912/15000], training loss: 0.0510
[2920/15000], training loss: 0.1002
16
AVD_Home_010_1_traj6, ate: 143.13543107597795
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[2928/15000], training loss: 0.0861
[2936/15000], training loss: 0.0563
[2944/15000], training loss: 0.0710
[2952/15000], training loss: 0.0738
[2960/15000], training loss: 0.0700
16
AVD_Home_010_1_traj6, ate: 153.279090736227
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[2968/15000], training loss: 0.0737
[2976/15000], training loss: 0.0858
[2984/15000], training loss: 0.0624
[2992/15000], training loss: 0.0664
[3000/15000], training loss: 0.0635
16
AVD_Home_010_1_traj6, ate: 140.81953927302715
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[3008/15000], training loss: 0.0542
[3016/15000], training loss: 0.0530
[3024/15000], training loss: 0.0527
[3032/15000], training loss: 0.0512
[3040/15000], training loss: 0.0692
16
AVD_Home_010_1_traj6, ate: 130.2064889871156
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[3048/15000], training loss: 0.0504
[3056/15000], training loss: 0.0545
[3064/15000], training loss: 0.0748
[3072/15000], training loss: 0.0730
[3080/15000], training loss: 0.0736
16
AVD_Home_010_1_traj6, ate: 122.46001204151602
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[3088/15000], training loss: 0.0887
[3096/15000], training loss: 0.0611
[3104/15000], training loss: 0.0629
[3112/15000], training loss: 0.0615
[3120/15000], training loss: 0.0644
16
AVD_Home_010_1_traj6, ate: 127.44106230317311
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[3128/15000], training loss: 0.0534
[3136/15000], training loss: 0.0411
[3144/15000], training loss: 0.0614
[3152/15000], training loss: 0.0698
[3160/15000], training loss: 0.0657
16
AVD_Home_010_1_traj6, ate: 131.13056115404018
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[3168/15000], training loss: 0.0580
[3176/15000], training loss: 0.0442
[3184/15000], training loss: 0.0913
[3192/15000], training loss: 0.0714
[3200/15000], training loss: 0.0576
16
AVD_Home_010_1_traj6, ate: 125.57637643459205
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[3208/15000], training loss: 0.0478
[3216/15000], training loss: 0.1068
[3224/15000], training loss: 0.0829
[3232/15000], training loss: 0.0780
[3240/15000], training loss: 0.0638
16
AVD_Home_010_1_traj6, ate: 130.4808836447811
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[3248/15000], training loss: 0.0568
[3256/15000], training loss: 0.0538
[3264/15000], training loss: 0.0693
[3272/15000], training loss: 0.0656
[3280/15000], training loss: 0.0422
16
AVD_Home_010_1_traj6, ate: 136.22572268772043
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[3288/15000], training loss: 0.0551
[3296/15000], training loss: 0.0675
[3304/15000], training loss: 0.0593
[3312/15000], training loss: 0.0595
[3320/15000], training loss: 0.0572
16
AVD_Home_010_1_traj6, ate: 144.66577421322904
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[3328/15000], training loss: 0.0663
[3336/15000], training loss: 0.0572
[3344/15000], training loss: 0.0761
[3352/15000], training loss: 0.0708
[3360/15000], training loss: 0.0742
16
AVD_Home_010_1_traj6, ate: 129.2857677465682
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[3368/15000], training loss: 0.0728
[3376/15000], training loss: 0.0506
[3384/15000], training loss: 0.0535
[3392/15000], training loss: 0.0714
[3400/15000], training loss: 0.0556
16
AVD_Home_010_1_traj6, ate: 129.29542596865574
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[3408/15000], training loss: 0.0539
[3416/15000], training loss: 0.0687
[3424/15000], training loss: 0.0612
[3432/15000], training loss: 0.0710
[3440/15000], training loss: 0.0749
16
AVD_Home_010_1_traj6, ate: 128.86363265096693
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[3448/15000], training loss: 0.0763
[3456/15000], training loss: 0.0956
[3464/15000], training loss: 0.0670
[3472/15000], training loss: 0.0697
[3480/15000], training loss: 0.0530
16
AVD_Home_010_1_traj6, ate: 139.84141153571449
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[3488/15000], training loss: 0.0632
[3496/15000], training loss: 0.0838
[3504/15000], training loss: 0.0692
[3512/15000], training loss: 0.0478
[3520/15000], training loss: 0.0538
16
AVD_Home_010_1_traj6, ate: 147.6452480996385
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[3528/15000], training loss: 0.0577
[3536/15000], training loss: 0.0562
[3544/15000], training loss: 0.0728
[3552/15000], training loss: 0.0688
[3560/15000], training loss: 0.0762
16
AVD_Home_010_1_traj6, ate: 131.4766829349442
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[3568/15000], training loss: 0.0557
[3576/15000], training loss: 0.0594
[3584/15000], training loss: 0.0608
[3592/15000], training loss: 0.0629
[3600/15000], training loss: 0.0643
16
AVD_Home_010_1_traj6, ate: 135.75948233709852
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[3608/15000], training loss: 0.0629
[3616/15000], training loss: 0.0518
[3624/15000], training loss: 0.0659
[3632/15000], training loss: 0.0638
[3640/15000], training loss: 0.0754
16
AVD_Home_010_1_traj6, ate: 129.47230688351632
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[3648/15000], training loss: 0.0593
[3656/15000], training loss: 0.0696
[3664/15000], training loss: 0.0622
[3672/15000], training loss: 0.0609
[3680/15000], training loss: 0.0683
16
AVD_Home_010_1_traj6, ate: 131.49693258652078
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[3688/15000], training loss: 0.0487
[3696/15000], training loss: 0.0648
[3704/15000], training loss: 0.0716
[3712/15000], training loss: 0.0667
[3720/15000], training loss: 0.0584
16
AVD_Home_010_1_traj6, ate: 136.38181246152104
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[3728/15000], training loss: 0.0561
[3736/15000], training loss: 0.0559
[3744/15000], training loss: 0.0599
[3752/15000], training loss: 0.0497
[3760/15000], training loss: 0.0558
16
AVD_Home_010_1_traj6, ate: 129.89993857910267
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[3768/15000], training loss: 0.0508
[3776/15000], training loss: 0.0444
[3784/15000], training loss: 0.0618
[3792/15000], training loss: 0.0486
[3800/15000], training loss: 0.0551
16
AVD_Home_010_1_traj6, ate: 131.37709342257747
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[3808/15000], training loss: 0.0617
[3816/15000], training loss: 0.0641
[3824/15000], training loss: 0.0622
[3832/15000], training loss: 0.0489
[3840/15000], training loss: 0.0781
16
AVD_Home_010_1_traj6, ate: 126.08030987053137
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[3848/15000], training loss: 0.0634
[3856/15000], training loss: 0.0600
[3864/15000], training loss: 0.0557
[3872/15000], training loss: 0.0888
[3880/15000], training loss: 0.0804
16
AVD_Home_010_1_traj6, ate: 137.42023836480894
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[3888/15000], training loss: 0.0464
[3896/15000], training loss: 0.0523
[3904/15000], training loss: 0.0721
[3912/15000], training loss: 0.0498
[3920/15000], training loss: 0.0793
16
AVD_Home_010_1_traj6, ate: 127.07507107466915
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[3928/15000], training loss: 0.0709
[3936/15000], training loss: 0.0689
[3944/15000], training loss: 0.0875
[3952/15000], training loss: 0.0588
[3960/15000], training loss: 0.0473
16
AVD_Home_010_1_traj6, ate: 137.93836887240602
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[3968/15000], training loss: 0.0723
[3976/15000], training loss: 0.0870
[3984/15000], training loss: 0.0628
[3992/15000], training loss: 0.0570
[4000/15000], training loss: 0.0604
16
AVD_Home_010_1_traj6, ate: 136.40194703603055
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[4008/15000], training loss: 0.0492
[4016/15000], training loss: 0.0580
[4024/15000], training loss: 0.0613
[4032/15000], training loss: 0.0649
[4040/15000], training loss: 0.0613
16
AVD_Home_010_1_traj6, ate: 130.14396435096776
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[4048/15000], training loss: 0.0469
[4056/15000], training loss: 0.0661
[4064/15000], training loss: 0.0571
[4072/15000], training loss: 0.0742
[4080/15000], training loss: 0.0457
16
AVD_Home_010_1_traj6, ate: 133.5401831822682
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[4088/15000], training loss: 0.0593
[4096/15000], training loss: 0.0476
[4104/15000], training loss: 0.0718
[4112/15000], training loss: 0.0659
[4120/15000], training loss: 0.0840
16
AVD_Home_010_1_traj6, ate: 118.90767042692548
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[4128/15000], training loss: 0.0499
[4136/15000], training loss: 0.0582
[4144/15000], training loss: 0.0655
[4152/15000], training loss: 0.0782
[4160/15000], training loss: 0.0575
16
AVD_Home_010_1_traj6, ate: 134.05434126305272
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[4168/15000], training loss: 0.0492
[4176/15000], training loss: 0.0622
[4184/15000], training loss: 0.0585
[4192/15000], training loss: 0.0465
[4200/15000], training loss: 0.0590
16
AVD_Home_010_1_traj6, ate: 133.54606708503835
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[4208/15000], training loss: 0.0674
[4216/15000], training loss: 0.0532
[4224/15000], training loss: 0.0650
[4232/15000], training loss: 0.0684
[4240/15000], training loss: 0.0460
16
AVD_Home_010_1_traj6, ate: 137.20849873902978
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[4248/15000], training loss: 0.1135
[4256/15000], training loss: 0.0658
[4264/15000], training loss: 0.0805
[4272/15000], training loss: 0.0832
[4280/15000], training loss: 0.1107
16
AVD_Home_010_1_traj6, ate: 129.2508847338456
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[4288/15000], training loss: 0.0590
[4296/15000], training loss: 0.0690
[4304/15000], training loss: 0.0668
[4312/15000], training loss: 0.0757
[4320/15000], training loss: 0.0715
16
AVD_Home_010_1_traj6, ate: 129.37221918379632
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[4328/15000], training loss: 0.0525
[4336/15000], training loss: 0.0570
[4344/15000], training loss: 0.0553
[4352/15000], training loss: 0.0580
[4360/15000], training loss: 0.0532
16
AVD_Home_010_1_traj6, ate: 135.8183557479805
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[4368/15000], training loss: 0.0727
[4376/15000], training loss: 0.0613
[4384/15000], training loss: 0.0595
[4392/15000], training loss: 0.0561
[4400/15000], training loss: 0.0572
16
AVD_Home_010_1_traj6, ate: 140.67694012615587
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[4408/15000], training loss: 0.0636
[4416/15000], training loss: 0.0635
[4424/15000], training loss: 0.0520
[4432/15000], training loss: 0.0618
[4440/15000], training loss: 0.0696
16
AVD_Home_010_1_traj6, ate: 137.38861362238367
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[4448/15000], training loss: 0.0607
[4456/15000], training loss: 0.0591
[4464/15000], training loss: 0.0965
[4472/15000], training loss: 0.0642
[4480/15000], training loss: 0.0820
16
AVD_Home_010_1_traj6, ate: 142.3938163177947
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[4488/15000], training loss: 0.0720
[4496/15000], training loss: 0.1171
[4504/15000], training loss: 0.0849
[4512/15000], training loss: 0.0630
[4520/15000], training loss: 0.0524
16
AVD_Home_010_1_traj6, ate: 129.73563737086195
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[4528/15000], training loss: 0.0465
[4536/15000], training loss: 0.0468
[4544/15000], training loss: 0.0610
[4552/15000], training loss: 0.0445
[4560/15000], training loss: 0.0829
16
AVD_Home_010_1_traj6, ate: 152.29356200076793
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[4568/15000], training loss: 0.0604
[4576/15000], training loss: 0.0657
[4584/15000], training loss: 0.0745
[4592/15000], training loss: 0.0522
[4600/15000], training loss: 0.0622
16
AVD_Home_010_1_traj6, ate: 145.01730252184794
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[4608/15000], training loss: 0.0572
[4616/15000], training loss: 0.0471
[4624/15000], training loss: 0.0548
[4632/15000], training loss: 0.0586
[4640/15000], training loss: 0.0757
16
AVD_Home_010_1_traj6, ate: 123.40497700203042
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[4648/15000], training loss: 0.0723
[4656/15000], training loss: 0.0584
[4664/15000], training loss: 0.0877
[4672/15000], training loss: 0.0567
[4680/15000], training loss: 0.0611
16
AVD_Home_010_1_traj6, ate: 139.59249082798308
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[4688/15000], training loss: 0.0772
[4696/15000], training loss: 0.0720
[4704/15000], training loss: 0.0620
[4712/15000], training loss: 0.0427
[4720/15000], training loss: 0.0427
16
AVD_Home_010_1_traj6, ate: 141.9617649965564
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[4728/15000], training loss: 0.0694
[4736/15000], training loss: 0.0841
[4744/15000], training loss: 0.0540
[4752/15000], training loss: 0.0571
[4760/15000], training loss: 0.0749
16
AVD_Home_010_1_traj6, ate: 137.94059856738644
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[4768/15000], training loss: 0.0556
[4776/15000], training loss: 0.0429
[4784/15000], training loss: 0.0848
[4792/15000], training loss: 0.0643
[4800/15000], training loss: 0.0570
16
AVD_Home_010_1_traj6, ate: 135.3410426033634
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[4808/15000], training loss: 0.0547
[4816/15000], training loss: 0.0629
[4824/15000], training loss: 0.0885
[4832/15000], training loss: 0.0526
[4840/15000], training loss: 0.0664
16
AVD_Home_010_1_traj6, ate: 134.1138963320463
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[4848/15000], training loss: 0.0743
[4856/15000], training loss: 0.0569
[4864/15000], training loss: 0.0443
[4872/15000], training loss: 0.0617
[4880/15000], training loss: 0.0528
16
AVD_Home_010_1_traj6, ate: 140.13099627015742
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[4888/15000], training loss: 0.0577
[4896/15000], training loss: 0.0415
[4904/15000], training loss: 0.0553
[4912/15000], training loss: 0.0547
[4920/15000], training loss: 0.0513
16
AVD_Home_010_1_traj6, ate: 138.37373374990034
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[4928/15000], training loss: 0.0946
[4936/15000], training loss: 0.0536
[4944/15000], training loss: 0.0826
[4952/15000], training loss: 0.0482
[4960/15000], training loss: 0.0515
16
AVD_Home_010_1_traj6, ate: 141.95301536649012
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[4968/15000], training loss: 0.0657
[4976/15000], training loss: 0.0841
[4984/15000], training loss: 0.0589
[4992/15000], training loss: 0.0410
[5000/15000], training loss: 0.0797
16
AVD_Home_010_1_traj6, ate: 142.37498967721908
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[5008/15000], training loss: 0.0612
[5016/15000], training loss: 0.0572
[5024/15000], training loss: 0.0657
[5032/15000], training loss: 0.0442
[5040/15000], training loss: 0.0542
16
AVD_Home_010_1_traj6, ate: 134.1439959323359
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[5048/15000], training loss: 0.0704
[5056/15000], training loss: 0.0817
[5064/15000], training loss: 0.0636
[5072/15000], training loss: 0.0535
[5080/15000], training loss: 0.0547
16
AVD_Home_010_1_traj6, ate: 132.67566930949977
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[5088/15000], training loss: 0.0543
[5096/15000], training loss: 0.0543
[5104/15000], training loss: 0.0488
[5112/15000], training loss: 0.0747
[5120/15000], training loss: 0.0789
16
AVD_Home_010_1_traj6, ate: 140.02097678179794
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[5128/15000], training loss: 0.0640
[5136/15000], training loss: 0.0870
[5144/15000], training loss: 0.0547
[5152/15000], training loss: 0.0545
[5160/15000], training loss: 0.0578
16
AVD_Home_010_1_traj6, ate: 132.6230981383221
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[5168/15000], training loss: 0.0542
[5176/15000], training loss: 0.0571
[5184/15000], training loss: 0.0689
[5192/15000], training loss: 0.0810
[5200/15000], training loss: 0.0775
16
AVD_Home_010_1_traj6, ate: 128.90524273011073
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[5208/15000], training loss: 0.0788
[5216/15000], training loss: 0.0546
[5224/15000], training loss: 0.0824
[5232/15000], training loss: 0.0422
[5240/15000], training loss: 0.0681
16
AVD_Home_010_1_traj6, ate: 143.6649970225326
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[5248/15000], training loss: 0.0577
[5256/15000], training loss: 0.0535
[5264/15000], training loss: 0.0545
[5272/15000], training loss: 0.0668
[5280/15000], training loss: 0.0665
16
AVD_Home_010_1_traj6, ate: 133.0059821152288
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[5288/15000], training loss: 0.0611
[5296/15000], training loss: 0.0614
[5304/15000], training loss: 0.1049
[5312/15000], training loss: 0.0411
[5320/15000], training loss: 0.0740
16
AVD_Home_010_1_traj6, ate: 132.1789952161105
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[5328/15000], training loss: 0.0942
[5336/15000], training loss: 0.0704
[5344/15000], training loss: 0.0503
[5352/15000], training loss: 0.0743
[5360/15000], training loss: 0.0694
16
AVD_Home_010_1_traj6, ate: 127.30935742666206
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[5368/15000], training loss: 0.0738
[5376/15000], training loss: 0.0523
[5384/15000], training loss: 0.0760
[5392/15000], training loss: 0.0426
[5400/15000], training loss: 0.0624
16
AVD_Home_010_1_traj6, ate: 133.21890049019942
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[5408/15000], training loss: 0.0711
[5416/15000], training loss: 0.0570
[5424/15000], training loss: 0.0648
[5432/15000], training loss: 0.0454
[5440/15000], training loss: 0.0539
16
AVD_Home_010_1_traj6, ate: 148.25174384107652
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[5448/15000], training loss: 0.0870
[5456/15000], training loss: 0.0712
[5464/15000], training loss: 0.0667
[5472/15000], training loss: 0.0617
[5480/15000], training loss: 0.0743
16
AVD_Home_010_1_traj6, ate: 128.09943302103457
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[5488/15000], training loss: 0.0610
[5496/15000], training loss: 0.0521
[5504/15000], training loss: 0.0685
[5512/15000], training loss: 0.0513
[5520/15000], training loss: 0.0618
16
AVD_Home_010_1_traj6, ate: 135.73455099156297
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[5528/15000], training loss: 0.0707
[5536/15000], training loss: 0.0672
[5544/15000], training loss: 0.0409
[5552/15000], training loss: 0.0570
[5560/15000], training loss: 0.0664
16
AVD_Home_010_1_traj6, ate: 134.12151735236608
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[5568/15000], training loss: 0.0509
[5576/15000], training loss: 0.0597
[5584/15000], training loss: 0.0694
[5592/15000], training loss: 0.0602
[5600/15000], training loss: 0.0555
16
AVD_Home_010_1_traj6, ate: 130.3434567902346
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[5608/15000], training loss: 0.0499
[5616/15000], training loss: 0.0396
[5624/15000], training loss: 0.0727
[5632/15000], training loss: 0.0633
[5640/15000], training loss: 0.0488
16
AVD_Home_010_1_traj6, ate: 131.92303716095702
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[5648/15000], training loss: 0.0467
[5656/15000], training loss: 0.0682
[5664/15000], training loss: 0.0853
[5672/15000], training loss: 0.0585
[5680/15000], training loss: 0.0462
16
AVD_Home_010_1_traj6, ate: 153.66974664334276
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[5688/15000], training loss: 0.0600
[5696/15000], training loss: 0.0755
[5704/15000], training loss: 0.0513
[5712/15000], training loss: 0.0701
[5720/15000], training loss: 0.0584
16
AVD_Home_010_1_traj6, ate: 139.01173561845565
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[5728/15000], training loss: 0.0585
[5736/15000], training loss: 0.0531
[5744/15000], training loss: 0.0623
[5752/15000], training loss: 0.0669
[5760/15000], training loss: 0.0449
16
AVD_Home_010_1_traj6, ate: 139.99804826229652
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[5768/15000], training loss: 0.0759
[5776/15000], training loss: 0.0618
[5784/15000], training loss: 0.0545
[5792/15000], training loss: 0.0487
[5800/15000], training loss: 0.0652
16
AVD_Home_010_1_traj6, ate: 139.0972793715447
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[5808/15000], training loss: 0.0551
[5816/15000], training loss: 0.0712
[5824/15000], training loss: 0.0402
[5832/15000], training loss: 0.0492
[5840/15000], training loss: 0.0476
16
AVD_Home_010_1_traj6, ate: 140.78921488588065
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[5848/15000], training loss: 0.0573
[5856/15000], training loss: 0.0526
[5864/15000], training loss: 0.1007
[5872/15000], training loss: 0.0670
[5880/15000], training loss: 0.0541
16
AVD_Home_010_1_traj6, ate: 143.97850100117006
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[5888/15000], training loss: 0.0467
[5896/15000], training loss: 0.0499
[5904/15000], training loss: 0.0456
[5912/15000], training loss: 0.0430
[5920/15000], training loss: 0.0568
16
AVD_Home_010_1_traj6, ate: 138.48328722419754
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[5928/15000], training loss: 0.0708
[5936/15000], training loss: 0.0811
[5944/15000], training loss: 0.0602
[5952/15000], training loss: 0.0672
[5960/15000], training loss: 0.0747
16
AVD_Home_010_1_traj6, ate: 133.9771024688196
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[5968/15000], training loss: 0.0564
[5976/15000], training loss: 0.0687
[5984/15000], training loss: 0.0534
[5992/15000], training loss: 0.0432
[6000/15000], training loss: 0.0509
16
AVD_Home_010_1_traj6, ate: 139.7338359188048
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[6008/15000], training loss: 0.0493
[6016/15000], training loss: 0.0637
[6024/15000], training loss: 0.0632
[6032/15000], training loss: 0.0598
[6040/15000], training loss: 0.0552
16
AVD_Home_010_1_traj6, ate: 135.66923126283274
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[6048/15000], training loss: 0.0806
[6056/15000], training loss: 0.0443
[6064/15000], training loss: 0.0602
[6072/15000], training loss: 0.0618
[6080/15000], training loss: 0.0620
16
AVD_Home_010_1_traj6, ate: 137.07517374917154
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[6088/15000], training loss: 0.0466
[6096/15000], training loss: 0.0416
[6104/15000], training loss: 0.0622
[6112/15000], training loss: 0.0599
[6120/15000], training loss: 0.0745
16
AVD_Home_010_1_traj6, ate: 132.54160330647022
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[6128/15000], training loss: 0.0951
[6136/15000], training loss: 0.0600
[6144/15000], training loss: 0.0701
[6152/15000], training loss: 0.0405
[6160/15000], training loss: 0.0671
16
AVD_Home_010_1_traj6, ate: 134.65228410311835
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[6168/15000], training loss: 0.0433
[6176/15000], training loss: 0.0501
[6184/15000], training loss: 0.0579
[6192/15000], training loss: 0.0473
[6200/15000], training loss: 0.0474
16
AVD_Home_010_1_traj6, ate: 133.0942555122932
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[6208/15000], training loss: 0.0678
[6216/15000], training loss: 0.0404
[6224/15000], training loss: 0.0421
[6232/15000], training loss: 0.0582
[6240/15000], training loss: 0.0499
16
AVD_Home_010_1_traj6, ate: 134.2593122772871
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[6248/15000], training loss: 0.0597
[6256/15000], training loss: 0.0590
[6264/15000], training loss: 0.0370
[6272/15000], training loss: 0.0443
[6280/15000], training loss: 0.0696
16
AVD_Home_010_1_traj6, ate: 133.23915900890808
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[6288/15000], training loss: 0.0830
[6296/15000], training loss: 0.0548
[6304/15000], training loss: 0.0362
[6312/15000], training loss: 0.0630
[6320/15000], training loss: 0.0544
16
AVD_Home_010_1_traj6, ate: 137.43946698378872
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[6328/15000], training loss: 0.0408
[6336/15000], training loss: 0.0546
[6344/15000], training loss: 0.0588
[6352/15000], training loss: 0.0612
[6360/15000], training loss: 0.0397
16
AVD_Home_010_1_traj6, ate: 131.64488111128958
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[6368/15000], training loss: 0.0480
[6376/15000], training loss: 0.0472
[6384/15000], training loss: 0.0494
[6392/15000], training loss: 0.0583
[6400/15000], training loss: 0.0430
16
AVD_Home_010_1_traj6, ate: 141.1841842978855
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[6408/15000], training loss: 0.0531
[6416/15000], training loss: 0.0625
[6424/15000], training loss: 0.0487
[6432/15000], training loss: 0.0573
[6440/15000], training loss: 0.0557
16
AVD_Home_010_1_traj6, ate: 133.3926544840601
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[6448/15000], training loss: 0.0356
[6456/15000], training loss: 0.0491
[6464/15000], training loss: 0.0767
[6472/15000], training loss: 0.0607
[6480/15000], training loss: 0.0676
16
AVD_Home_010_1_traj6, ate: 147.56396035117842
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[6488/15000], training loss: 0.0502
[6496/15000], training loss: 0.0437
[6504/15000], training loss: 0.0547
[6512/15000], training loss: 0.0729
[6520/15000], training loss: 0.0603
16
AVD_Home_010_1_traj6, ate: 139.8940319275644
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[6528/15000], training loss: 0.0610
[6536/15000], training loss: 0.0444
[6544/15000], training loss: 0.0959
[6552/15000], training loss: 0.0362
[6560/15000], training loss: 0.0522
16
AVD_Home_010_1_traj6, ate: 140.77328042853077
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[6568/15000], training loss: 0.0835
[6576/15000], training loss: 0.0587
[6584/15000], training loss: 0.0522
[6592/15000], training loss: 0.0661
[6600/15000], training loss: 0.0640
16
AVD_Home_010_1_traj6, ate: 136.683693185155
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[6608/15000], training loss: 0.0457
[6616/15000], training loss: 0.0580
[6624/15000], training loss: 0.0409
[6632/15000], training loss: 0.0626
[6640/15000], training loss: 0.0359
16
AVD_Home_010_1_traj6, ate: 144.21906404865368
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[6648/15000], training loss: 0.0844
[6656/15000], training loss: 0.0512
[6664/15000], training loss: 0.0372
[6672/15000], training loss: 0.0495
[6680/15000], training loss: 0.0498
16
AVD_Home_010_1_traj6, ate: 134.56673018251405
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[6688/15000], training loss: 0.0592
[6696/15000], training loss: 0.0392
[6704/15000], training loss: 0.0570
[6712/15000], training loss: 0.0594
[6720/15000], training loss: 0.0708
16
AVD_Home_010_1_traj6, ate: 135.18612001749366
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[6728/15000], training loss: 0.0683
[6736/15000], training loss: 0.0688
[6744/15000], training loss: 0.0575
[6752/15000], training loss: 0.0447
[6760/15000], training loss: 0.0429
16
AVD_Home_010_1_traj6, ate: 139.92538146675025
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[6768/15000], training loss: 0.0600
[6776/15000], training loss: 0.0868
[6784/15000], training loss: 0.0560
[6792/15000], training loss: 0.0402
[6800/15000], training loss: 0.0685
16
AVD_Home_010_1_traj6, ate: 141.6325178984972
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[6808/15000], training loss: 0.0580
[6816/15000], training loss: 0.0387
[6824/15000], training loss: 0.0431
[6832/15000], training loss: 0.0601
[6840/15000], training loss: 0.0445
16
AVD_Home_010_1_traj6, ate: 138.2048927610804
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[6848/15000], training loss: 0.0523
[6856/15000], training loss: 0.0548
[6864/15000], training loss: 0.0675
[6872/15000], training loss: 0.0489
[6880/15000], training loss: 0.0606
16
AVD_Home_010_1_traj6, ate: 135.8001821113955
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[6888/15000], training loss: 0.0497
[6896/15000], training loss: 0.0494
[6904/15000], training loss: 0.0481
[6912/15000], training loss: 0.0521
[6920/15000], training loss: 0.0718
16
AVD_Home_010_1_traj6, ate: 138.42090687621948
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[6928/15000], training loss: 0.0618
[6936/15000], training loss: 0.0456
[6944/15000], training loss: 0.0350
[6952/15000], training loss: 0.0528
[6960/15000], training loss: 0.0534
16
AVD_Home_010_1_traj6, ate: 137.15620562154797
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[6968/15000], training loss: 0.0512
[6976/15000], training loss: 0.0519
[6984/15000], training loss: 0.0508
[6992/15000], training loss: 0.0527
[7000/15000], training loss: 0.0801
16
AVD_Home_010_1_traj6, ate: 136.4228911478859
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[7008/15000], training loss: 0.0473
[7016/15000], training loss: 0.0396
[7024/15000], training loss: 0.0522
[7032/15000], training loss: 0.0351
[7040/15000], training loss: 0.0458
16
AVD_Home_010_1_traj6, ate: 147.6609706362215
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[7048/15000], training loss: 0.0598
[7056/15000], training loss: 0.0592
[7064/15000], training loss: 0.0632
[7072/15000], training loss: 0.0446
[7080/15000], training loss: 0.0436
16
AVD_Home_010_1_traj6, ate: 135.95064676726832
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[7088/15000], training loss: 0.0731
[7096/15000], training loss: 0.0615
[7104/15000], training loss: 0.0835
[7112/15000], training loss: 0.0602
[7120/15000], training loss: 0.0467
16
AVD_Home_010_1_traj6, ate: 144.4031552744806
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[7128/15000], training loss: 0.0523
[7136/15000], training loss: 0.0869
[7144/15000], training loss: 0.0684
[7152/15000], training loss: 0.0412
[7160/15000], training loss: 0.0493
16
AVD_Home_010_1_traj6, ate: 138.05787314140014
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[7168/15000], training loss: 0.0517
[7176/15000], training loss: 0.0560
[7184/15000], training loss: 0.0583
[7192/15000], training loss: 0.0651
[7200/15000], training loss: 0.0365
16
AVD_Home_010_1_traj6, ate: 142.05791887356077
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[7208/15000], training loss: 0.0506
[7216/15000], training loss: 0.0479
[7224/15000], training loss: 0.0635
[7232/15000], training loss: 0.0569
[7240/15000], training loss: 0.0492
16
AVD_Home_010_1_traj6, ate: 138.41867691597594
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[7248/15000], training loss: 0.0508
[7256/15000], training loss: 0.0451
[7264/15000], training loss: 0.0413
[7272/15000], training loss: 0.0582
[7280/15000], training loss: 0.0763
16
AVD_Home_010_1_traj6, ate: 142.73582262580365
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[7288/15000], training loss: 0.0714
[7296/15000], training loss: 0.0404
[7304/15000], training loss: 0.0633
[7312/15000], training loss: 0.0684
[7320/15000], training loss: 0.0774
16
AVD_Home_010_1_traj6, ate: 134.44205486078792
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[7328/15000], training loss: 0.0629
[7336/15000], training loss: 0.0581
[7344/15000], training loss: 0.0550
[7352/15000], training loss: 0.0541
[7360/15000], training loss: 0.0517
16
AVD_Home_010_1_traj6, ate: 138.89256368974654
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[7368/15000], training loss: 0.0668
[7376/15000], training loss: 0.0607
[7384/15000], training loss: 0.0558
[7392/15000], training loss: 0.0477
[7400/15000], training loss: 0.0471
16
AVD_Home_010_1_traj6, ate: 143.41850233708576
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[7408/15000], training loss: 0.0374
[7416/15000], training loss: 0.0368
[7424/15000], training loss: 0.0554
[7432/15000], training loss: 0.0640
[7440/15000], training loss: 0.0704
16
AVD_Home_010_1_traj6, ate: 138.9108619952333
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[7448/15000], training loss: 0.0747
[7456/15000], training loss: 0.0466
[7464/15000], training loss: 0.0542
[7472/15000], training loss: 0.0588
[7480/15000], training loss: 0.0421
16
AVD_Home_010_1_traj6, ate: 139.28915058957176
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[7488/15000], training loss: 0.0603
[7496/15000], training loss: 0.0453
[7504/15000], training loss: 0.0592
[7512/15000], training loss: 0.0420
[7520/15000], training loss: 0.0546
16
AVD_Home_010_1_traj6, ate: 145.09290280762804
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[7528/15000], training loss: 0.0670
[7536/15000], training loss: 0.0556
[7544/15000], training loss: 0.0706
[7552/15000], training loss: 0.0565
[7560/15000], training loss: 0.0506
16
AVD_Home_010_1_traj6, ate: 140.44738624622198
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[7568/15000], training loss: 0.0610
[7576/15000], training loss: 0.0634
[7584/15000], training loss: 0.0591
[7592/15000], training loss: 0.0454
[7600/15000], training loss: 0.0503
16
AVD_Home_010_1_traj6, ate: 138.1233281421398
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[7608/15000], training loss: 0.0493
[7616/15000], training loss: 0.0502
[7624/15000], training loss: 0.0572
[7632/15000], training loss: 0.0657
[7640/15000], training loss: 0.0801
16
AVD_Home_010_1_traj6, ate: 139.8132914679628
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[7648/15000], training loss: 0.0517
[7656/15000], training loss: 0.0538
[7664/15000], training loss: 0.0577
[7672/15000], training loss: 0.0592
[7680/15000], training loss: 0.0408
16
AVD_Home_010_1_traj6, ate: 138.0991726995481
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[7688/15000], training loss: 0.0777
[7696/15000], training loss: 0.0608
[7704/15000], training loss: 0.0687
[7712/15000], training loss: 0.0520
[7720/15000], training loss: 0.0472
16
AVD_Home_010_1_traj6, ate: 134.14055546467424
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[7728/15000], training loss: 0.0584
[7736/15000], training loss: 0.0428
[7744/15000], training loss: 0.0368
[7752/15000], training loss: 0.0442
[7760/15000], training loss: 0.0533
16
AVD_Home_010_1_traj6, ate: 136.87685235246826
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[7768/15000], training loss: 0.1028
[7776/15000], training loss: 0.0518
[7784/15000], training loss: 0.0388
[7792/15000], training loss: 0.0826
[7800/15000], training loss: 0.0433
16
AVD_Home_010_1_traj6, ate: 139.80937643196722
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[7808/15000], training loss: 0.0516
[7816/15000], training loss: 0.0613
[7824/15000], training loss: 0.0476
[7832/15000], training loss: 0.0415
[7840/15000], training loss: 0.0584
16
AVD_Home_010_1_traj6, ate: 140.9293615402414
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[7848/15000], training loss: 0.0367
[7856/15000], training loss: 0.0648
[7864/15000], training loss: 0.0851
[7872/15000], training loss: 0.0566
[7880/15000], training loss: 0.0388
16
AVD_Home_010_1_traj6, ate: 135.995216589395
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[7888/15000], training loss: 0.0615
[7896/15000], training loss: 0.0702
[7904/15000], training loss: 0.0613
[7912/15000], training loss: 0.0379
[7920/15000], training loss: 0.0893
16
AVD_Home_010_1_traj6, ate: 136.5448812039733
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[7928/15000], training loss: 0.0444
[7936/15000], training loss: 0.0687
[7944/15000], training loss: 0.0597
[7952/15000], training loss: 0.0590
[7960/15000], training loss: 0.0558
16
AVD_Home_010_1_traj6, ate: 136.84195910304388
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[7968/15000], training loss: 0.0947
[7976/15000], training loss: 0.0416
[7984/15000], training loss: 0.0408
[7992/15000], training loss: 0.0669
[8000/15000], training loss: 0.0406
16
AVD_Home_010_1_traj6, ate: 141.7939999236852
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[8008/15000], training loss: 0.0629
[8016/15000], training loss: 0.0534
[8024/15000], training loss: 0.0419
[8032/15000], training loss: 0.0599
[8040/15000], training loss: 0.0410
16
AVD_Home_010_1_traj6, ate: 138.72897325910782
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[8048/15000], training loss: 0.0508
[8056/15000], training loss: 0.0439
[8064/15000], training loss: 0.0619
[8072/15000], training loss: 0.0419
[8080/15000], training loss: 0.0531
16
AVD_Home_010_1_traj6, ate: 138.2275922925079
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[8088/15000], training loss: 0.0605
[8096/15000], training loss: 0.0413
[8104/15000], training loss: 0.0787
[8112/15000], training loss: 0.0490
[8120/15000], training loss: 0.0910
16
AVD_Home_010_1_traj6, ate: 140.81936988130192
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[8128/15000], training loss: 0.0712
[8136/15000], training loss: 0.0630
[8144/15000], training loss: 0.0521
[8152/15000], training loss: 0.0519
[8160/15000], training loss: 0.0600
16
AVD_Home_010_1_traj6, ate: 136.11103043493202
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[8168/15000], training loss: 0.1081
[8176/15000], training loss: 0.0502
[8184/15000], training loss: 0.0655
[8192/15000], training loss: 0.0923
[8200/15000], training loss: 0.0428
16
AVD_Home_010_1_traj6, ate: 140.91321140002688
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[8208/15000], training loss: 0.0549
[8216/15000], training loss: 0.0393
[8224/15000], training loss: 0.0431
[8232/15000], training loss: 0.0497
[8240/15000], training loss: 0.0676
16
AVD_Home_010_1_traj6, ate: 140.50561701043628
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[8248/15000], training loss: 0.0443
[8256/15000], training loss: 0.0465
[8264/15000], training loss: 0.0450
[8272/15000], training loss: 0.0531
[8280/15000], training loss: 0.0552
16
AVD_Home_010_1_traj6, ate: 139.55816348375342
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[8288/15000], training loss: 0.0484
[8296/15000], training loss: 0.0599
[8304/15000], training loss: 0.0356
[8312/15000], training loss: 0.0820
[8320/15000], training loss: 0.0625
16
AVD_Home_010_1_traj6, ate: 138.53174447824208
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[8328/15000], training loss: 0.0773
[8336/15000], training loss: 0.0608
[8344/15000], training loss: 0.0749
[8352/15000], training loss: 0.0417
[8360/15000], training loss: 0.0450
16
AVD_Home_010_1_traj6, ate: 138.39497441031187
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[8368/15000], training loss: 0.0554
[8376/15000], training loss: 0.0466
[8384/15000], training loss: 0.0793
[8392/15000], training loss: 0.0514
[8400/15000], training loss: 0.0366
16
AVD_Home_010_1_traj6, ate: 140.9534666422325
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[8408/15000], training loss: 0.0632
[8416/15000], training loss: 0.0562
[8424/15000], training loss: 0.0557
[8432/15000], training loss: 0.0555
[8440/15000], training loss: 0.0451
16
AVD_Home_010_1_traj6, ate: 137.74376703934553
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[8448/15000], training loss: 0.0586
[8456/15000], training loss: 0.0403
[8464/15000], training loss: 0.0404
[8472/15000], training loss: 0.0531
[8480/15000], training loss: 0.0520
16
AVD_Home_010_1_traj6, ate: 137.30048074825186
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[8488/15000], training loss: 0.0686
[8496/15000], training loss: 0.0376
[8504/15000], training loss: 0.0594
[8512/15000], training loss: 0.0366
[8520/15000], training loss: 0.0639
16
AVD_Home_010_1_traj6, ate: 140.7949660510766
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[8528/15000], training loss: 0.0514
[8536/15000], training loss: 0.0448
[8544/15000], training loss: 0.0404
[8552/15000], training loss: 0.0558
[8560/15000], training loss: 0.0585
16
AVD_Home_010_1_traj6, ate: 141.05527706896453
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[8568/15000], training loss: 0.0404
[8576/15000], training loss: 0.0920
[8584/15000], training loss: 0.0410
[8592/15000], training loss: 0.0599
[8600/15000], training loss: 0.0537
16
AVD_Home_010_1_traj6, ate: 132.50795308806033
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[8608/15000], training loss: 0.0399
[8616/15000], training loss: 0.0457
[8624/15000], training loss: 0.0362
[8632/15000], training loss: 0.0445
[8640/15000], training loss: 0.0480
16
AVD_Home_010_1_traj6, ate: 137.65940369381278
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[8648/15000], training loss: 0.0421
[8656/15000], training loss: 0.0443
[8664/15000], training loss: 0.0644
[8672/15000], training loss: 0.0408
[8680/15000], training loss: 0.0678
16
AVD_Home_010_1_traj6, ate: 135.84479425216426
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[8688/15000], training loss: 0.0566
[8696/15000], training loss: 0.0436
[8704/15000], training loss: 0.0482
[8712/15000], training loss: 0.0622
[8720/15000], training loss: 0.0472
16
AVD_Home_010_1_traj6, ate: 140.86520922867672
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[8728/15000], training loss: 0.0426
[8736/15000], training loss: 0.0540
[8744/15000], training loss: 0.0501
[8752/15000], training loss: 0.0510
[8760/15000], training loss: 0.0633
16
AVD_Home_010_1_traj6, ate: 136.7139297355129
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[8768/15000], training loss: 0.0622
[8776/15000], training loss: 0.0366
[8784/15000], training loss: 0.0445
[8792/15000], training loss: 0.0375
[8800/15000], training loss: 0.0601
16
AVD_Home_010_1_traj6, ate: 139.19335288464012
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[8808/15000], training loss: 0.0652
[8816/15000], training loss: 0.0468
[8824/15000], training loss: 0.0601
[8832/15000], training loss: 0.0448
[8840/15000], training loss: 0.0611
16
AVD_Home_010_1_traj6, ate: 137.36546284765024
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[8848/15000], training loss: 0.0578
[8856/15000], training loss: 0.0388
[8864/15000], training loss: 0.0495
[8872/15000], training loss: 0.0378
[8880/15000], training loss: 0.0540
16
AVD_Home_010_1_traj6, ate: 142.30728908326637
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[8888/15000], training loss: 0.0670
[8896/15000], training loss: 0.0791
[8904/15000], training loss: 0.0821
[8912/15000], training loss: 0.0779
[8920/15000], training loss: 0.0649
16
AVD_Home_010_1_traj6, ate: 139.4234687766955
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[8928/15000], training loss: 0.0623
[8936/15000], training loss: 0.0367
[8944/15000], training loss: 0.0498
[8952/15000], training loss: 0.0658
[8960/15000], training loss: 0.0421
16
AVD_Home_010_1_traj6, ate: 140.7929507902692
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[8968/15000], training loss: 0.0505
[8976/15000], training loss: 0.0540
[8984/15000], training loss: 0.0434
[8992/15000], training loss: 0.0472
[9000/15000], training loss: 0.0595
16
AVD_Home_010_1_traj6, ate: 136.03244014229642
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[9008/15000], training loss: 0.0422
[9016/15000], training loss: 0.0462
[9024/15000], training loss: 0.0441
[9032/15000], training loss: 0.0497
[9040/15000], training loss: 0.0493
16
AVD_Home_010_1_traj6, ate: 139.17259894233337
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[9048/15000], training loss: 0.0681
[9056/15000], training loss: 0.0674
[9064/15000], training loss: 0.0478
[9072/15000], training loss: 0.0479
[9080/15000], training loss: 0.0485
16
AVD_Home_010_1_traj6, ate: 138.5503264987213
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[9088/15000], training loss: 0.0407
[9096/15000], training loss: 0.0413
[9104/15000], training loss: 0.0467
[9112/15000], training loss: 0.0535
[9120/15000], training loss: 0.0607
16
AVD_Home_010_1_traj6, ate: 141.97757096972248
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[9128/15000], training loss: 0.0579
[9136/15000], training loss: 0.0598
[9144/15000], training loss: 0.0423
[9152/15000], training loss: 0.0693
[9160/15000], training loss: 0.0401
16
AVD_Home_010_1_traj6, ate: 138.07376461282172
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[9168/15000], training loss: 0.0415
[9176/15000], training loss: 0.0595
[9184/15000], training loss: 0.0474
[9192/15000], training loss: 0.0427
[9200/15000], training loss: 0.0395
16
AVD_Home_010_1_traj6, ate: 137.04137807948229
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[9208/15000], training loss: 0.0570
[9216/15000], training loss: 0.0477
[9224/15000], training loss: 0.0463
[9232/15000], training loss: 0.0568
[9240/15000], training loss: 0.0503
16
AVD_Home_010_1_traj6, ate: 143.37930352019242
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[9248/15000], training loss: 0.0908
[9256/15000], training loss: 0.0718
[9264/15000], training loss: 0.0520
[9272/15000], training loss: 0.0367
[9280/15000], training loss: 0.0490
16
AVD_Home_010_1_traj6, ate: 137.82027325629795
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[9288/15000], training loss: 0.0444
[9296/15000], training loss: 0.0426
[9304/15000], training loss: 0.0359
[9312/15000], training loss: 0.0452
[9320/15000], training loss: 0.0438
16
AVD_Home_010_1_traj6, ate: 140.32475561085468
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[9328/15000], training loss: 0.0731
[9336/15000], training loss: 0.0659
[9344/15000], training loss: 0.0404
[9352/15000], training loss: 0.0414
[9360/15000], training loss: 0.0456
16
AVD_Home_010_1_traj6, ate: 136.66178618272087
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[9368/15000], training loss: 0.0403
[9376/15000], training loss: 0.0392
[9384/15000], training loss: 0.0612
[9392/15000], training loss: 0.0398
[9400/15000], training loss: 0.0609
16
AVD_Home_010_1_traj6, ate: 136.09201222137165
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[9408/15000], training loss: 0.0636
[9416/15000], training loss: 0.0554
[9424/15000], training loss: 0.0379
[9432/15000], training loss: 0.0579
[9440/15000], training loss: 0.0372
16
AVD_Home_010_1_traj6, ate: 142.61250748701573
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[9448/15000], training loss: 0.0423
[9456/15000], training loss: 0.0430
[9464/15000], training loss: 0.0422
[9472/15000], training loss: 0.0607
[9480/15000], training loss: 0.0630
16
AVD_Home_010_1_traj6, ate: 141.98160673260446
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[9488/15000], training loss: 0.0415
[9496/15000], training loss: 0.0440
[9504/15000], training loss: 0.0420
[9512/15000], training loss: 0.0429
[9520/15000], training loss: 0.0467
16
AVD_Home_010_1_traj6, ate: 138.27199323675836
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[9528/15000], training loss: 0.0470
[9536/15000], training loss: 0.0525
[9544/15000], training loss: 0.0364
[9552/15000], training loss: 0.0588
[9560/15000], training loss: 0.0647
16
AVD_Home_010_1_traj6, ate: 139.5347091310943
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[9568/15000], training loss: 0.0591
[9576/15000], training loss: 0.0672
[9584/15000], training loss: 0.0440
[9592/15000], training loss: 0.0526
[9600/15000], training loss: 0.0609
16
AVD_Home_010_1_traj6, ate: 141.31643550749283
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[9608/15000], training loss: 0.0474
[9616/15000], training loss: 0.0519
[9624/15000], training loss: 0.0436
[9632/15000], training loss: 0.0472
[9640/15000], training loss: 0.0551
16
AVD_Home_010_1_traj6, ate: 137.50394476350584
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[9648/15000], training loss: 0.0576
[9656/15000], training loss: 0.0366
[9664/15000], training loss: 0.0538
[9672/15000], training loss: 0.0641
[9680/15000], training loss: 0.0384
16
AVD_Home_010_1_traj6, ate: 140.44631375559024
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[9688/15000], training loss: 0.0536
[9696/15000], training loss: 0.0414
[9704/15000], training loss: 0.0685
[9712/15000], training loss: 0.0426
[9720/15000], training loss: 0.0403
16
AVD_Home_010_1_traj6, ate: 135.5563175544817
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[9728/15000], training loss: 0.0372
[9736/15000], training loss: 0.0404
[9744/15000], training loss: 0.0636
[9752/15000], training loss: 0.0383
[9760/15000], training loss: 0.0474
16
AVD_Home_010_1_traj6, ate: 137.0273598390096
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[9768/15000], training loss: 0.0543
[9776/15000], training loss: 0.0633
[9784/15000], training loss: 0.0486
[9792/15000], training loss: 0.0373
[9800/15000], training loss: 0.0603
16
AVD_Home_010_1_traj6, ate: 141.69746223495883
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[9808/15000], training loss: 0.0496
[9816/15000], training loss: 0.0344
[9824/15000], training loss: 0.0363
[9832/15000], training loss: 0.0497
[9840/15000], training loss: 0.0408
16
AVD_Home_010_1_traj6, ate: 137.76849560422005
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[9848/15000], training loss: 0.0594
[9856/15000], training loss: 0.0795
[9864/15000], training loss: 0.0407
[9872/15000], training loss: 0.0528
[9880/15000], training loss: 0.0419
16
AVD_Home_010_1_traj6, ate: 139.7725849617111
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[9888/15000], training loss: 0.0314
[9896/15000], training loss: 0.0450
[9904/15000], training loss: 0.0558
[9912/15000], training loss: 0.0424
[9920/15000], training loss: 0.0647
16
AVD_Home_010_1_traj6, ate: 139.86099403472545
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[9928/15000], training loss: 0.0377
[9936/15000], training loss: 0.0427
[9944/15000], training loss: 0.0327
[9952/15000], training loss: 0.0386
[9960/15000], training loss: 0.0487
16
AVD_Home_010_1_traj6, ate: 138.3377011082247
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[9968/15000], training loss: 0.0525
[9976/15000], training loss: 0.0578
[9984/15000], training loss: 0.0594
[9992/15000], training loss: 0.0519
[10000/15000], training loss: 0.0629
16
AVD_Home_010_1_traj6, ate: 140.86163277582924
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[10008/15000], training loss: 0.0414
[10016/15000], training loss: 0.0408
[10024/15000], training loss: 0.0417
[10032/15000], training loss: 0.0417
[10040/15000], training loss: 0.0604
16
AVD_Home_010_1_traj6, ate: 137.33014549725704
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[10048/15000], training loss: 0.0474
[10056/15000], training loss: 0.0558
[10064/15000], training loss: 0.0443
[10072/15000], training loss: 0.0340
[10080/15000], training loss: 0.1028
16
AVD_Home_010_1_traj6, ate: 138.88512266251465
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[10088/15000], training loss: 0.0546
[10096/15000], training loss: 0.0649
[10104/15000], training loss: 0.0394
[10112/15000], training loss: 0.0527
[10120/15000], training loss: 0.0340
16
AVD_Home_010_1_traj6, ate: 140.17008528092447
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[10128/15000], training loss: 0.0539
[10136/15000], training loss: 0.0309
[10144/15000], training loss: 0.0496
[10152/15000], training loss: 0.0436
[10160/15000], training loss: 0.0400
16
AVD_Home_010_1_traj6, ate: 138.81845457655382
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[10168/15000], training loss: 0.0832
[10176/15000], training loss: 0.0765
[10184/15000], training loss: 0.0424
[10192/15000], training loss: 0.0459
[10200/15000], training loss: 0.0364
16
AVD_Home_010_1_traj6, ate: 141.6289965986818
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[10208/15000], training loss: 0.0576
[10216/15000], training loss: 0.0350
[10224/15000], training loss: 0.0762
[10232/15000], training loss: 0.0972
[10240/15000], training loss: 0.0599
16
AVD_Home_010_1_traj6, ate: 138.391722295967
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[10248/15000], training loss: 0.0522
[10256/15000], training loss: 0.0515
[10264/15000], training loss: 0.0427
[10272/15000], training loss: 0.0636
[10280/15000], training loss: 0.0494
16
AVD_Home_010_1_traj6, ate: 138.26023351396924
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[10288/15000], training loss: 0.0567
[10296/15000], training loss: 0.0544
[10304/15000], training loss: 0.0560
[10312/15000], training loss: 0.0353
[10320/15000], training loss: 0.0512
16
AVD_Home_010_1_traj6, ate: 134.8454038755234
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[10328/15000], training loss: 0.0682
[10336/15000], training loss: 0.0762
[10344/15000], training loss: 0.0480
[10352/15000], training loss: 0.0511
[10360/15000], training loss: 0.0497
16
AVD_Home_010_1_traj6, ate: 136.81212521202409
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[10368/15000], training loss: 0.0601
[10376/15000], training loss: 0.0402
[10384/15000], training loss: 0.0409
[10392/15000], training loss: 0.0414
[10400/15000], training loss: 0.0360
16
AVD_Home_010_1_traj6, ate: 139.10199313488863
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[10408/15000], training loss: 0.0574
[10416/15000], training loss: 0.0428
[10424/15000], training loss: 0.0452
[10432/15000], training loss: 0.0375
[10440/15000], training loss: 0.0606
16
AVD_Home_010_1_traj6, ate: 135.51829908884275
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[10448/15000], training loss: 0.0442
[10456/15000], training loss: 0.0461
[10464/15000], training loss: 0.0541
[10472/15000], training loss: 0.0428
[10480/15000], training loss: 0.0532
16
AVD_Home_010_1_traj6, ate: 138.92556543360683
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[10488/15000], training loss: 0.0385
[10496/15000], training loss: 0.0361
[10504/15000], training loss: 0.0496
[10512/15000], training loss: 0.0417
[10520/15000], training loss: 0.0579
16
AVD_Home_010_1_traj6, ate: 140.64141410637737
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[10528/15000], training loss: 0.0351
[10536/15000], training loss: 0.0448
[10544/15000], training loss: 0.0568
[10552/15000], training loss: 0.0778
[10560/15000], training loss: 0.0549
16
AVD_Home_010_1_traj6, ate: 140.74748828312477
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[10568/15000], training loss: 0.0375
[10576/15000], training loss: 0.0548
[10584/15000], training loss: 0.0612
[10592/15000], training loss: 0.0457
[10600/15000], training loss: 0.0444
16
AVD_Home_010_1_traj6, ate: 139.69996110756435
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[10608/15000], training loss: 0.0679
[10616/15000], training loss: 0.0421
[10624/15000], training loss: 0.0367
[10632/15000], training loss: 0.0459
[10640/15000], training loss: 0.0431
16
AVD_Home_010_1_traj6, ate: 140.71653298050245
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[10648/15000], training loss: 0.0774
[10656/15000], training loss: 0.0631
[10664/15000], training loss: 0.0445
[10672/15000], training loss: 0.0441
[10680/15000], training loss: 0.0388
16
AVD_Home_010_1_traj6, ate: 140.4904987221422
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[10688/15000], training loss: 0.0499
[10696/15000], training loss: 0.0447
[10704/15000], training loss: 0.0394
[10712/15000], training loss: 0.0361
[10720/15000], training loss: 0.0390
16
AVD_Home_010_1_traj6, ate: 139.86668948156014
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[10728/15000], training loss: 0.0375
[10736/15000], training loss: 0.0529
[10744/15000], training loss: 0.0686
[10752/15000], training loss: 0.0689
[10760/15000], training loss: 0.0533
16
AVD_Home_010_1_traj6, ate: 140.55117445332755
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[10768/15000], training loss: 0.0357
[10776/15000], training loss: 0.0465
[10784/15000], training loss: 0.0476
[10792/15000], training loss: 0.0610
[10800/15000], training loss: 0.0397
16
AVD_Home_010_1_traj6, ate: 139.45920738158773
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[10808/15000], training loss: 0.0647
[10816/15000], training loss: 0.0620
[10824/15000], training loss: 0.0349
[10832/15000], training loss: 0.0538
[10840/15000], training loss: 0.0665
16
AVD_Home_010_1_traj6, ate: 139.90100808519225
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[10848/15000], training loss: 0.0597
[10856/15000], training loss: 0.0415
[10864/15000], training loss: 0.0530
[10872/15000], training loss: 0.0326
[10880/15000], training loss: 0.0436
16
AVD_Home_010_1_traj6, ate: 139.71914491730521
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[10888/15000], training loss: 0.0794
[10896/15000], training loss: 0.0591
[10904/15000], training loss: 0.0592
[10912/15000], training loss: 0.0436
[10920/15000], training loss: 0.0504
16
AVD_Home_010_1_traj6, ate: 136.7765226302591
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[10928/15000], training loss: 0.0466
[10936/15000], training loss: 0.0561
[10944/15000], training loss: 0.0553
[10952/15000], training loss: 0.0371
[10960/15000], training loss: 0.0390
16
AVD_Home_010_1_traj6, ate: 140.82515088149827
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[10968/15000], training loss: 0.0408
[10976/15000], training loss: 0.0658
[10984/15000], training loss: 0.0395
[10992/15000], training loss: 0.0663
[11000/15000], training loss: 0.0592
16
AVD_Home_010_1_traj6, ate: 139.56729640707252
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[11008/15000], training loss: 0.0686
[11016/15000], training loss: 0.0434
[11024/15000], training loss: 0.0609
[11032/15000], training loss: 0.0466
[11040/15000], training loss: 0.0656
16
AVD_Home_010_1_traj6, ate: 137.57657255062264
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[11048/15000], training loss: 0.0472
[11056/15000], training loss: 0.0412
[11064/15000], training loss: 0.0628
[11072/15000], training loss: 0.0646
[11080/15000], training loss: 0.0408
16
AVD_Home_010_1_traj6, ate: 139.45560826457478
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[11088/15000], training loss: 0.0374
[11096/15000], training loss: 0.0529
[11104/15000], training loss: 0.0460
[11112/15000], training loss: 0.0823
[11120/15000], training loss: 0.0558
16
AVD_Home_010_1_traj6, ate: 141.07825302262708
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[11128/15000], training loss: 0.0484
[11136/15000], training loss: 0.0700
[11144/15000], training loss: 0.0691
[11152/15000], training loss: 0.0347
[11160/15000], training loss: 0.0635
16
AVD_Home_010_1_traj6, ate: 139.66445425790982
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[11168/15000], training loss: 0.0631
[11176/15000], training loss: 0.0338
[11184/15000], training loss: 0.0439
[11192/15000], training loss: 0.0749
[11200/15000], training loss: 0.0757
16
AVD_Home_010_1_traj6, ate: 141.39243679142373
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[11208/15000], training loss: 0.0628
[11216/15000], training loss: 0.0481
[11224/15000], training loss: 0.0488
[11232/15000], training loss: 0.0518
[11240/15000], training loss: 0.0437
16
AVD_Home_010_1_traj6, ate: 139.74389244296967
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[11248/15000], training loss: 0.0582
[11256/15000], training loss: 0.0419
[11264/15000], training loss: 0.0517
[11272/15000], training loss: 0.0698
[11280/15000], training loss: 0.0535
16
AVD_Home_010_1_traj6, ate: 140.0163856354216
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[11288/15000], training loss: 0.0346
[11296/15000], training loss: 0.0481
[11304/15000], training loss: 0.0507
[11312/15000], training loss: 0.0388
[11320/15000], training loss: 0.0476
16
AVD_Home_010_1_traj6, ate: 143.0553823548558
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[11328/15000], training loss: 0.0463
[11336/15000], training loss: 0.0442
[11344/15000], training loss: 0.0433
[11352/15000], training loss: 0.0485
[11360/15000], training loss: 0.0489
16
AVD_Home_010_1_traj6, ate: 140.39234284124453
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[11368/15000], training loss: 0.0650
[11376/15000], training loss: 0.0536
[11384/15000], training loss: 0.0386
[11392/15000], training loss: 0.0381
[11400/15000], training loss: 0.0440
16
AVD_Home_010_1_traj6, ate: 143.24035945768583
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[11408/15000], training loss: 0.0366
[11416/15000], training loss: 0.0485
[11424/15000], training loss: 0.0557
[11432/15000], training loss: 0.0450
[11440/15000], training loss: 0.0423
16
AVD_Home_010_1_traj6, ate: 140.2088100515343
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[11448/15000], training loss: 0.0362
[11456/15000], training loss: 0.0647
[11464/15000], training loss: 0.0494
[11472/15000], training loss: 0.0583
[11480/15000], training loss: 0.0382
16
AVD_Home_010_1_traj6, ate: 142.3112311908594
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[11488/15000], training loss: 0.0452
[11496/15000], training loss: 0.0636
[11504/15000], training loss: 0.0528
[11512/15000], training loss: 0.0827
[11520/15000], training loss: 0.0540
16
AVD_Home_010_1_traj6, ate: 138.1653086895698
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[11528/15000], training loss: 0.0524
[11536/15000], training loss: 0.0660
[11544/15000], training loss: 0.0451
[11552/15000], training loss: 0.0441
[11560/15000], training loss: 0.0430
16
AVD_Home_010_1_traj6, ate: 139.3383580006473
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[11568/15000], training loss: 0.0467
[11576/15000], training loss: 0.0503
[11584/15000], training loss: 0.0400
[11592/15000], training loss: 0.0546
[11600/15000], training loss: 0.0388
16
AVD_Home_010_1_traj6, ate: 142.49492528870326
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[11608/15000], training loss: 0.0546
[11616/15000], training loss: 0.0545
[11624/15000], training loss: 0.0422
[11632/15000], training loss: 0.0383
[11640/15000], training loss: 0.0391
16
AVD_Home_010_1_traj6, ate: 141.85076666989292
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[11648/15000], training loss: 0.0577
[11656/15000], training loss: 0.0532
[11664/15000], training loss: 0.0471
[11672/15000], training loss: 0.0528
[11680/15000], training loss: 0.0335
16
AVD_Home_010_1_traj6, ate: 139.57701738879825
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[11688/15000], training loss: 0.0429
[11696/15000], training loss: 0.0617
[11704/15000], training loss: 0.0343
[11712/15000], training loss: 0.0507
[11720/15000], training loss: 0.0385
16
AVD_Home_010_1_traj6, ate: 141.53297657746182
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[11728/15000], training loss: 0.0492
[11736/15000], training loss: 0.0435
[11744/15000], training loss: 0.0628
[11752/15000], training loss: 0.0384
[11760/15000], training loss: 0.0653
16
AVD_Home_010_1_traj6, ate: 139.33101954404415
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[11768/15000], training loss: 0.0513
[11776/15000], training loss: 0.0479
[11784/15000], training loss: 0.0494
[11792/15000], training loss: 0.0563
[11800/15000], training loss: 0.0476
16
AVD_Home_010_1_traj6, ate: 143.63603705265464
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[11808/15000], training loss: 0.0441
[11816/15000], training loss: 0.0446
[11824/15000], training loss: 0.0655
[11832/15000], training loss: 0.0614
[11840/15000], training loss: 0.0640
16
AVD_Home_010_1_traj6, ate: 140.90748638756256
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[11848/15000], training loss: 0.0460
[11856/15000], training loss: 0.0413
[11864/15000], training loss: 0.0716
[11872/15000], training loss: 0.0446
[11880/15000], training loss: 0.0692
16
AVD_Home_010_1_traj6, ate: 139.26515636933965
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[11888/15000], training loss: 0.0401
[11896/15000], training loss: 0.0626
[11904/15000], training loss: 0.0357
[11912/15000], training loss: 0.0575
[11920/15000], training loss: 0.0567
16
AVD_Home_010_1_traj6, ate: 136.25346719503708
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[11928/15000], training loss: 0.0679
[11936/15000], training loss: 0.0502
[11944/15000], training loss: 0.0413
[11952/15000], training loss: 0.0446
[11960/15000], training loss: 0.0620
16
AVD_Home_010_1_traj6, ate: 133.5560910809118
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[11968/15000], training loss: 0.0682
[11976/15000], training loss: 0.0777
[11984/15000], training loss: 0.0778
[11992/15000], training loss: 0.0416
[12000/15000], training loss: 0.0633
16
AVD_Home_010_1_traj6, ate: 141.48724271262913
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[12008/15000], training loss: 0.0565
[12016/15000], training loss: 0.0547
[12024/15000], training loss: 0.0726
[12032/15000], training loss: 0.0348
[12040/15000], training loss: 0.0551
16
AVD_Home_010_1_traj6, ate: 140.4995844948927
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[12048/15000], training loss: 0.0675
[12056/15000], training loss: 0.0374
[12064/15000], training loss: 0.0618
[12072/15000], training loss: 0.0457
[12080/15000], training loss: 0.0410
16
AVD_Home_010_1_traj6, ate: 139.67418698843355
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[12088/15000], training loss: 0.0586
[12096/15000], training loss: 0.0625
[12104/15000], training loss: 0.0582
[12112/15000], training loss: 0.0606
[12120/15000], training loss: 0.0401
16
AVD_Home_010_1_traj6, ate: 140.68869068319697
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[12128/15000], training loss: 0.0632
[12136/15000], training loss: 0.0386
[12144/15000], training loss: 0.0437
[12152/15000], training loss: 0.0554
[12160/15000], training loss: 0.0600
16
AVD_Home_010_1_traj6, ate: 141.04436061276027
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[12168/15000], training loss: 0.0554
[12176/15000], training loss: 0.0434
[12184/15000], training loss: 0.0800
[12192/15000], training loss: 0.0576
[12200/15000], training loss: 0.0543
16
AVD_Home_010_1_traj6, ate: 141.1630576697454
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[12208/15000], training loss: 0.0513
[12216/15000], training loss: 0.0367
[12224/15000], training loss: 0.0457
[12232/15000], training loss: 0.0441
[12240/15000], training loss: 0.0414
16
AVD_Home_010_1_traj6, ate: 140.30368617076687
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[12248/15000], training loss: 0.0538
[12256/15000], training loss: 0.0477
[12264/15000], training loss: 0.0424
[12272/15000], training loss: 0.0422
[12280/15000], training loss: 0.0524
16
AVD_Home_010_1_traj6, ate: 139.66801428501336
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[12288/15000], training loss: 0.0395
[12296/15000], training loss: 0.0751
[12304/15000], training loss: 0.0435
[12312/15000], training loss: 0.0408
[12320/15000], training loss: 0.0457
16
AVD_Home_010_1_traj6, ate: 138.5466859443759
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[12328/15000], training loss: 0.0541
[12336/15000], training loss: 0.0338
[12344/15000], training loss: 0.0599
[12352/15000], training loss: 0.0547
[12360/15000], training loss: 0.0362
16
AVD_Home_010_1_traj6, ate: 138.58621253832084
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[12368/15000], training loss: 0.0353
[12376/15000], training loss: 0.0536
[12384/15000], training loss: 0.0474
[12392/15000], training loss: 0.0588
[12400/15000], training loss: 0.0505
16
AVD_Home_010_1_traj6, ate: 139.3310990145366
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[12408/15000], training loss: 0.0487
[12416/15000], training loss: 0.0462
[12424/15000], training loss: 0.0707
[12432/15000], training loss: 0.0485
[12440/15000], training loss: 0.0411
16
AVD_Home_010_1_traj6, ate: 139.9075948472387
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[12448/15000], training loss: 0.0522
[12456/15000], training loss: 0.0345
[12464/15000], training loss: 0.0576
[12472/15000], training loss: 0.0668
[12480/15000], training loss: 0.0607
16
AVD_Home_010_1_traj6, ate: 141.00156650159218
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[12488/15000], training loss: 0.0473
[12496/15000], training loss: 0.0536
[12504/15000], training loss: 0.0357
[12512/15000], training loss: 0.0359
[12520/15000], training loss: 0.0485
16
AVD_Home_010_1_traj6, ate: 141.3975610660883
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[12528/15000], training loss: 0.0517
[12536/15000], training loss: 0.0600
[12544/15000], training loss: 0.0699
[12552/15000], training loss: 0.0400
[12560/15000], training loss: 0.0533
16
AVD_Home_010_1_traj6, ate: 137.42085303810063
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[12568/15000], training loss: 0.0504
[12576/15000], training loss: 0.0604
[12584/15000], training loss: 0.0435
[12592/15000], training loss: 0.0463
[12600/15000], training loss: 0.0361
16
AVD_Home_010_1_traj6, ate: 139.5899129124067
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[12608/15000], training loss: 0.0379
[12616/15000], training loss: 0.0454
[12624/15000], training loss: 0.0418
[12632/15000], training loss: 0.0392
[12640/15000], training loss: 0.0774
16
AVD_Home_010_1_traj6, ate: 141.07235388858157
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[12648/15000], training loss: 0.0423
[12656/15000], training loss: 0.0409
[12664/15000], training loss: 0.0489
[12672/15000], training loss: 0.0367
[12680/15000], training loss: 0.0594
16
AVD_Home_010_1_traj6, ate: 139.7729782343151
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[12688/15000], training loss: 0.0537
[12696/15000], training loss: 0.0626
[12704/15000], training loss: 0.0381
[12712/15000], training loss: 0.0410
[12720/15000], training loss: 0.0448
16
AVD_Home_010_1_traj6, ate: 140.73414118252083
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[12728/15000], training loss: 0.0548
[12736/15000], training loss: 0.0462
[12744/15000], training loss: 0.0471
[12752/15000], training loss: 0.0424
[12760/15000], training loss: 0.0481
16
AVD_Home_010_1_traj6, ate: 137.39824026091264
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[12768/15000], training loss: 0.0342
[12776/15000], training loss: 0.0391
[12784/15000], training loss: 0.0427
[12792/15000], training loss: 0.0724
[12800/15000], training loss: 0.0473
16
AVD_Home_010_1_traj6, ate: 140.1075273121996
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[12808/15000], training loss: 0.0347
[12816/15000], training loss: 0.0440
[12824/15000], training loss: 0.0467
[12832/15000], training loss: 0.0826
[12840/15000], training loss: 0.0370
16
AVD_Home_010_1_traj6, ate: 141.35584439090283
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[12848/15000], training loss: 0.0452
[12856/15000], training loss: 0.0517
[12864/15000], training loss: 0.0354
[12872/15000], training loss: 0.0509
[12880/15000], training loss: 0.0507
16
AVD_Home_010_1_traj6, ate: 144.91365894510625
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[12888/15000], training loss: 0.0652
[12896/15000], training loss: 0.0621
[12904/15000], training loss: 0.0610
[12912/15000], training loss: 0.0707
[12920/15000], training loss: 0.0973
16
AVD_Home_010_1_traj6, ate: 140.09827738905568
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[12928/15000], training loss: 0.0400
[12936/15000], training loss: 0.0655
[12944/15000], training loss: 0.0468
[12952/15000], training loss: 0.0435
[12960/15000], training loss: 0.0793
16
AVD_Home_010_1_traj6, ate: 142.41355831828793
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[12968/15000], training loss: 0.0534
[12976/15000], training loss: 0.0437
[12984/15000], training loss: 0.0505
[12992/15000], training loss: 0.0390
[13000/15000], training loss: 0.0471
16
AVD_Home_010_1_traj6, ate: 139.78837650577722
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[13008/15000], training loss: 0.0458
[13016/15000], training loss: 0.0415
[13024/15000], training loss: 0.0316
[13032/15000], training loss: 0.0520
[13040/15000], training loss: 0.0423
16
AVD_Home_010_1_traj6, ate: 141.58703389622085
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[13048/15000], training loss: 0.0389
[13056/15000], training loss: 0.0600
[13064/15000], training loss: 0.0432
[13072/15000], training loss: 0.0349
[13080/15000], training loss: 0.0584
16
AVD_Home_010_1_traj6, ate: 139.07631707064078
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[13088/15000], training loss: 0.0486
[13096/15000], training loss: 0.0612
[13104/15000], training loss: 0.0468
[13112/15000], training loss: 0.0501
[13120/15000], training loss: 0.0372
16
AVD_Home_010_1_traj6, ate: 140.79078778660406
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[13128/15000], training loss: 0.0446
[13136/15000], training loss: 0.0618
[13144/15000], training loss: 0.0485
[13152/15000], training loss: 0.0380
[13160/15000], training loss: 0.0502
16
AVD_Home_010_1_traj6, ate: 139.81242216505672
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[13168/15000], training loss: 0.0678
[13176/15000], training loss: 0.0430
[13184/15000], training loss: 0.0331
[13192/15000], training loss: 0.0479
[13200/15000], training loss: 0.0603
16
AVD_Home_010_1_traj6, ate: 145.3039312915568
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[13208/15000], training loss: 0.0584
[13216/15000], training loss: 0.0582
[13224/15000], training loss: 0.0507
[13232/15000], training loss: 0.0423
[13240/15000], training loss: 0.0490
16
AVD_Home_010_1_traj6, ate: 139.4385013203802
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[13248/15000], training loss: 0.0378
[13256/15000], training loss: 0.0586
[13264/15000], training loss: 0.0756
[13272/15000], training loss: 0.0603
[13280/15000], training loss: 0.0383
16
AVD_Home_010_1_traj6, ate: 140.90550865274173
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[13288/15000], training loss: 0.0416
[13296/15000], training loss: 0.0477
[13304/15000], training loss: 0.0600
[13312/15000], training loss: 0.0329
[13320/15000], training loss: 0.0404
16
AVD_Home_010_1_traj6, ate: 140.28897139860345
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[13328/15000], training loss: 0.0696
[13336/15000], training loss: 0.0449
[13344/15000], training loss: 0.0900
[13352/15000], training loss: 0.0583
[13360/15000], training loss: 0.0341
16
AVD_Home_010_1_traj6, ate: 141.83145026753337
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[13368/15000], training loss: 0.0394
[13376/15000], training loss: 0.0448
[13384/15000], training loss: 0.0515
[13392/15000], training loss: 0.0378
[13400/15000], training loss: 0.0609
16
AVD_Home_010_1_traj6, ate: 140.4085486574497
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[13408/15000], training loss: 0.0517
[13416/15000], training loss: 0.0379
[13424/15000], training loss: 0.0620
[13432/15000], training loss: 0.0347
[13440/15000], training loss: 0.0524
16
AVD_Home_010_1_traj6, ate: 141.7033525455351
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[13448/15000], training loss: 0.0661
[13456/15000], training loss: 0.0544
[13464/15000], training loss: 0.0575
[13472/15000], training loss: 0.0472
[13480/15000], training loss: 0.0322
16
AVD_Home_010_1_traj6, ate: 142.42543365577657
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[13488/15000], training loss: 0.0487
[13496/15000], training loss: 0.0383
[13504/15000], training loss: 0.0370
[13512/15000], training loss: 0.0459
[13520/15000], training loss: 0.0413
16
AVD_Home_010_1_traj6, ate: 141.17303566507647
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[13528/15000], training loss: 0.0327
[13536/15000], training loss: 0.0352
[13544/15000], training loss: 0.0442
[13552/15000], training loss: 0.0386
[13560/15000], training loss: 0.0340
16
AVD_Home_010_1_traj6, ate: 139.904063835331
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[13568/15000], training loss: 0.0520
[13576/15000], training loss: 0.0427
[13584/15000], training loss: 0.0465
[13592/15000], training loss: 0.0494
[13600/15000], training loss: 0.0490
16
AVD_Home_010_1_traj6, ate: 138.2539016599204
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[13608/15000], training loss: 0.0460
[13616/15000], training loss: 0.0639
[13624/15000], training loss: 0.0387
[13632/15000], training loss: 0.0679
[13640/15000], training loss: 0.0721
16
AVD_Home_010_1_traj6, ate: 142.39696673165142
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[13648/15000], training loss: 0.0514
[13656/15000], training loss: 0.0449
[13664/15000], training loss: 0.0601
[13672/15000], training loss: 0.0674
[13680/15000], training loss: 0.0401
16
AVD_Home_010_1_traj6, ate: 140.73911823391884
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[13688/15000], training loss: 0.0572
[13696/15000], training loss: 0.0514
[13704/15000], training loss: 0.0420
[13712/15000], training loss: 0.0745
[13720/15000], training loss: 0.0348
16
AVD_Home_010_1_traj6, ate: 140.6366527462395
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[13728/15000], training loss: 0.0518
[13736/15000], training loss: 0.0607
[13744/15000], training loss: 0.0373
[13752/15000], training loss: 0.0455
[13760/15000], training loss: 0.0594
16
AVD_Home_010_1_traj6, ate: 141.3998734219783
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[13768/15000], training loss: 0.0595
[13776/15000], training loss: 0.0426
[13784/15000], training loss: 0.0446
[13792/15000], training loss: 0.0585
[13800/15000], training loss: 0.0736
16
AVD_Home_010_1_traj6, ate: 142.13100433759897
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[13808/15000], training loss: 0.0700
[13816/15000], training loss: 0.0356
[13824/15000], training loss: 0.0517
[13832/15000], training loss: 0.0432
[13840/15000], training loss: 0.0698
16
AVD_Home_010_1_traj6, ate: 140.6820532161834
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[13848/15000], training loss: 0.0629
[13856/15000], training loss: 0.0350
[13864/15000], training loss: 0.0418
[13872/15000], training loss: 0.0569
[13880/15000], training loss: 0.0383
16
AVD_Home_010_1_traj6, ate: 139.1358699414884
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[13888/15000], training loss: 0.0383
[13896/15000], training loss: 0.0402
[13904/15000], training loss: 0.0399
[13912/15000], training loss: 0.0429
[13920/15000], training loss: 0.0556
16
AVD_Home_010_1_traj6, ate: 139.07236881789368
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[13928/15000], training loss: 0.0474
[13936/15000], training loss: 0.0590
[13944/15000], training loss: 0.0538
[13952/15000], training loss: 0.0890
[13960/15000], training loss: 0.0341
16
AVD_Home_010_1_traj6, ate: 141.29470681096822
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[13968/15000], training loss: 0.0555
[13976/15000], training loss: 0.0506
[13984/15000], training loss: 0.0617
[13992/15000], training loss: 0.0497
[14000/15000], training loss: 0.0409
16
AVD_Home_010_1_traj6, ate: 139.08246260649693
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[14008/15000], training loss: 0.0872
[14016/15000], training loss: 0.0367
[14024/15000], training loss: 0.0590
[14032/15000], training loss: 0.0875
[14040/15000], training loss: 0.0365
16
AVD_Home_010_1_traj6, ate: 141.94023715915742
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[14048/15000], training loss: 0.0455
[14056/15000], training loss: 0.0584
[14064/15000], training loss: 0.0370
[14072/15000], training loss: 0.0507
[14080/15000], training loss: 0.0597
16
AVD_Home_010_1_traj6, ate: 139.53015937557387
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[14088/15000], training loss: 0.0492
[14096/15000], training loss: 0.0552
[14104/15000], training loss: 0.0528
[14112/15000], training loss: 0.0412
[14120/15000], training loss: 0.0533
16
AVD_Home_010_1_traj6, ate: 140.6869351514251
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[14128/15000], training loss: 0.0455
[14136/15000], training loss: 0.0568
[14144/15000], training loss: 0.0624
[14152/15000], training loss: 0.0431
[14160/15000], training loss: 0.0604
16
AVD_Home_010_1_traj6, ate: 140.33648115733678
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[14168/15000], training loss: 0.0501
[14176/15000], training loss: 0.0357
[14184/15000], training loss: 0.0473
[14192/15000], training loss: 0.0358
[14200/15000], training loss: 0.0354
16
AVD_Home_010_1_traj6, ate: 140.20638530739063
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[14208/15000], training loss: 0.0600
[14216/15000], training loss: 0.0587
[14224/15000], training loss: 0.0332
[14232/15000], training loss: 0.0371
[14240/15000], training loss: 0.0415
16
AVD_Home_010_1_traj6, ate: 139.75485523877433
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[14248/15000], training loss: 0.0372
[14256/15000], training loss: 0.0358
[14264/15000], training loss: 0.0421
[14272/15000], training loss: 0.0819
[14280/15000], training loss: 0.0409
16
AVD_Home_010_1_traj6, ate: 141.4401987841695
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[14288/15000], training loss: 0.0530
[14296/15000], training loss: 0.0861
[14304/15000], training loss: 0.0411
[14312/15000], training loss: 0.0464
[14320/15000], training loss: 0.0490
16
AVD_Home_010_1_traj6, ate: 141.99146205082502
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[14328/15000], training loss: 0.0389
[14336/15000], training loss: 0.0660
[14344/15000], training loss: 0.0563
[14352/15000], training loss: 0.0467
[14360/15000], training loss: 0.0475
16
AVD_Home_010_1_traj6, ate: 139.72535744706482
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[14368/15000], training loss: 0.0413
[14376/15000], training loss: 0.0365
[14384/15000], training loss: 0.0587
[14392/15000], training loss: 0.0398
[14400/15000], training loss: 0.0569
16
AVD_Home_010_1_traj6, ate: 139.8868869570795
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[14408/15000], training loss: 0.0361
[14416/15000], training loss: 0.0456
[14424/15000], training loss: 0.0374
[14432/15000], training loss: 0.0665
[14440/15000], training loss: 0.0391
16
AVD_Home_010_1_traj6, ate: 143.6782676838637
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[14448/15000], training loss: 0.0414
[14456/15000], training loss: 0.0415
[14464/15000], training loss: 0.0344
[14472/15000], training loss: 0.0604
[14480/15000], training loss: 0.0669
16
AVD_Home_010_1_traj6, ate: 141.5494871269721
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[14488/15000], training loss: 0.0580
[14496/15000], training loss: 0.0415
[14504/15000], training loss: 0.0429
[14512/15000], training loss: 0.0336
[14520/15000], training loss: 0.0427
16
AVD_Home_010_1_traj6, ate: 139.9513705218688
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[14528/15000], training loss: 0.0738
[14536/15000], training loss: 0.0491
[14544/15000], training loss: 0.0444
[14552/15000], training loss: 0.0640
[14560/15000], training loss: 0.0353
16
AVD_Home_010_1_traj6, ate: 141.89956648226152
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[14568/15000], training loss: 0.0551
[14576/15000], training loss: 0.0376
[14584/15000], training loss: 0.0352
[14592/15000], training loss: 0.0552
[14600/15000], training loss: 0.0325
16
AVD_Home_010_1_traj6, ate: 140.94417195529843
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[14608/15000], training loss: 0.0392
[14616/15000], training loss: 0.0372
[14624/15000], training loss: 0.0589
[14632/15000], training loss: 0.0441
[14640/15000], training loss: 0.0770
16
AVD_Home_010_1_traj6, ate: 136.90291051321543
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[14648/15000], training loss: 0.0484
[14656/15000], training loss: 0.0434
[14664/15000], training loss: 0.0438
[14672/15000], training loss: 0.0473
[14680/15000], training loss: 0.0685
16
AVD_Home_010_1_traj6, ate: 142.50778418256962
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[14688/15000], training loss: 0.0364
[14696/15000], training loss: 0.0437
[14704/15000], training loss: 0.0568
[14712/15000], training loss: 0.0342
[14720/15000], training loss: 0.0474
16
AVD_Home_010_1_traj6, ate: 141.03385053495577
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[14728/15000], training loss: 0.0567
[14736/15000], training loss: 0.0365
[14744/15000], training loss: 0.0376
[14752/15000], training loss: 0.0440
[14760/15000], training loss: 0.0520
16
AVD_Home_010_1_traj6, ate: 139.51418694839097
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[14768/15000], training loss: 0.0312
[14776/15000], training loss: 0.0346
[14784/15000], training loss: 0.0631
[14792/15000], training loss: 0.0404
[14800/15000], training loss: 0.0654
16
AVD_Home_010_1_traj6, ate: 140.91820699391104
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[14808/15000], training loss: 0.0372
[14816/15000], training loss: 0.0536
[14824/15000], training loss: 0.0461
[14832/15000], training loss: 0.0333
[14840/15000], training loss: 0.0434
16
AVD_Home_010_1_traj6, ate: 141.4079908211243
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[14848/15000], training loss: 0.0403
[14856/15000], training loss: 0.0451
[14864/15000], training loss: 0.0467
[14872/15000], training loss: 0.0780
[14880/15000], training loss: 0.0396
16
AVD_Home_010_1_traj6, ate: 142.8943176950123
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[14888/15000], training loss: 0.0578
[14896/15000], training loss: 0.0470
[14904/15000], training loss: 0.0506
[14912/15000], training loss: 0.0548
[14920/15000], training loss: 0.1030
16
AVD_Home_010_1_traj6, ate: 140.69875818313008
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[14928/15000], training loss: 0.0357
[14936/15000], training loss: 0.0345
[14944/15000], training loss: 0.0500
[14952/15000], training loss: 0.0569
[14960/15000], training loss: 0.0435
16
AVD_Home_010_1_traj6, ate: 140.01381211193672
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
[14968/15000], training loss: 0.0360
[14976/15000], training loss: 0.0406
[14984/15000], training loss: 0.0766
[14992/15000], training loss: 0.0617
[15000/15000], training loss: 0.0523
16
AVD_Home_010_1_traj6, ate: 140.45276792889229
model saved to ../results/AVD/AVD_Home_010_1_traj6/model_best.pth
./lstm_run_train_AVD.sh: line 25: /home/mmvc: Is a directory
