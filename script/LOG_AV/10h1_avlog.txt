maxpool
latent size single: 16
loading dataset
16
pccppcpc1123 (16, 27, 48, 3)
creating model
start training
[8/15000], training loss: 0.1654
[16/15000], training loss: 0.1455
[24/15000], training loss: 0.1269
[32/15000], training loss: 0.1204
[40/15000], training loss: 0.1108
16
AVD_Home_010_1_traj1, ate: 438.8078753129861
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[48/15000], training loss: 0.1122
[56/15000], training loss: 0.1091
[64/15000], training loss: 0.1154
[72/15000], training loss: 0.1122
[80/15000], training loss: 0.1100
16
AVD_Home_010_1_traj1, ate: 527.2889757144779
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[88/15000], training loss: 0.1138
[96/15000], training loss: 0.1041
[104/15000], training loss: 0.0896
[112/15000], training loss: 0.0996
[120/15000], training loss: 0.0990
16
AVD_Home_010_1_traj1, ate: 684.2488118748472
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[128/15000], training loss: 0.1047
[136/15000], training loss: 0.0943
[144/15000], training loss: 0.1074
[152/15000], training loss: 0.0982
[160/15000], training loss: 0.0949
16
AVD_Home_010_1_traj1, ate: 595.519011913055
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[168/15000], training loss: 0.1025
[176/15000], training loss: 0.0916
[184/15000], training loss: 0.1033
[192/15000], training loss: 0.0994
[200/15000], training loss: 0.0863
16
AVD_Home_010_1_traj1, ate: 663.3308574459312
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[208/15000], training loss: 0.0932
[216/15000], training loss: 0.0910
[224/15000], training loss: 0.0980
[232/15000], training loss: 0.0966
[240/15000], training loss: 0.0914
16
AVD_Home_010_1_traj1, ate: 712.1382802638576
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[248/15000], training loss: 0.0883
[256/15000], training loss: 0.0881
[264/15000], training loss: 0.0944
[272/15000], training loss: 0.0990
[280/15000], training loss: 0.0820
16
AVD_Home_010_1_traj1, ate: 714.006252877159
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[288/15000], training loss: 0.0975
[296/15000], training loss: 0.0910
[304/15000], training loss: 0.0906
[312/15000], training loss: 0.1039
[320/15000], training loss: 0.0859
16
AVD_Home_010_1_traj1, ate: 692.2025102927846
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[328/15000], training loss: 0.0964
[336/15000], training loss: 0.0883
[344/15000], training loss: 0.0784
[352/15000], training loss: 0.0826
[360/15000], training loss: 0.1014
16
AVD_Home_010_1_traj1, ate: 675.9133706024306
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[368/15000], training loss: 0.0884
[376/15000], training loss: 0.0869
[384/15000], training loss: 0.0886
[392/15000], training loss: 0.0991
[400/15000], training loss: 0.0931
16
AVD_Home_010_1_traj1, ate: 728.4160572099993
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[408/15000], training loss: 0.0898
[416/15000], training loss: 0.1058
[424/15000], training loss: 0.1054
[432/15000], training loss: 0.0908
[440/15000], training loss: 0.0844
16
AVD_Home_010_1_traj1, ate: 689.6616863624782
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[448/15000], training loss: 0.0853
[456/15000], training loss: 0.0893
[464/15000], training loss: 0.0767
[472/15000], training loss: 0.0883
[480/15000], training loss: 0.0903
16
AVD_Home_010_1_traj1, ate: 775.1930260818172
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[488/15000], training loss: 0.0887
[496/15000], training loss: 0.0893
[504/15000], training loss: 0.0858
[512/15000], training loss: 0.0822
[520/15000], training loss: 0.0936
16
AVD_Home_010_1_traj1, ate: 773.9315779131687
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[528/15000], training loss: 0.0982
[536/15000], training loss: 0.0795
[544/15000], training loss: 0.0892
[552/15000], training loss: 0.0922
[560/15000], training loss: 0.0858
16
AVD_Home_010_1_traj1, ate: 778.9868136446047
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[568/15000], training loss: 0.0934
[576/15000], training loss: 0.0930
[584/15000], training loss: 0.0908
[592/15000], training loss: 0.0931
[600/15000], training loss: 0.0832
16
AVD_Home_010_1_traj1, ate: 759.2929096458671
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[608/15000], training loss: 0.0948
[616/15000], training loss: 0.0802
[624/15000], training loss: 0.1020
[632/15000], training loss: 0.0821
[640/15000], training loss: 0.0869
16
AVD_Home_010_1_traj1, ate: 802.9770572683512
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[648/15000], training loss: 0.0808
[656/15000], training loss: 0.0854
[664/15000], training loss: 0.0853
[672/15000], training loss: 0.0935
[680/15000], training loss: 0.0885
16
AVD_Home_010_1_traj1, ate: 809.4769434994531
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[688/15000], training loss: 0.0961
[696/15000], training loss: 0.0867
[704/15000], training loss: 0.0858
[712/15000], training loss: 0.0898
[720/15000], training loss: 0.0739
16
AVD_Home_010_1_traj1, ate: 805.9760411278355
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[728/15000], training loss: 0.0854
[736/15000], training loss: 0.0858
[744/15000], training loss: 0.0916
[752/15000], training loss: 0.0915
[760/15000], training loss: 0.0803
16
AVD_Home_010_1_traj1, ate: 806.4117368540869
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[768/15000], training loss: 0.0884
[776/15000], training loss: 0.0959
[784/15000], training loss: 0.0890
[792/15000], training loss: 0.0877
[800/15000], training loss: 0.0867
16
AVD_Home_010_1_traj1, ate: 741.4678168798428
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[808/15000], training loss: 0.0782
[816/15000], training loss: 0.0841
[824/15000], training loss: 0.0824
[832/15000], training loss: 0.0767
[840/15000], training loss: 0.0740
16
AVD_Home_010_1_traj1, ate: 759.075312772609
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[848/15000], training loss: 0.0940
[856/15000], training loss: 0.0905
[864/15000], training loss: 0.0888
[872/15000], training loss: 0.0892
[880/15000], training loss: 0.0889
16
AVD_Home_010_1_traj1, ate: 798.0888262954296
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[888/15000], training loss: 0.0913
[896/15000], training loss: 0.0847
[904/15000], training loss: 0.0727
[912/15000], training loss: 0.0751
[920/15000], training loss: 0.0749
16
AVD_Home_010_1_traj1, ate: 753.2170337823809
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[928/15000], training loss: 0.0728
[936/15000], training loss: 0.0815
[944/15000], training loss: 0.0879
[952/15000], training loss: 0.0744
[960/15000], training loss: 0.0662
16
AVD_Home_010_1_traj1, ate: 737.831237577335
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[968/15000], training loss: 0.0849
[976/15000], training loss: 0.0732
[984/15000], training loss: 0.0998
[992/15000], training loss: 0.0887
[1000/15000], training loss: 0.0841
16
AVD_Home_010_1_traj1, ate: 763.2827757999803
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[1008/15000], training loss: 0.0930
[1016/15000], training loss: 0.0783
[1024/15000], training loss: 0.0743
[1032/15000], training loss: 0.0782
[1040/15000], training loss: 0.0813
16
AVD_Home_010_1_traj1, ate: 732.4807853540266
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[1048/15000], training loss: 0.0805
[1056/15000], training loss: 0.0795
[1064/15000], training loss: 0.0789
[1072/15000], training loss: 0.0730
[1080/15000], training loss: 0.1010
16
AVD_Home_010_1_traj1, ate: 730.9047376298454
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[1088/15000], training loss: 0.0966
[1096/15000], training loss: 0.0778
[1104/15000], training loss: 0.0816
[1112/15000], training loss: 0.0756
[1120/15000], training loss: 0.0816
16
AVD_Home_010_1_traj1, ate: 778.8109832286362
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[1128/15000], training loss: 0.1205
[1136/15000], training loss: 0.0911
[1144/15000], training loss: 0.0796
[1152/15000], training loss: 0.0838
[1160/15000], training loss: 0.0950
16
AVD_Home_010_1_traj1, ate: 728.657213436178
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[1168/15000], training loss: 0.0753
[1176/15000], training loss: 0.0867
[1184/15000], training loss: 0.0836
[1192/15000], training loss: 0.0822
[1200/15000], training loss: 0.0753
16
AVD_Home_010_1_traj1, ate: 752.3736172772263
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[1208/15000], training loss: 0.0813
[1216/15000], training loss: 0.0802
[1224/15000], training loss: 0.0718
[1232/15000], training loss: 0.0681
[1240/15000], training loss: 0.0739
16
AVD_Home_010_1_traj1, ate: 742.6478987273954
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[1248/15000], training loss: 0.0886
[1256/15000], training loss: 0.0688
[1264/15000], training loss: 0.0733
[1272/15000], training loss: 0.0793
[1280/15000], training loss: 0.0679
16
AVD_Home_010_1_traj1, ate: 760.1784849671643
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[1288/15000], training loss: 0.0699
[1296/15000], training loss: 0.1017
[1304/15000], training loss: 0.0789
[1312/15000], training loss: 0.0851
[1320/15000], training loss: 0.0868
16
AVD_Home_010_1_traj1, ate: 717.1502913638274
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[1328/15000], training loss: 0.0628
[1336/15000], training loss: 0.0837
[1344/15000], training loss: 0.0773
[1352/15000], training loss: 0.0861
[1360/15000], training loss: 0.0702
16
AVD_Home_010_1_traj1, ate: 716.0902283751349
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[1368/15000], training loss: 0.0882
[1376/15000], training loss: 0.0865
[1384/15000], training loss: 0.0730
[1392/15000], training loss: 0.0768
[1400/15000], training loss: 0.0946
16
AVD_Home_010_1_traj1, ate: 753.0094357796148
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[1408/15000], training loss: 0.0722
[1416/15000], training loss: 0.0663
[1424/15000], training loss: 0.0950
[1432/15000], training loss: 0.0904
[1440/15000], training loss: 0.0858
16
AVD_Home_010_1_traj1, ate: 716.6218160862271
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[1448/15000], training loss: 0.0855
[1456/15000], training loss: 0.0828
[1464/15000], training loss: 0.0753
[1472/15000], training loss: 0.0875
[1480/15000], training loss: 0.0709
16
AVD_Home_010_1_traj1, ate: 702.5655278215586
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[1488/15000], training loss: 0.0762
[1496/15000], training loss: 0.0682
[1504/15000], training loss: 0.0756
[1512/15000], training loss: 0.0675
[1520/15000], training loss: 0.0690
16
AVD_Home_010_1_traj1, ate: 738.7375101130584
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[1528/15000], training loss: 0.0867
[1536/15000], training loss: 0.0831
[1544/15000], training loss: 0.0805
[1552/15000], training loss: 0.0686
[1560/15000], training loss: 0.0708
16
AVD_Home_010_1_traj1, ate: 743.1078980719332
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[1568/15000], training loss: 0.0811
[1576/15000], training loss: 0.0992
[1584/15000], training loss: 0.0715
[1592/15000], training loss: 0.0687
[1600/15000], training loss: 0.0781
16
AVD_Home_010_1_traj1, ate: 719.1237008226661
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[1608/15000], training loss: 0.0743
[1616/15000], training loss: 0.0633
[1624/15000], training loss: 0.0689
[1632/15000], training loss: 0.0855
[1640/15000], training loss: 0.0720
16
AVD_Home_010_1_traj1, ate: 715.8025782088803
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[1648/15000], training loss: 0.0801
[1656/15000], training loss: 0.0888
[1664/15000], training loss: 0.0813
[1672/15000], training loss: 0.0774
[1680/15000], training loss: 0.0710
16
AVD_Home_010_1_traj1, ate: 719.67103224764
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[1688/15000], training loss: 0.0735
[1696/15000], training loss: 0.0662
[1704/15000], training loss: 0.0800
[1712/15000], training loss: 0.0842
[1720/15000], training loss: 0.0962
16
AVD_Home_010_1_traj1, ate: 714.0739923474029
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[1728/15000], training loss: 0.0752
[1736/15000], training loss: 0.0707
[1744/15000], training loss: 0.0759
[1752/15000], training loss: 0.0825
[1760/15000], training loss: 0.0737
16
AVD_Home_010_1_traj1, ate: 715.4466447971013
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[1768/15000], training loss: 0.0880
[1776/15000], training loss: 0.0718
[1784/15000], training loss: 0.0695
[1792/15000], training loss: 0.0759
[1800/15000], training loss: 0.0898
16
AVD_Home_010_1_traj1, ate: 720.5539540589208
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[1808/15000], training loss: 0.0958
[1816/15000], training loss: 0.0958
[1824/15000], training loss: 0.0987
[1832/15000], training loss: 0.0844
[1840/15000], training loss: 0.0926
16
AVD_Home_010_1_traj1, ate: 685.2590677457022
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[1848/15000], training loss: 0.0877
[1856/15000], training loss: 0.0730
[1864/15000], training loss: 0.0606
[1872/15000], training loss: 0.0776
[1880/15000], training loss: 0.0823
16
AVD_Home_010_1_traj1, ate: 686.1926606563388
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[1888/15000], training loss: 0.0987
[1896/15000], training loss: 0.0845
[1904/15000], training loss: 0.0774
[1912/15000], training loss: 0.0717
[1920/15000], training loss: 0.0817
16
AVD_Home_010_1_traj1, ate: 717.7473323316107
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[1928/15000], training loss: 0.0770
[1936/15000], training loss: 0.0792
[1944/15000], training loss: 0.0908
[1952/15000], training loss: 0.0700
[1960/15000], training loss: 0.0728
16
AVD_Home_010_1_traj1, ate: 729.8959759062648
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[1968/15000], training loss: 0.0950
[1976/15000], training loss: 0.0935
[1984/15000], training loss: 0.0825
[1992/15000], training loss: 0.0945
[2000/15000], training loss: 0.0728
16
AVD_Home_010_1_traj1, ate: 708.2670342146961
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[2008/15000], training loss: 0.0743
[2016/15000], training loss: 0.0881
[2024/15000], training loss: 0.0653
[2032/15000], training loss: 0.0739
[2040/15000], training loss: 0.0919
16
AVD_Home_010_1_traj1, ate: 701.5694334334195
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[2048/15000], training loss: 0.0746
[2056/15000], training loss: 0.0659
[2064/15000], training loss: 0.0823
[2072/15000], training loss: 0.0902
[2080/15000], training loss: 0.0993
16
AVD_Home_010_1_traj1, ate: 705.0584081682687
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[2088/15000], training loss: 0.0905
[2096/15000], training loss: 0.0855
[2104/15000], training loss: 0.0773
[2112/15000], training loss: 0.0677
[2120/15000], training loss: 0.0843
16
AVD_Home_010_1_traj1, ate: 715.7707571350772
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[2128/15000], training loss: 0.0848
[2136/15000], training loss: 0.0864
[2144/15000], training loss: 0.0790
[2152/15000], training loss: 0.0855
[2160/15000], training loss: 0.0825
16
AVD_Home_010_1_traj1, ate: 674.7507215856756
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[2168/15000], training loss: 0.0663
[2176/15000], training loss: 0.0715
[2184/15000], training loss: 0.0741
[2192/15000], training loss: 0.0736
[2200/15000], training loss: 0.0781
16
AVD_Home_010_1_traj1, ate: 727.9347954469832
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[2208/15000], training loss: 0.0576
[2216/15000], training loss: 0.0720
[2224/15000], training loss: 0.0627
[2232/15000], training loss: 0.0773
[2240/15000], training loss: 0.0765
16
AVD_Home_010_1_traj1, ate: 701.1771631440314
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[2248/15000], training loss: 0.0709
[2256/15000], training loss: 0.0794
[2264/15000], training loss: 0.0763
[2272/15000], training loss: 0.0589
[2280/15000], training loss: 0.0629
16
AVD_Home_010_1_traj1, ate: 701.9324276370387
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[2288/15000], training loss: 0.0638
[2296/15000], training loss: 0.0979
[2304/15000], training loss: 0.0748
[2312/15000], training loss: 0.0648
[2320/15000], training loss: 0.0737
16
AVD_Home_010_1_traj1, ate: 705.4499176792328
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[2328/15000], training loss: 0.0762
[2336/15000], training loss: 0.0699
[2344/15000], training loss: 0.0699
[2352/15000], training loss: 0.0730
[2360/15000], training loss: 0.0794
16
AVD_Home_010_1_traj1, ate: 680.3074996520742
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[2368/15000], training loss: 0.0544
[2376/15000], training loss: 0.0875
[2384/15000], training loss: 0.0751
[2392/15000], training loss: 0.0707
[2400/15000], training loss: 0.0625
16
AVD_Home_010_1_traj1, ate: 686.362609761498
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[2408/15000], training loss: 0.0705
[2416/15000], training loss: 0.0610
[2424/15000], training loss: 0.0733
[2432/15000], training loss: 0.0754
[2440/15000], training loss: 0.0841
16
AVD_Home_010_1_traj1, ate: 682.3742324693923
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[2448/15000], training loss: 0.0717
[2456/15000], training loss: 0.0799
[2464/15000], training loss: 0.0873
[2472/15000], training loss: 0.0585
[2480/15000], training loss: 0.0705
16
AVD_Home_010_1_traj1, ate: 679.7198691413412
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[2488/15000], training loss: 0.0640
[2496/15000], training loss: 0.0714
[2504/15000], training loss: 0.0757
[2512/15000], training loss: 0.0727
[2520/15000], training loss: 0.0681
16
AVD_Home_010_1_traj1, ate: 697.0313731332142
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[2528/15000], training loss: 0.0722
[2536/15000], training loss: 0.0659
[2544/15000], training loss: 0.0604
[2552/15000], training loss: 0.0621
[2560/15000], training loss: 0.0779
16
AVD_Home_010_1_traj1, ate: 659.1184277278182
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[2568/15000], training loss: 0.0859
[2576/15000], training loss: 0.0648
[2584/15000], training loss: 0.0785
[2592/15000], training loss: 0.0754
[2600/15000], training loss: 0.0732
16
AVD_Home_010_1_traj1, ate: 672.4877970410504
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[2608/15000], training loss: 0.0791
[2616/15000], training loss: 0.0841
[2624/15000], training loss: 0.0642
[2632/15000], training loss: 0.0755
[2640/15000], training loss: 0.0774
16
AVD_Home_010_1_traj1, ate: 669.710204149646
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[2648/15000], training loss: 0.0852
[2656/15000], training loss: 0.0827
[2664/15000], training loss: 0.0754
[2672/15000], training loss: 0.0704
[2680/15000], training loss: 0.0865
16
AVD_Home_010_1_traj1, ate: 668.6327677444947
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[2688/15000], training loss: 0.0938
[2696/15000], training loss: 0.0683
[2704/15000], training loss: 0.0587
[2712/15000], training loss: 0.0833
[2720/15000], training loss: 0.1141
16
AVD_Home_010_1_traj1, ate: 653.5986842593934
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[2728/15000], training loss: 0.0664
[2736/15000], training loss: 0.0660
[2744/15000], training loss: 0.0636
[2752/15000], training loss: 0.0820
[2760/15000], training loss: 0.0781
16
AVD_Home_010_1_traj1, ate: 642.6808484138146
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[2768/15000], training loss: 0.0733
[2776/15000], training loss: 0.0724
[2784/15000], training loss: 0.0810
[2792/15000], training loss: 0.0745
[2800/15000], training loss: 0.0581
16
AVD_Home_010_1_traj1, ate: 645.6178387256995
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[2808/15000], training loss: 0.0700
[2816/15000], training loss: 0.0537
[2824/15000], training loss: 0.0623
[2832/15000], training loss: 0.0752
[2840/15000], training loss: 0.0849
16
AVD_Home_010_1_traj1, ate: 639.583117842326
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[2848/15000], training loss: 0.0627
[2856/15000], training loss: 0.0607
[2864/15000], training loss: 0.0788
[2872/15000], training loss: 0.0675
[2880/15000], training loss: 0.0654
16
AVD_Home_010_1_traj1, ate: 613.8053856566163
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[2888/15000], training loss: 0.0679
[2896/15000], training loss: 0.0933
[2904/15000], training loss: 0.0687
[2912/15000], training loss: 0.0569
[2920/15000], training loss: 0.0972
16
AVD_Home_010_1_traj1, ate: 645.8915515576533
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[2928/15000], training loss: 0.0942
[2936/15000], training loss: 0.0700
[2944/15000], training loss: 0.0742
[2952/15000], training loss: 0.0663
[2960/15000], training loss: 0.0678
16
AVD_Home_010_1_traj1, ate: 615.5225532617518
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[2968/15000], training loss: 0.0744
[2976/15000], training loss: 0.0863
[2984/15000], training loss: 0.0622
[2992/15000], training loss: 0.0662
[3000/15000], training loss: 0.0663
16
AVD_Home_010_1_traj1, ate: 628.483358236985
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[3008/15000], training loss: 0.0642
[3016/15000], training loss: 0.0627
[3024/15000], training loss: 0.0625
[3032/15000], training loss: 0.0582
[3040/15000], training loss: 0.0700
16
AVD_Home_010_1_traj1, ate: 630.3970148794979
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[3048/15000], training loss: 0.0562
[3056/15000], training loss: 0.0577
[3064/15000], training loss: 0.0723
[3072/15000], training loss: 0.0806
[3080/15000], training loss: 0.0762
16
AVD_Home_010_1_traj1, ate: 614.2722161676098
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[3088/15000], training loss: 0.0780
[3096/15000], training loss: 0.0620
[3104/15000], training loss: 0.0743
[3112/15000], training loss: 0.0683
[3120/15000], training loss: 0.0644
16
AVD_Home_010_1_traj1, ate: 606.0642830342805
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[3128/15000], training loss: 0.0593
[3136/15000], training loss: 0.0513
[3144/15000], training loss: 0.0705
[3152/15000], training loss: 0.0821
[3160/15000], training loss: 0.0665
16
AVD_Home_010_1_traj1, ate: 617.3602145909044
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[3168/15000], training loss: 0.0627
[3176/15000], training loss: 0.0513
[3184/15000], training loss: 0.0826
[3192/15000], training loss: 0.0718
[3200/15000], training loss: 0.0626
16
AVD_Home_010_1_traj1, ate: 617.2066367644483
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[3208/15000], training loss: 0.0618
[3216/15000], training loss: 0.0950
[3224/15000], training loss: 0.0775
[3232/15000], training loss: 0.0782
[3240/15000], training loss: 0.0676
16
AVD_Home_010_1_traj1, ate: 601.547023423099
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[3248/15000], training loss: 0.0629
[3256/15000], training loss: 0.0564
[3264/15000], training loss: 0.0725
[3272/15000], training loss: 0.0782
[3280/15000], training loss: 0.0554
16
AVD_Home_010_1_traj1, ate: 600.0915139309172
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[3288/15000], training loss: 0.0553
[3296/15000], training loss: 0.0701
[3304/15000], training loss: 0.0555
[3312/15000], training loss: 0.0672
[3320/15000], training loss: 0.0605
16
AVD_Home_010_1_traj1, ate: 601.3577191882007
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[3328/15000], training loss: 0.0673
[3336/15000], training loss: 0.0607
[3344/15000], training loss: 0.0708
[3352/15000], training loss: 0.0686
[3360/15000], training loss: 0.0777
16
AVD_Home_010_1_traj1, ate: 589.0259037030271
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[3368/15000], training loss: 0.0786
[3376/15000], training loss: 0.0588
[3384/15000], training loss: 0.0555
[3392/15000], training loss: 0.0717
[3400/15000], training loss: 0.0609
16
AVD_Home_010_1_traj1, ate: 594.6064080692531
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[3408/15000], training loss: 0.0575
[3416/15000], training loss: 0.0645
[3424/15000], training loss: 0.0646
[3432/15000], training loss: 0.0722
[3440/15000], training loss: 0.0720
16
AVD_Home_010_1_traj1, ate: 600.999089036964
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[3448/15000], training loss: 0.0817
[3456/15000], training loss: 0.1022
[3464/15000], training loss: 0.0688
[3472/15000], training loss: 0.0730
[3480/15000], training loss: 0.0595
16
AVD_Home_010_1_traj1, ate: 590.25945829053
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[3488/15000], training loss: 0.0661
[3496/15000], training loss: 0.0769
[3504/15000], training loss: 0.0792
[3512/15000], training loss: 0.0532
[3520/15000], training loss: 0.0569
16
AVD_Home_010_1_traj1, ate: 608.0472651437871
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[3528/15000], training loss: 0.0623
[3536/15000], training loss: 0.0613
[3544/15000], training loss: 0.0750
[3552/15000], training loss: 0.0767
[3560/15000], training loss: 0.0780
16
AVD_Home_010_1_traj1, ate: 596.4252397072405
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[3568/15000], training loss: 0.0632
[3576/15000], training loss: 0.0690
[3584/15000], training loss: 0.0641
[3592/15000], training loss: 0.0613
[3600/15000], training loss: 0.0658
16
AVD_Home_010_1_traj1, ate: 601.4363379209422
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[3608/15000], training loss: 0.0669
[3616/15000], training loss: 0.0600
[3624/15000], training loss: 0.0686
[3632/15000], training loss: 0.0676
[3640/15000], training loss: 0.0674
16
AVD_Home_010_1_traj1, ate: 579.9595878181866
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[3648/15000], training loss: 0.0645
[3656/15000], training loss: 0.0702
[3664/15000], training loss: 0.0632
[3672/15000], training loss: 0.0587
[3680/15000], training loss: 0.0708
16
AVD_Home_010_1_traj1, ate: 575.1815040851977
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[3688/15000], training loss: 0.0519
[3696/15000], training loss: 0.0758
[3704/15000], training loss: 0.0674
[3712/15000], training loss: 0.0806
[3720/15000], training loss: 0.0638
16
AVD_Home_010_1_traj1, ate: 588.8925980606963
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[3728/15000], training loss: 0.0596
[3736/15000], training loss: 0.0583
[3744/15000], training loss: 0.0627
[3752/15000], training loss: 0.0529
[3760/15000], training loss: 0.0569
16
AVD_Home_010_1_traj1, ate: 580.5987343010978
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[3768/15000], training loss: 0.0582
[3776/15000], training loss: 0.0507
[3784/15000], training loss: 0.0617
[3792/15000], training loss: 0.0565
[3800/15000], training loss: 0.0591
16
AVD_Home_010_1_traj1, ate: 579.0703682557671
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[3808/15000], training loss: 0.0682
[3816/15000], training loss: 0.0698
[3824/15000], training loss: 0.0634
[3832/15000], training loss: 0.0541
[3840/15000], training loss: 0.0813
16
AVD_Home_010_1_traj1, ate: 585.4577849172485
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[3848/15000], training loss: 0.0652
[3856/15000], training loss: 0.0641
[3864/15000], training loss: 0.0556
[3872/15000], training loss: 0.0811
[3880/15000], training loss: 0.0741
16
AVD_Home_010_1_traj1, ate: 577.4857952541832
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[3888/15000], training loss: 0.0498
[3896/15000], training loss: 0.0545
[3904/15000], training loss: 0.0675
[3912/15000], training loss: 0.0570
[3920/15000], training loss: 0.0881
16
AVD_Home_010_1_traj1, ate: 592.6800388459542
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[3928/15000], training loss: 0.0795
[3936/15000], training loss: 0.0807
[3944/15000], training loss: 0.0991
[3952/15000], training loss: 0.0617
[3960/15000], training loss: 0.0545
16
AVD_Home_010_1_traj1, ate: 562.5866021160527
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[3968/15000], training loss: 0.0723
[3976/15000], training loss: 0.0813
[3984/15000], training loss: 0.0601
[3992/15000], training loss: 0.0561
[4000/15000], training loss: 0.0641
16
AVD_Home_010_1_traj1, ate: 563.6135200399572
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[4008/15000], training loss: 0.0524
[4016/15000], training loss: 0.0613
[4024/15000], training loss: 0.0657
[4032/15000], training loss: 0.0669
[4040/15000], training loss: 0.0648
16
AVD_Home_010_1_traj1, ate: 556.5832612254385
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[4048/15000], training loss: 0.0550
[4056/15000], training loss: 0.0722
[4064/15000], training loss: 0.0642
[4072/15000], training loss: 0.0699
[4080/15000], training loss: 0.0494
16
AVD_Home_010_1_traj1, ate: 578.0351758736037
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[4088/15000], training loss: 0.0645
[4096/15000], training loss: 0.0540
[4104/15000], training loss: 0.0676
[4112/15000], training loss: 0.0709
[4120/15000], training loss: 0.0754
16
AVD_Home_010_1_traj1, ate: 563.4580585830167
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[4128/15000], training loss: 0.0497
[4136/15000], training loss: 0.0525
[4144/15000], training loss: 0.0617
[4152/15000], training loss: 0.0858
[4160/15000], training loss: 0.0689
16
AVD_Home_010_1_traj1, ate: 570.731826040606
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[4168/15000], training loss: 0.0555
[4176/15000], training loss: 0.0697
[4184/15000], training loss: 0.0635
[4192/15000], training loss: 0.0461
[4200/15000], training loss: 0.0615
16
AVD_Home_010_1_traj1, ate: 561.4982330323621
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[4208/15000], training loss: 0.0677
[4216/15000], training loss: 0.0598
[4224/15000], training loss: 0.0654
[4232/15000], training loss: 0.0737
[4240/15000], training loss: 0.0574
16
AVD_Home_010_1_traj1, ate: 561.4424493258762
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[4248/15000], training loss: 0.0939
[4256/15000], training loss: 0.0667
[4264/15000], training loss: 0.0792
[4272/15000], training loss: 0.0830
[4280/15000], training loss: 0.1225
16
AVD_Home_010_1_traj1, ate: 553.6892047322276
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[4288/15000], training loss: 0.0628
[4296/15000], training loss: 0.0710
[4304/15000], training loss: 0.0695
[4312/15000], training loss: 0.0751
[4320/15000], training loss: 0.0760
16
AVD_Home_010_1_traj1, ate: 568.7550176857549
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[4328/15000], training loss: 0.0591
[4336/15000], training loss: 0.0578
[4344/15000], training loss: 0.0574
[4352/15000], training loss: 0.0638
[4360/15000], training loss: 0.0573
16
AVD_Home_010_1_traj1, ate: 558.2902716231985
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[4368/15000], training loss: 0.0659
[4376/15000], training loss: 0.0614
[4384/15000], training loss: 0.0621
[4392/15000], training loss: 0.0601
[4400/15000], training loss: 0.0666
16
AVD_Home_010_1_traj1, ate: 558.7664894601087
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[4408/15000], training loss: 0.0709
[4416/15000], training loss: 0.0612
[4424/15000], training loss: 0.0641
[4432/15000], training loss: 0.0660
[4440/15000], training loss: 0.0696
16
AVD_Home_010_1_traj1, ate: 556.6937589039934
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[4448/15000], training loss: 0.0600
[4456/15000], training loss: 0.0589
[4464/15000], training loss: 0.0782
[4472/15000], training loss: 0.0706
[4480/15000], training loss: 0.0780
16
AVD_Home_010_1_traj1, ate: 556.6713123549005
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[4488/15000], training loss: 0.0700
[4496/15000], training loss: 0.0967
[4504/15000], training loss: 0.0827
[4512/15000], training loss: 0.0636
[4520/15000], training loss: 0.0585
16
AVD_Home_010_1_traj1, ate: 560.5891941367462
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[4528/15000], training loss: 0.0516
[4536/15000], training loss: 0.0522
[4544/15000], training loss: 0.0636
[4552/15000], training loss: 0.0517
[4560/15000], training loss: 0.0767
16
AVD_Home_010_1_traj1, ate: 565.9399160580027
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[4568/15000], training loss: 0.0591
[4576/15000], training loss: 0.0742
[4584/15000], training loss: 0.0767
[4592/15000], training loss: 0.0546
[4600/15000], training loss: 0.0633
16
AVD_Home_010_1_traj1, ate: 549.3909608048137
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[4608/15000], training loss: 0.0660
[4616/15000], training loss: 0.0535
[4624/15000], training loss: 0.0557
[4632/15000], training loss: 0.0706
[4640/15000], training loss: 0.0733
16
AVD_Home_010_1_traj1, ate: 558.3345337366588
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[4648/15000], training loss: 0.0768
[4656/15000], training loss: 0.0618
[4664/15000], training loss: 0.0853
[4672/15000], training loss: 0.0579
[4680/15000], training loss: 0.0680
16
AVD_Home_010_1_traj1, ate: 548.4490482400271
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[4688/15000], training loss: 0.0787
[4696/15000], training loss: 0.0756
[4704/15000], training loss: 0.0641
[4712/15000], training loss: 0.0482
[4720/15000], training loss: 0.0451
16
AVD_Home_010_1_traj1, ate: 548.5196547081543
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[4728/15000], training loss: 0.0689
[4736/15000], training loss: 0.0736
[4744/15000], training loss: 0.0571
[4752/15000], training loss: 0.0574
[4760/15000], training loss: 0.0753
16
AVD_Home_010_1_traj1, ate: 550.0997813789935
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[4768/15000], training loss: 0.0546
[4776/15000], training loss: 0.0454
[4784/15000], training loss: 0.0860
[4792/15000], training loss: 0.0606
[4800/15000], training loss: 0.0596
16
AVD_Home_010_1_traj1, ate: 548.4526988852715
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[4808/15000], training loss: 0.0746
[4816/15000], training loss: 0.0660
[4824/15000], training loss: 0.0920
[4832/15000], training loss: 0.0574
[4840/15000], training loss: 0.0635
16
AVD_Home_010_1_traj1, ate: 550.7513903838932
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[4848/15000], training loss: 0.0724
[4856/15000], training loss: 0.0634
[4864/15000], training loss: 0.0514
[4872/15000], training loss: 0.0701
[4880/15000], training loss: 0.0646
16
AVD_Home_010_1_traj1, ate: 554.5830015944321
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[4888/15000], training loss: 0.0739
[4896/15000], training loss: 0.0504
[4904/15000], training loss: 0.0559
[4912/15000], training loss: 0.0565
[4920/15000], training loss: 0.0559
16
AVD_Home_010_1_traj1, ate: 553.425549273203
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[4928/15000], training loss: 0.0879
[4936/15000], training loss: 0.0611
[4944/15000], training loss: 0.0896
[4952/15000], training loss: 0.0510
[4960/15000], training loss: 0.0606
16
AVD_Home_010_1_traj1, ate: 550.0676764729311
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[4968/15000], training loss: 0.0731
[4976/15000], training loss: 0.0782
[4984/15000], training loss: 0.0626
[4992/15000], training loss: 0.0482
[5000/15000], training loss: 0.0783
16
AVD_Home_010_1_traj1, ate: 552.2413803495939
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[5008/15000], training loss: 0.0641
[5016/15000], training loss: 0.0654
[5024/15000], training loss: 0.0655
[5032/15000], training loss: 0.0488
[5040/15000], training loss: 0.0516
16
AVD_Home_010_1_traj1, ate: 552.6725085360043
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[5048/15000], training loss: 0.0757
[5056/15000], training loss: 0.0792
[5064/15000], training loss: 0.0643
[5072/15000], training loss: 0.0568
[5080/15000], training loss: 0.0609
16
AVD_Home_010_1_traj1, ate: 547.8129181359444
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[5088/15000], training loss: 0.0575
[5096/15000], training loss: 0.0588
[5104/15000], training loss: 0.0499
[5112/15000], training loss: 0.0759
[5120/15000], training loss: 0.0752
16
AVD_Home_010_1_traj1, ate: 547.1965480280976
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[5128/15000], training loss: 0.0699
[5136/15000], training loss: 0.0785
[5144/15000], training loss: 0.0565
[5152/15000], training loss: 0.0554
[5160/15000], training loss: 0.0571
16
AVD_Home_010_1_traj1, ate: 547.9118662660695
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[5168/15000], training loss: 0.0546
[5176/15000], training loss: 0.0670
[5184/15000], training loss: 0.0784
[5192/15000], training loss: 0.0869
[5200/15000], training loss: 0.0757
16
AVD_Home_010_1_traj1, ate: 539.4161229285935
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[5208/15000], training loss: 0.0832
[5216/15000], training loss: 0.0566
[5224/15000], training loss: 0.0883
[5232/15000], training loss: 0.0464
[5240/15000], training loss: 0.0694
16
AVD_Home_010_1_traj1, ate: 540.6816931320028
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[5248/15000], training loss: 0.0577
[5256/15000], training loss: 0.0604
[5264/15000], training loss: 0.0647
[5272/15000], training loss: 0.0775
[5280/15000], training loss: 0.0709
16
AVD_Home_010_1_traj1, ate: 533.3213910469259
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[5288/15000], training loss: 0.0640
[5296/15000], training loss: 0.0643
[5304/15000], training loss: 0.0937
[5312/15000], training loss: 0.0483
[5320/15000], training loss: 0.0746
16
AVD_Home_010_1_traj1, ate: 555.9083138686849
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[5328/15000], training loss: 0.0888
[5336/15000], training loss: 0.0724
[5344/15000], training loss: 0.0575
[5352/15000], training loss: 0.0785
[5360/15000], training loss: 0.0771
16
AVD_Home_010_1_traj1, ate: 546.1621294111497
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[5368/15000], training loss: 0.0900
[5376/15000], training loss: 0.0604
[5384/15000], training loss: 0.0802
[5392/15000], training loss: 0.0463
[5400/15000], training loss: 0.0649
16
AVD_Home_010_1_traj1, ate: 547.1504361150809
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[5408/15000], training loss: 0.0719
[5416/15000], training loss: 0.0595
[5424/15000], training loss: 0.0722
[5432/15000], training loss: 0.0478
[5440/15000], training loss: 0.0560
16
AVD_Home_010_1_traj1, ate: 536.2392070816509
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[5448/15000], training loss: 0.0895
[5456/15000], training loss: 0.0756
[5464/15000], training loss: 0.0737
[5472/15000], training loss: 0.0653
[5480/15000], training loss: 0.0899
16
AVD_Home_010_1_traj1, ate: 531.4750835454188
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[5488/15000], training loss: 0.0652
[5496/15000], training loss: 0.0558
[5504/15000], training loss: 0.0659
[5512/15000], training loss: 0.0531
[5520/15000], training loss: 0.0640
16
AVD_Home_010_1_traj1, ate: 542.7322462906974
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[5528/15000], training loss: 0.0719
[5536/15000], training loss: 0.0713
[5544/15000], training loss: 0.0496
[5552/15000], training loss: 0.0587
[5560/15000], training loss: 0.0696
16
AVD_Home_010_1_traj1, ate: 543.352625350765
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[5568/15000], training loss: 0.0585
[5576/15000], training loss: 0.0631
[5584/15000], training loss: 0.0866
[5592/15000], training loss: 0.0812
[5600/15000], training loss: 0.0559
16
AVD_Home_010_1_traj1, ate: 540.2090165140323
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[5608/15000], training loss: 0.0550
[5616/15000], training loss: 0.0465
[5624/15000], training loss: 0.0726
[5632/15000], training loss: 0.0706
[5640/15000], training loss: 0.0516
16
AVD_Home_010_1_traj1, ate: 540.4747152335269
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[5648/15000], training loss: 0.0521
[5656/15000], training loss: 0.0638
[5664/15000], training loss: 0.0741
[5672/15000], training loss: 0.0626
[5680/15000], training loss: 0.0470
16
AVD_Home_010_1_traj1, ate: 525.4809205633404
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[5688/15000], training loss: 0.0633
[5696/15000], training loss: 0.0756
[5704/15000], training loss: 0.0580
[5712/15000], training loss: 0.0644
[5720/15000], training loss: 0.0691
16
AVD_Home_010_1_traj1, ate: 547.2214526664753
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[5728/15000], training loss: 0.0569
[5736/15000], training loss: 0.0614
[5744/15000], training loss: 0.0649
[5752/15000], training loss: 0.0711
[5760/15000], training loss: 0.0529
16
AVD_Home_010_1_traj1, ate: 540.472027466017
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[5768/15000], training loss: 0.0766
[5776/15000], training loss: 0.0683
[5784/15000], training loss: 0.0593
[5792/15000], training loss: 0.0541
[5800/15000], training loss: 0.0651
16
AVD_Home_010_1_traj1, ate: 538.6269820141507
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[5808/15000], training loss: 0.0575
[5816/15000], training loss: 0.0780
[5824/15000], training loss: 0.0494
[5832/15000], training loss: 0.0586
[5840/15000], training loss: 0.0511
16
AVD_Home_010_1_traj1, ate: 543.1551968198839
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[5848/15000], training loss: 0.0609
[5856/15000], training loss: 0.0554
[5864/15000], training loss: 0.0968
[5872/15000], training loss: 0.0568
[5880/15000], training loss: 0.0477
16
AVD_Home_010_1_traj1, ate: 537.047245506069
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[5888/15000], training loss: 0.0473
[5896/15000], training loss: 0.0502
[5904/15000], training loss: 0.0536
[5912/15000], training loss: 0.0499
[5920/15000], training loss: 0.0677
16
AVD_Home_010_1_traj1, ate: 531.8254694430234
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[5928/15000], training loss: 0.0690
[5936/15000], training loss: 0.0918
[5944/15000], training loss: 0.0587
[5952/15000], training loss: 0.0691
[5960/15000], training loss: 0.0804
16
AVD_Home_010_1_traj1, ate: 539.5875546273683
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[5968/15000], training loss: 0.0590
[5976/15000], training loss: 0.0656
[5984/15000], training loss: 0.0570
[5992/15000], training loss: 0.0515
[6000/15000], training loss: 0.0551
16
AVD_Home_010_1_traj1, ate: 543.3765231783017
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[6008/15000], training loss: 0.0525
[6016/15000], training loss: 0.0712
[6024/15000], training loss: 0.0667
[6032/15000], training loss: 0.0626
[6040/15000], training loss: 0.0593
16
AVD_Home_010_1_traj1, ate: 536.7332785083316
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[6048/15000], training loss: 0.0825
[6056/15000], training loss: 0.0471
[6064/15000], training loss: 0.0614
[6072/15000], training loss: 0.0629
[6080/15000], training loss: 0.0579
16
AVD_Home_010_1_traj1, ate: 536.0887086567571
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[6088/15000], training loss: 0.0511
[6096/15000], training loss: 0.0495
[6104/15000], training loss: 0.0654
[6112/15000], training loss: 0.0610
[6120/15000], training loss: 0.0715
16
AVD_Home_010_1_traj1, ate: 539.3915438775091
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[6128/15000], training loss: 0.0968
[6136/15000], training loss: 0.0604
[6144/15000], training loss: 0.0739
[6152/15000], training loss: 0.0520
[6160/15000], training loss: 0.0709
16
AVD_Home_010_1_traj1, ate: 544.7210011578621
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[6168/15000], training loss: 0.0509
[6176/15000], training loss: 0.0520
[6184/15000], training loss: 0.0577
[6192/15000], training loss: 0.0519
[6200/15000], training loss: 0.0494
16
AVD_Home_010_1_traj1, ate: 532.2024190071879
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[6208/15000], training loss: 0.0664
[6216/15000], training loss: 0.0447
[6224/15000], training loss: 0.0472
[6232/15000], training loss: 0.0645
[6240/15000], training loss: 0.0526
16
AVD_Home_010_1_traj1, ate: 530.3323668140209
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[6248/15000], training loss: 0.0620
[6256/15000], training loss: 0.0626
[6264/15000], training loss: 0.0447
[6272/15000], training loss: 0.0451
[6280/15000], training loss: 0.0655
16
AVD_Home_010_1_traj1, ate: 538.9599455976928
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[6288/15000], training loss: 0.0879
[6296/15000], training loss: 0.0545
[6304/15000], training loss: 0.0448
[6312/15000], training loss: 0.0731
[6320/15000], training loss: 0.0580
16
AVD_Home_010_1_traj1, ate: 533.6630861416463
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[6328/15000], training loss: 0.0464
[6336/15000], training loss: 0.0527
[6344/15000], training loss: 0.0602
[6352/15000], training loss: 0.0609
[6360/15000], training loss: 0.0424
16
AVD_Home_010_1_traj1, ate: 530.1997939177652
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[6368/15000], training loss: 0.0521
[6376/15000], training loss: 0.0500
[6384/15000], training loss: 0.0553
[6392/15000], training loss: 0.0592
[6400/15000], training loss: 0.0486
16
AVD_Home_010_1_traj1, ate: 536.2676763516789
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[6408/15000], training loss: 0.0567
[6416/15000], training loss: 0.0589
[6424/15000], training loss: 0.0493
[6432/15000], training loss: 0.0588
[6440/15000], training loss: 0.0561
16
AVD_Home_010_1_traj1, ate: 531.8928844809407
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[6448/15000], training loss: 0.0407
[6456/15000], training loss: 0.0534
[6464/15000], training loss: 0.0730
[6472/15000], training loss: 0.0750
[6480/15000], training loss: 0.0675
16
AVD_Home_010_1_traj1, ate: 532.3218522029283
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[6488/15000], training loss: 0.0564
[6496/15000], training loss: 0.0464
[6504/15000], training loss: 0.0564
[6512/15000], training loss: 0.0735
[6520/15000], training loss: 0.0628
16
AVD_Home_010_1_traj1, ate: 529.216609336699
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[6528/15000], training loss: 0.0629
[6536/15000], training loss: 0.0489
[6544/15000], training loss: 0.0833
[6552/15000], training loss: 0.0425
[6560/15000], training loss: 0.0513
16
AVD_Home_010_1_traj1, ate: 538.3962573109944
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[6568/15000], training loss: 0.0709
[6576/15000], training loss: 0.0621
[6584/15000], training loss: 0.0477
[6592/15000], training loss: 0.0691
[6600/15000], training loss: 0.0653
16
AVD_Home_010_1_traj1, ate: 526.9415774943711
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[6608/15000], training loss: 0.0526
[6616/15000], training loss: 0.0634
[6624/15000], training loss: 0.0457
[6632/15000], training loss: 0.0634
[6640/15000], training loss: 0.0427
16
AVD_Home_010_1_traj1, ate: 528.7454800696739
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[6648/15000], training loss: 0.0786
[6656/15000], training loss: 0.0625
[6664/15000], training loss: 0.0432
[6672/15000], training loss: 0.0562
[6680/15000], training loss: 0.0568
16
AVD_Home_010_1_traj1, ate: 525.8382463473679
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[6688/15000], training loss: 0.0667
[6696/15000], training loss: 0.0483
[6704/15000], training loss: 0.0608
[6712/15000], training loss: 0.0664
[6720/15000], training loss: 0.0724
16
AVD_Home_010_1_traj1, ate: 532.5644471722896
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[6728/15000], training loss: 0.0702
[6736/15000], training loss: 0.0646
[6744/15000], training loss: 0.0599
[6752/15000], training loss: 0.0501
[6760/15000], training loss: 0.0492
16
AVD_Home_010_1_traj1, ate: 524.656351865159
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[6768/15000], training loss: 0.0653
[6776/15000], training loss: 0.0785
[6784/15000], training loss: 0.0553
[6792/15000], training loss: 0.0451
[6800/15000], training loss: 0.0664
16
AVD_Home_010_1_traj1, ate: 533.995459493383
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[6808/15000], training loss: 0.0599
[6816/15000], training loss: 0.0421
[6824/15000], training loss: 0.0468
[6832/15000], training loss: 0.0658
[6840/15000], training loss: 0.0491
16
AVD_Home_010_1_traj1, ate: 527.0427178125941
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[6848/15000], training loss: 0.0521
[6856/15000], training loss: 0.0522
[6864/15000], training loss: 0.0693
[6872/15000], training loss: 0.0470
[6880/15000], training loss: 0.0761
16
AVD_Home_010_1_traj1, ate: 534.5948405660862
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[6888/15000], training loss: 0.0533
[6896/15000], training loss: 0.0557
[6904/15000], training loss: 0.0485
[6912/15000], training loss: 0.0520
[6920/15000], training loss: 0.0779
16
AVD_Home_010_1_traj1, ate: 522.7116798689655
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[6928/15000], training loss: 0.0603
[6936/15000], training loss: 0.0515
[6944/15000], training loss: 0.0423
[6952/15000], training loss: 0.0512
[6960/15000], training loss: 0.0582
16
AVD_Home_010_1_traj1, ate: 530.8528445912394
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[6968/15000], training loss: 0.0537
[6976/15000], training loss: 0.0556
[6984/15000], training loss: 0.0532
[6992/15000], training loss: 0.0543
[7000/15000], training loss: 0.0783
16
AVD_Home_010_1_traj1, ate: 534.2246289873065
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[7008/15000], training loss: 0.0556
[7016/15000], training loss: 0.0520
[7024/15000], training loss: 0.0574
[7032/15000], training loss: 0.0448
[7040/15000], training loss: 0.0475
16
AVD_Home_010_1_traj1, ate: 531.2904776307654
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[7048/15000], training loss: 0.0565
[7056/15000], training loss: 0.0584
[7064/15000], training loss: 0.0659
[7072/15000], training loss: 0.0497
[7080/15000], training loss: 0.0469
16
AVD_Home_010_1_traj1, ate: 526.3843050975291
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[7088/15000], training loss: 0.0806
[7096/15000], training loss: 0.0669
[7104/15000], training loss: 0.0841
[7112/15000], training loss: 0.0620
[7120/15000], training loss: 0.0459
16
AVD_Home_010_1_traj1, ate: 531.3831719778088
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[7128/15000], training loss: 0.0553
[7136/15000], training loss: 0.1008
[7144/15000], training loss: 0.0690
[7152/15000], training loss: 0.0460
[7160/15000], training loss: 0.0498
16
AVD_Home_010_1_traj1, ate: 534.8649885305038
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[7168/15000], training loss: 0.0579
[7176/15000], training loss: 0.0506
[7184/15000], training loss: 0.0534
[7192/15000], training loss: 0.0649
[7200/15000], training loss: 0.0408
16
AVD_Home_010_1_traj1, ate: 528.6686868626563
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[7208/15000], training loss: 0.0504
[7216/15000], training loss: 0.0523
[7224/15000], training loss: 0.0721
[7232/15000], training loss: 0.0570
[7240/15000], training loss: 0.0529
16
AVD_Home_010_1_traj1, ate: 531.146323599503
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[7248/15000], training loss: 0.0471
[7256/15000], training loss: 0.0498
[7264/15000], training loss: 0.0455
[7272/15000], training loss: 0.0563
[7280/15000], training loss: 0.0737
16
AVD_Home_010_1_traj1, ate: 532.4518166309747
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[7288/15000], training loss: 0.0711
[7296/15000], training loss: 0.0447
[7304/15000], training loss: 0.0638
[7312/15000], training loss: 0.0675
[7320/15000], training loss: 0.0841
16
AVD_Home_010_1_traj1, ate: 521.6949689330218
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[7328/15000], training loss: 0.0639
[7336/15000], training loss: 0.0607
[7344/15000], training loss: 0.0489
[7352/15000], training loss: 0.0513
[7360/15000], training loss: 0.0661
16
AVD_Home_010_1_traj1, ate: 520.6342180352854
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[7368/15000], training loss: 0.0787
[7376/15000], training loss: 0.0631
[7384/15000], training loss: 0.0643
[7392/15000], training loss: 0.0598
[7400/15000], training loss: 0.0489
16
AVD_Home_010_1_traj1, ate: 531.2088248348495
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[7408/15000], training loss: 0.0440
[7416/15000], training loss: 0.0430
[7424/15000], training loss: 0.0570
[7432/15000], training loss: 0.0640
[7440/15000], training loss: 0.0722
16
AVD_Home_010_1_traj1, ate: 529.9927846348202
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[7448/15000], training loss: 0.0702
[7456/15000], training loss: 0.0526
[7464/15000], training loss: 0.0634
[7472/15000], training loss: 0.0645
[7480/15000], training loss: 0.0489
16
AVD_Home_010_1_traj1, ate: 530.1170625775669
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[7488/15000], training loss: 0.0642
[7496/15000], training loss: 0.0537
[7504/15000], training loss: 0.0615
[7512/15000], training loss: 0.0446
[7520/15000], training loss: 0.0552
16
AVD_Home_010_1_traj1, ate: 534.9133869337246
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[7528/15000], training loss: 0.0677
[7536/15000], training loss: 0.0578
[7544/15000], training loss: 0.0721
[7552/15000], training loss: 0.0542
[7560/15000], training loss: 0.0518
16
AVD_Home_010_1_traj1, ate: 531.2022129515476
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[7568/15000], training loss: 0.0648
[7576/15000], training loss: 0.0641
[7584/15000], training loss: 0.0605
[7592/15000], training loss: 0.0484
[7600/15000], training loss: 0.0524
16
AVD_Home_010_1_traj1, ate: 522.2594281152716
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[7608/15000], training loss: 0.0535
[7616/15000], training loss: 0.0502
[7624/15000], training loss: 0.0575
[7632/15000], training loss: 0.0642
[7640/15000], training loss: 0.0877
16
AVD_Home_010_1_traj1, ate: 511.0020696032015
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[7648/15000], training loss: 0.0549
[7656/15000], training loss: 0.0525
[7664/15000], training loss: 0.0617
[7672/15000], training loss: 0.0589
[7680/15000], training loss: 0.0504
16
AVD_Home_010_1_traj1, ate: 519.054223964618
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[7688/15000], training loss: 0.0736
[7696/15000], training loss: 0.0595
[7704/15000], training loss: 0.0683
[7712/15000], training loss: 0.0558
[7720/15000], training loss: 0.0486
16
AVD_Home_010_1_traj1, ate: 529.0862098156978
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[7728/15000], training loss: 0.0629
[7736/15000], training loss: 0.0629
[7744/15000], training loss: 0.0415
[7752/15000], training loss: 0.0486
[7760/15000], training loss: 0.0564
16
AVD_Home_010_1_traj1, ate: 529.8361203007996
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[7768/15000], training loss: 0.0897
[7776/15000], training loss: 0.0528
[7784/15000], training loss: 0.0474
[7792/15000], training loss: 0.0766
[7800/15000], training loss: 0.0471
16
AVD_Home_010_1_traj1, ate: 526.4820982031399
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[7808/15000], training loss: 0.0591
[7816/15000], training loss: 0.0735
[7824/15000], training loss: 0.0588
[7832/15000], training loss: 0.0450
[7840/15000], training loss: 0.0626
16
AVD_Home_010_1_traj1, ate: 530.9066965036028
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[7848/15000], training loss: 0.0426
[7856/15000], training loss: 0.0692
[7864/15000], training loss: 0.0686
[7872/15000], training loss: 0.0608
[7880/15000], training loss: 0.0417
16
AVD_Home_010_1_traj1, ate: 528.6997462338123
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[7888/15000], training loss: 0.0645
[7896/15000], training loss: 0.0669
[7904/15000], training loss: 0.0642
[7912/15000], training loss: 0.0413
[7920/15000], training loss: 0.1001
16
AVD_Home_010_1_traj1, ate: 529.1781773622308
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[7928/15000], training loss: 0.0511
[7936/15000], training loss: 0.0712
[7944/15000], training loss: 0.0563
[7952/15000], training loss: 0.0601
[7960/15000], training loss: 0.0584
16
AVD_Home_010_1_traj1, ate: 528.3897851957998
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[7968/15000], training loss: 0.0856
[7976/15000], training loss: 0.0453
[7984/15000], training loss: 0.0471
[7992/15000], training loss: 0.0685
[8000/15000], training loss: 0.0510
16
AVD_Home_010_1_traj1, ate: 530.2606103388121
model saved to ../results/AVD/AVD_Home_010_1_traj1/model_best.pth
[8008/15000], training loss: 0.0620
[8016/15000], training loss: 0.0564
[8024/15000], training loss: 0.0473
./lstm_run_train_AVD.sh: line 25: 21446 Terminated              python lstm_train_AVD.py -o $MODE -g $GPUID -y $LAT --name $NAME -d $DATA_DIR -t ${TRAJ}.txt -e $EPOCH -b $BS -l $LOSS -n $N --log_interval $LOG
./lstm_run_train_AVD.sh: line 26: /home/mmvc: Is a directory
