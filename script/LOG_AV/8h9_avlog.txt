maxpool
latent size single: 16
loading dataset
16
pccppcpc1123 (16, 27, 48, 3)
creating model
start training
[8/15000], training loss: 0.1522
[16/15000], training loss: 0.1304
[24/15000], training loss: 0.1233
[32/15000], training loss: 0.1198
[40/15000], training loss: 0.1101
16
AVD_Home_008_1_traj9, ate: 463.0545599242542
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[48/15000], training loss: 0.1135
[56/15000], training loss: 0.1198
[64/15000], training loss: 0.1065
[72/15000], training loss: 0.1144
[80/15000], training loss: 0.1200
16
AVD_Home_008_1_traj9, ate: 687.1206480829989
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[88/15000], training loss: 0.1128
[96/15000], training loss: 0.1130
[104/15000], training loss: 0.1019
[112/15000], training loss: 0.1103
[120/15000], training loss: 0.1076
16
AVD_Home_008_1_traj9, ate: 893.364529744102
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[128/15000], training loss: 0.1070
[136/15000], training loss: 0.1004
[144/15000], training loss: 0.1080
[152/15000], training loss: 0.1151
[160/15000], training loss: 0.0966
16
AVD_Home_008_1_traj9, ate: 1409.9850337515686
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[168/15000], training loss: 0.1089
[176/15000], training loss: 0.0986
[184/15000], training loss: 0.1039
[192/15000], training loss: 0.1085
[200/15000], training loss: 0.1025
16
AVD_Home_008_1_traj9, ate: 1363.6600684647674
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[208/15000], training loss: 0.1058
[216/15000], training loss: 0.0957
[224/15000], training loss: 0.1040
[232/15000], training loss: 0.1012
[240/15000], training loss: 0.0981
16
AVD_Home_008_1_traj9, ate: 1517.6077892436472
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[248/15000], training loss: 0.0961
[256/15000], training loss: 0.1019
[264/15000], training loss: 0.1029
[272/15000], training loss: 0.1046
[280/15000], training loss: 0.0938
16
AVD_Home_008_1_traj9, ate: 1525.2196093915643
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[288/15000], training loss: 0.1040
[296/15000], training loss: 0.0965
[304/15000], training loss: 0.0967
[312/15000], training loss: 0.1127
[320/15000], training loss: 0.0955
16
AVD_Home_008_1_traj9, ate: 1290.3954291786292
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[328/15000], training loss: 0.1045
[336/15000], training loss: 0.0990
[344/15000], training loss: 0.0889
[352/15000], training loss: 0.0912
[360/15000], training loss: 0.1024
16
AVD_Home_008_1_traj9, ate: 1423.2826683488283
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[368/15000], training loss: 0.1156
[376/15000], training loss: 0.0995
[384/15000], training loss: 0.0987
[392/15000], training loss: 0.1084
[400/15000], training loss: 0.1005
16
AVD_Home_008_1_traj9, ate: 1454.3241344961266
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[408/15000], training loss: 0.0925
[416/15000], training loss: 0.1053
[424/15000], training loss: 0.1123
[432/15000], training loss: 0.1010
[440/15000], training loss: 0.0908
16
AVD_Home_008_1_traj9, ate: 1459.1999065435323
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[448/15000], training loss: 0.0988
[456/15000], training loss: 0.0982
[464/15000], training loss: 0.0845
[472/15000], training loss: 0.0966
[480/15000], training loss: 0.0987
16
AVD_Home_008_1_traj9, ate: 1586.6786888588863
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[488/15000], training loss: 0.0967
[496/15000], training loss: 0.0973
[504/15000], training loss: 0.0896
[512/15000], training loss: 0.0941
[520/15000], training loss: 0.1069
16
AVD_Home_008_1_traj9, ate: 1409.1036452218962
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[528/15000], training loss: 0.1101
[536/15000], training loss: 0.0870
[544/15000], training loss: 0.0967
[552/15000], training loss: 0.1034
[560/15000], training loss: 0.0990
16
AVD_Home_008_1_traj9, ate: 1548.165592564065
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[568/15000], training loss: 0.1009
[576/15000], training loss: 0.1005
[584/15000], training loss: 0.0946
[592/15000], training loss: 0.1013
[600/15000], training loss: 0.0987
16
AVD_Home_008_1_traj9, ate: 1478.1686492215779
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[608/15000], training loss: 0.0958
[616/15000], training loss: 0.0855
[624/15000], training loss: 0.1005
[632/15000], training loss: 0.0863
[640/15000], training loss: 0.0929
16
AVD_Home_008_1_traj9, ate: 1579.2789857649059
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[648/15000], training loss: 0.0865
[656/15000], training loss: 0.0901
[664/15000], training loss: 0.0956
[672/15000], training loss: 0.1030
[680/15000], training loss: 0.1005
16
AVD_Home_008_1_traj9, ate: 1602.1087146393493
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[688/15000], training loss: 0.1034
[696/15000], training loss: 0.0936
[704/15000], training loss: 0.0945
[712/15000], training loss: 0.0978
[720/15000], training loss: 0.0838
16
AVD_Home_008_1_traj9, ate: 1543.319558315958
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[728/15000], training loss: 0.0968
[736/15000], training loss: 0.0965
[744/15000], training loss: 0.0963
[752/15000], training loss: 0.0982
[760/15000], training loss: 0.0880
16
AVD_Home_008_1_traj9, ate: 1533.713032255158
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[768/15000], training loss: 0.0959
[776/15000], training loss: 0.0994
[784/15000], training loss: 0.0947
[792/15000], training loss: 0.0957
[800/15000], training loss: 0.0922
16
AVD_Home_008_1_traj9, ate: 1616.6152625513262
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[808/15000], training loss: 0.0846
[816/15000], training loss: 0.0916
[824/15000], training loss: 0.0889
[832/15000], training loss: 0.0834
[840/15000], training loss: 0.0820
16
AVD_Home_008_1_traj9, ate: 1512.3224645724263
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[848/15000], training loss: 0.0969
[856/15000], training loss: 0.0953
[864/15000], training loss: 0.1066
[872/15000], training loss: 0.0977
[880/15000], training loss: 0.0980
16
AVD_Home_008_1_traj9, ate: 1497.8055616027755
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[888/15000], training loss: 0.0998
[896/15000], training loss: 0.0926
[904/15000], training loss: 0.0843
[912/15000], training loss: 0.0898
[920/15000], training loss: 0.0943
16
AVD_Home_008_1_traj9, ate: 1583.2611515194899
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[928/15000], training loss: 0.0808
[936/15000], training loss: 0.0916
[944/15000], training loss: 0.0927
[952/15000], training loss: 0.0853
[960/15000], training loss: 0.0847
16
AVD_Home_008_1_traj9, ate: 1463.2268665424187
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[968/15000], training loss: 0.1110
[976/15000], training loss: 0.0864
[984/15000], training loss: 0.0941
[992/15000], training loss: 0.0923
[1000/15000], training loss: 0.0896
16
AVD_Home_008_1_traj9, ate: 1529.3412018782485
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[1008/15000], training loss: 0.0944
[1016/15000], training loss: 0.0833
[1024/15000], training loss: 0.0822
[1032/15000], training loss: 0.0895
[1040/15000], training loss: 0.0868
16
AVD_Home_008_1_traj9, ate: 1473.8408653240958
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[1048/15000], training loss: 0.0910
[1056/15000], training loss: 0.0912
[1064/15000], training loss: 0.0934
[1072/15000], training loss: 0.0833
[1080/15000], training loss: 0.0941
16
AVD_Home_008_1_traj9, ate: 1508.069246811412
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[1088/15000], training loss: 0.1014
[1096/15000], training loss: 0.0879
[1104/15000], training loss: 0.0924
[1112/15000], training loss: 0.0840
[1120/15000], training loss: 0.0828
16
AVD_Home_008_1_traj9, ate: 1465.077284379244
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[1128/15000], training loss: 0.1174
[1136/15000], training loss: 0.0976
[1144/15000], training loss: 0.0840
[1152/15000], training loss: 0.0967
[1160/15000], training loss: 0.1009
16
AVD_Home_008_1_traj9, ate: 1501.7451100144424
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[1168/15000], training loss: 0.0856
[1176/15000], training loss: 0.0971
[1184/15000], training loss: 0.0920
[1192/15000], training loss: 0.0874
[1200/15000], training loss: 0.0837
16
AVD_Home_008_1_traj9, ate: 1409.70783849376
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[1208/15000], training loss: 0.0888
[1216/15000], training loss: 0.0834
[1224/15000], training loss: 0.0803
[1232/15000], training loss: 0.0812
[1240/15000], training loss: 0.0836
16
AVD_Home_008_1_traj9, ate: 1500.3509536602287
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[1248/15000], training loss: 0.1010
[1256/15000], training loss: 0.0820
[1264/15000], training loss: 0.0883
[1272/15000], training loss: 0.0825
[1280/15000], training loss: 0.0755
16
AVD_Home_008_1_traj9, ate: 1375.342810801773
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[1288/15000], training loss: 0.0761
[1296/15000], training loss: 0.0974
[1304/15000], training loss: 0.0929
[1312/15000], training loss: 0.0885
[1320/15000], training loss: 0.0925
16
AVD_Home_008_1_traj9, ate: 1389.321618050056
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[1328/15000], training loss: 0.0724
[1336/15000], training loss: 0.0885
[1344/15000], training loss: 0.0786
[1352/15000], training loss: 0.1102
[1360/15000], training loss: 0.0832
16
AVD_Home_008_1_traj9, ate: 1321.9065095450962
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[1368/15000], training loss: 0.0884
[1376/15000], training loss: 0.0861
[1384/15000], training loss: 0.0792
[1392/15000], training loss: 0.0827
[1400/15000], training loss: 0.0983
16
AVD_Home_008_1_traj9, ate: 1370.926156633414
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[1408/15000], training loss: 0.0779
[1416/15000], training loss: 0.0732
[1424/15000], training loss: 0.0997
[1432/15000], training loss: 0.0931
[1440/15000], training loss: 0.0932
16
AVD_Home_008_1_traj9, ate: 1392.3800789619409
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[1448/15000], training loss: 0.0924
[1456/15000], training loss: 0.0894
[1464/15000], training loss: 0.0848
[1472/15000], training loss: 0.0776
[1480/15000], training loss: 0.0735
16
AVD_Home_008_1_traj9, ate: 1362.485383159759
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[1488/15000], training loss: 0.0821
[1496/15000], training loss: 0.0698
[1504/15000], training loss: 0.0819
[1512/15000], training loss: 0.0721
[1520/15000], training loss: 0.0764
16
AVD_Home_008_1_traj9, ate: 1341.145251488154
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[1528/15000], training loss: 0.0818
[1536/15000], training loss: 0.0828
[1544/15000], training loss: 0.0898
[1552/15000], training loss: 0.0786
[1560/15000], training loss: 0.0745
16
AVD_Home_008_1_traj9, ate: 1319.2765124898742
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[1568/15000], training loss: 0.0866
[1576/15000], training loss: 0.1012
[1584/15000], training loss: 0.0779
[1592/15000], training loss: 0.0930
[1600/15000], training loss: 0.0890
16
AVD_Home_008_1_traj9, ate: 1345.1145917040176
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[1608/15000], training loss: 0.0808
[1616/15000], training loss: 0.0721
[1624/15000], training loss: 0.0699
[1632/15000], training loss: 0.0901
[1640/15000], training loss: 0.0779
16
AVD_Home_008_1_traj9, ate: 1355.4852224024041
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[1648/15000], training loss: 0.0833
[1656/15000], training loss: 0.1105
[1664/15000], training loss: 0.0937
[1672/15000], training loss: 0.0812
[1680/15000], training loss: 0.0701
16
AVD_Home_008_1_traj9, ate: 1362.4141778773387
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[1688/15000], training loss: 0.0769
[1696/15000], training loss: 0.0658
[1704/15000], training loss: 0.0781
[1712/15000], training loss: 0.0789
[1720/15000], training loss: 0.1419
16
AVD_Home_008_1_traj9, ate: 1336.2143798624506
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[1728/15000], training loss: 0.0946
[1736/15000], training loss: 0.0754
[1744/15000], training loss: 0.0795
[1752/15000], training loss: 0.0894
[1760/15000], training loss: 0.0742
16
AVD_Home_008_1_traj9, ate: 1229.1948015040093
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[1768/15000], training loss: 0.0914
[1776/15000], training loss: 0.0760
[1784/15000], training loss: 0.0706
[1792/15000], training loss: 0.0796
[1800/15000], training loss: 0.0877
16
AVD_Home_008_1_traj9, ate: 1296.7673922914526
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[1808/15000], training loss: 0.0891
[1816/15000], training loss: 0.0881
[1824/15000], training loss: 0.0902
[1832/15000], training loss: 0.0854
[1840/15000], training loss: 0.0979
16
AVD_Home_008_1_traj9, ate: 1321.4727842104414
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[1848/15000], training loss: 0.0892
[1856/15000], training loss: 0.0852
[1864/15000], training loss: 0.0712
[1872/15000], training loss: 0.0886
[1880/15000], training loss: 0.0791
16
AVD_Home_008_1_traj9, ate: 1314.2845425146293
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[1888/15000], training loss: 0.0911
[1896/15000], training loss: 0.0733
[1904/15000], training loss: 0.0654
[1912/15000], training loss: 0.0675
[1920/15000], training loss: 0.0846
16
AVD_Home_008_1_traj9, ate: 1329.308526453781
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[1928/15000], training loss: 0.0833
[1936/15000], training loss: 0.0883
[1944/15000], training loss: 0.0987
[1952/15000], training loss: 0.0713
[1960/15000], training loss: 0.0753
16
AVD_Home_008_1_traj9, ate: 1242.3735597426657
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[1968/15000], training loss: 0.1022
[1976/15000], training loss: 0.0878
[1984/15000], training loss: 0.0845
[1992/15000], training loss: 0.0932
[2000/15000], training loss: 0.0733
16
AVD_Home_008_1_traj9, ate: 1306.46382301826
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[2008/15000], training loss: 0.0724
[2016/15000], training loss: 0.0963
[2024/15000], training loss: 0.0691
[2032/15000], training loss: 0.0763
[2040/15000], training loss: 0.0923
16
AVD_Home_008_1_traj9, ate: 1302.6800488284434
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[2048/15000], training loss: 0.0801
[2056/15000], training loss: 0.0646
[2064/15000], training loss: 0.0864
[2072/15000], training loss: 0.0903
[2080/15000], training loss: 0.1101
16
AVD_Home_008_1_traj9, ate: 1162.1882395103291
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[2088/15000], training loss: 0.1065
[2096/15000], training loss: 0.0930
[2104/15000], training loss: 0.0803
[2112/15000], training loss: 0.0709
[2120/15000], training loss: 0.0891
16
AVD_Home_008_1_traj9, ate: 1254.5927643437165
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[2128/15000], training loss: 0.0858
[2136/15000], training loss: 0.0857
[2144/15000], training loss: 0.0773
[2152/15000], training loss: 0.0849
[2160/15000], training loss: 0.0807
16
AVD_Home_008_1_traj9, ate: 1229.5146006396967
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[2168/15000], training loss: 0.0606
[2176/15000], training loss: 0.0729
[2184/15000], training loss: 0.0715
[2192/15000], training loss: 0.0662
[2200/15000], training loss: 0.0714
16
AVD_Home_008_1_traj9, ate: 1300.4896385273144
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[2208/15000], training loss: 0.0543
[2216/15000], training loss: 0.0776
[2224/15000], training loss: 0.0622
[2232/15000], training loss: 0.0726
[2240/15000], training loss: 0.0758
16
AVD_Home_008_1_traj9, ate: 1282.187636205522
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[2248/15000], training loss: 0.0706
[2256/15000], training loss: 0.0882
[2264/15000], training loss: 0.0849
[2272/15000], training loss: 0.0655
[2280/15000], training loss: 0.0669
16
AVD_Home_008_1_traj9, ate: 1276.9729396319094
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[2288/15000], training loss: 0.0659
[2296/15000], training loss: 0.0972
[2304/15000], training loss: 0.0860
[2312/15000], training loss: 0.0663
[2320/15000], training loss: 0.0766
16
AVD_Home_008_1_traj9, ate: 1288.6878702002543
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[2328/15000], training loss: 0.0807
[2336/15000], training loss: 0.0749
[2344/15000], training loss: 0.0724
[2352/15000], training loss: 0.0736
[2360/15000], training loss: 0.0913
16
AVD_Home_008_1_traj9, ate: 1222.2430071521137
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[2368/15000], training loss: 0.0549
[2376/15000], training loss: 0.0866
[2384/15000], training loss: 0.0756
[2392/15000], training loss: 0.0704
[2400/15000], training loss: 0.0619
16
AVD_Home_008_1_traj9, ate: 1238.424581160767
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[2408/15000], training loss: 0.0734
[2416/15000], training loss: 0.0600
[2424/15000], training loss: 0.0695
[2432/15000], training loss: 0.0734
[2440/15000], training loss: 0.0745
16
AVD_Home_008_1_traj9, ate: 1302.9605344344425
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[2448/15000], training loss: 0.0809
[2456/15000], training loss: 0.0744
[2464/15000], training loss: 0.0824
[2472/15000], training loss: 0.0675
[2480/15000], training loss: 0.0772
16
AVD_Home_008_1_traj9, ate: 1219.6288359452751
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[2488/15000], training loss: 0.0697
[2496/15000], training loss: 0.0724
[2504/15000], training loss: 0.0786
[2512/15000], training loss: 0.0755
[2520/15000], training loss: 0.0702
16
AVD_Home_008_1_traj9, ate: 1279.554216170204
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[2528/15000], training loss: 0.0756
[2536/15000], training loss: 0.0789
[2544/15000], training loss: 0.0596
[2552/15000], training loss: 0.0771
[2560/15000], training loss: 0.0704
16
AVD_Home_008_1_traj9, ate: 1273.0122539628267
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[2568/15000], training loss: 0.0862
[2576/15000], training loss: 0.0605
[2584/15000], training loss: 0.0813
[2592/15000], training loss: 0.0771
[2600/15000], training loss: 0.0731
16
AVD_Home_008_1_traj9, ate: 1275.9028355505602
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[2608/15000], training loss: 0.0820
[2616/15000], training loss: 0.0741
[2624/15000], training loss: 0.0653
[2632/15000], training loss: 0.0766
[2640/15000], training loss: 0.0819
16
AVD_Home_008_1_traj9, ate: 1275.3349639256612
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[2648/15000], training loss: 0.0706
[2656/15000], training loss: 0.0799
[2664/15000], training loss: 0.0758
[2672/15000], training loss: 0.0727
[2680/15000], training loss: 0.0979
16
AVD_Home_008_1_traj9, ate: 1247.3378496032517
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[2688/15000], training loss: 0.1006
[2696/15000], training loss: 0.0778
[2704/15000], training loss: 0.0612
[2712/15000], training loss: 0.0858
[2720/15000], training loss: 0.1191
16
AVD_Home_008_1_traj9, ate: 1247.3099854402212
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[2728/15000], training loss: 0.0657
[2736/15000], training loss: 0.0717
[2744/15000], training loss: 0.0607
[2752/15000], training loss: 0.1022
[2760/15000], training loss: 0.0873
16
AVD_Home_008_1_traj9, ate: 1232.7760162043141
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[2768/15000], training loss: 0.0673
[2776/15000], training loss: 0.0735
[2784/15000], training loss: 0.0834
[2792/15000], training loss: 0.0794
[2800/15000], training loss: 0.0592
16
AVD_Home_008_1_traj9, ate: 1264.8497680178457
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[2808/15000], training loss: 0.0713
[2816/15000], training loss: 0.0546
[2824/15000], training loss: 0.0658
[2832/15000], training loss: 0.0790
[2840/15000], training loss: 0.0869
16
AVD_Home_008_1_traj9, ate: 1322.7894815434618
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[2848/15000], training loss: 0.0598
[2856/15000], training loss: 0.0608
[2864/15000], training loss: 0.0799
[2872/15000], training loss: 0.0674
[2880/15000], training loss: 0.0696
16
AVD_Home_008_1_traj9, ate: 1268.2044701965503
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[2888/15000], training loss: 0.0660
[2896/15000], training loss: 0.1015
[2904/15000], training loss: 0.0721
[2912/15000], training loss: 0.0575
[2920/15000], training loss: 0.1046
16
AVD_Home_008_1_traj9, ate: 1245.0385086919266
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[2928/15000], training loss: 0.1073
[2936/15000], training loss: 0.0712
[2944/15000], training loss: 0.0770
[2952/15000], training loss: 0.0674
[2960/15000], training loss: 0.0723
16
AVD_Home_008_1_traj9, ate: 1241.4629650932068
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[2968/15000], training loss: 0.0766
[2976/15000], training loss: 0.0861
[2984/15000], training loss: 0.0641
[2992/15000], training loss: 0.0685
[3000/15000], training loss: 0.0678
16
AVD_Home_008_1_traj9, ate: 1270.1380472436451
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[3008/15000], training loss: 0.0612
[3016/15000], training loss: 0.0714
[3024/15000], training loss: 0.0602
[3032/15000], training loss: 0.0568
[3040/15000], training loss: 0.0714
16
AVD_Home_008_1_traj9, ate: 1284.4703032046064
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[3048/15000], training loss: 0.0585
[3056/15000], training loss: 0.0625
[3064/15000], training loss: 0.0744
[3072/15000], training loss: 0.0802
[3080/15000], training loss: 0.0804
16
AVD_Home_008_1_traj9, ate: 1298.1262861390856
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[3088/15000], training loss: 0.0877
[3096/15000], training loss: 0.0693
[3104/15000], training loss: 0.0802
[3112/15000], training loss: 0.0697
[3120/15000], training loss: 0.0682
16
AVD_Home_008_1_traj9, ate: 1273.2740605869776
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[3128/15000], training loss: 0.0609
[3136/15000], training loss: 0.0516
[3144/15000], training loss: 0.0676
[3152/15000], training loss: 0.0865
[3160/15000], training loss: 0.0684
16
AVD_Home_008_1_traj9, ate: 1277.6799839625235
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[3168/15000], training loss: 0.0651
[3176/15000], training loss: 0.0523
[3184/15000], training loss: 0.0986
[3192/15000], training loss: 0.0688
[3200/15000], training loss: 0.0692
16
AVD_Home_008_1_traj9, ate: 1297.3220089644285
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[3208/15000], training loss: 0.0555
[3216/15000], training loss: 0.0924
[3224/15000], training loss: 0.0778
[3232/15000], training loss: 0.0778
[3240/15000], training loss: 0.0673
16
AVD_Home_008_1_traj9, ate: 1281.8680996183127
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[3248/15000], training loss: 0.0633
[3256/15000], training loss: 0.0559
[3264/15000], training loss: 0.0751
[3272/15000], training loss: 0.0818
[3280/15000], training loss: 0.0513
16
AVD_Home_008_1_traj9, ate: 1270.5903527257603
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[3288/15000], training loss: 0.0599
[3296/15000], training loss: 0.0750
[3304/15000], training loss: 0.0564
[3312/15000], training loss: 0.0671
[3320/15000], training loss: 0.0598
16
AVD_Home_008_1_traj9, ate: 1266.232228683957
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[3328/15000], training loss: 0.0723
[3336/15000], training loss: 0.0636
[3344/15000], training loss: 0.0801
[3352/15000], training loss: 0.0713
[3360/15000], training loss: 0.0795
16
AVD_Home_008_1_traj9, ate: 1287.4399679244134
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[3368/15000], training loss: 0.0787
[3376/15000], training loss: 0.0595
[3384/15000], training loss: 0.0642
[3392/15000], training loss: 0.0761
[3400/15000], training loss: 0.0588
16
AVD_Home_008_1_traj9, ate: 1281.1959198053082
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[3408/15000], training loss: 0.0608
[3416/15000], training loss: 0.0670
[3424/15000], training loss: 0.0645
[3432/15000], training loss: 0.0794
[3440/15000], training loss: 0.0848
16
AVD_Home_008_1_traj9, ate: 1284.2699862014213
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[3448/15000], training loss: 0.0873
[3456/15000], training loss: 0.1144
[3464/15000], training loss: 0.0720
[3472/15000], training loss: 0.0781
[3480/15000], training loss: 0.0615
16
AVD_Home_008_1_traj9, ate: 1272.1810443722784
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[3488/15000], training loss: 0.0695
[3496/15000], training loss: 0.0846
[3504/15000], training loss: 0.0725
[3512/15000], training loss: 0.0544
[3520/15000], training loss: 0.0549
16
AVD_Home_008_1_traj9, ate: 1281.7658250392294
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[3528/15000], training loss: 0.0729
[3536/15000], training loss: 0.0587
[3544/15000], training loss: 0.0748
[3552/15000], training loss: 0.0634
[3560/15000], training loss: 0.0771
16
AVD_Home_008_1_traj9, ate: 1286.9729503531394
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[3568/15000], training loss: 0.0602
[3576/15000], training loss: 0.0712
[3584/15000], training loss: 0.0655
[3592/15000], training loss: 0.0711
[3600/15000], training loss: 0.0745
16
AVD_Home_008_1_traj9, ate: 1291.7091399208575
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[3608/15000], training loss: 0.0703
[3616/15000], training loss: 0.0618
[3624/15000], training loss: 0.0726
[3632/15000], training loss: 0.0702
[3640/15000], training loss: 0.0745
16
AVD_Home_008_1_traj9, ate: 1293.6835375521387
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[3648/15000], training loss: 0.0653
[3656/15000], training loss: 0.0797
[3664/15000], training loss: 0.0673
[3672/15000], training loss: 0.0587
[3680/15000], training loss: 0.0733
16
AVD_Home_008_1_traj9, ate: 1304.2132321866734
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[3688/15000], training loss: 0.0569
[3696/15000], training loss: 0.0780
[3704/15000], training loss: 0.0720
[3712/15000], training loss: 0.0818
[3720/15000], training loss: 0.0667
16
AVD_Home_008_1_traj9, ate: 1272.1994246991494
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[3728/15000], training loss: 0.0649
[3736/15000], training loss: 0.0614
[3744/15000], training loss: 0.0655
[3752/15000], training loss: 0.0559
[3760/15000], training loss: 0.0657
16
AVD_Home_008_1_traj9, ate: 1275.6332211712775
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[3768/15000], training loss: 0.0619
[3776/15000], training loss: 0.0589
[3784/15000], training loss: 0.0628
[3792/15000], training loss: 0.0630
[3800/15000], training loss: 0.0677
16
AVD_Home_008_1_traj9, ate: 1319.7530753300507
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[3808/15000], training loss: 0.0639
[3816/15000], training loss: 0.0690
[3824/15000], training loss: 0.0641
[3832/15000], training loss: 0.0557
[3840/15000], training loss: 0.0906
16
AVD_Home_008_1_traj9, ate: 1294.079181890145
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[3848/15000], training loss: 0.0716
[3856/15000], training loss: 0.0709
[3864/15000], training loss: 0.0623
[3872/15000], training loss: 0.0858
[3880/15000], training loss: 0.0810
16
AVD_Home_008_1_traj9, ate: 1314.1993422811738
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[3888/15000], training loss: 0.0520
[3896/15000], training loss: 0.0615
[3904/15000], training loss: 0.0773
[3912/15000], training loss: 0.0642
[3920/15000], training loss: 0.0774
16
AVD_Home_008_1_traj9, ate: 1309.116925960866
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[3928/15000], training loss: 0.0759
[3936/15000], training loss: 0.0778
[3944/15000], training loss: 0.0928
[3952/15000], training loss: 0.0593
[3960/15000], training loss: 0.0536
16
AVD_Home_008_1_traj9, ate: 1290.4103465046703
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[3968/15000], training loss: 0.0785
[3976/15000], training loss: 0.0830
[3984/15000], training loss: 0.0725
[3992/15000], training loss: 0.0598
[4000/15000], training loss: 0.0692
16
AVD_Home_008_1_traj9, ate: 1281.8105997089067
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[4008/15000], training loss: 0.0583
[4016/15000], training loss: 0.0653
[4024/15000], training loss: 0.0682
[4032/15000], training loss: 0.0689
[4040/15000], training loss: 0.0690
16
AVD_Home_008_1_traj9, ate: 1283.510749210083
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[4048/15000], training loss: 0.0550
[4056/15000], training loss: 0.0728
[4064/15000], training loss: 0.0684
[4072/15000], training loss: 0.0733
[4080/15000], training loss: 0.0556
16
AVD_Home_008_1_traj9, ate: 1315.3799244135043
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[4088/15000], training loss: 0.0662
[4096/15000], training loss: 0.0557
[4104/15000], training loss: 0.0772
[4112/15000], training loss: 0.0764
[4120/15000], training loss: 0.0903
16
AVD_Home_008_1_traj9, ate: 1320.9425426120567
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[4128/15000], training loss: 0.0562
[4136/15000], training loss: 0.0652
[4144/15000], training loss: 0.0692
[4152/15000], training loss: 0.0865
[4160/15000], training loss: 0.0601
16
AVD_Home_008_1_traj9, ate: 1298.675382338885
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[4168/15000], training loss: 0.0552
[4176/15000], training loss: 0.0716
[4184/15000], training loss: 0.0659
[4192/15000], training loss: 0.0526
[4200/15000], training loss: 0.0664
16
AVD_Home_008_1_traj9, ate: 1292.6381451777927
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[4208/15000], training loss: 0.0718
[4216/15000], training loss: 0.0651
[4224/15000], training loss: 0.0694
[4232/15000], training loss: 0.0742
[4240/15000], training loss: 0.0588
16
AVD_Home_008_1_traj9, ate: 1315.3287098870085
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[4248/15000], training loss: 0.1045
[4256/15000], training loss: 0.0737
[4264/15000], training loss: 0.0861
[4272/15000], training loss: 0.0912
[4280/15000], training loss: 0.1138
16
AVD_Home_008_1_traj9, ate: 1289.9938706360847
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[4288/15000], training loss: 0.0637
[4296/15000], training loss: 0.0738
[4304/15000], training loss: 0.0713
[4312/15000], training loss: 0.0785
[4320/15000], training loss: 0.0781
16
AVD_Home_008_1_traj9, ate: 1295.7486055156585
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[4328/15000], training loss: 0.0595
[4336/15000], training loss: 0.0623
[4344/15000], training loss: 0.0598
[4352/15000], training loss: 0.0650
[4360/15000], training loss: 0.0644
16
AVD_Home_008_1_traj9, ate: 1252.3110563289022
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[4368/15000], training loss: 0.0757
[4376/15000], training loss: 0.0685
[4384/15000], training loss: 0.0650
[4392/15000], training loss: 0.0643
[4400/15000], training loss: 0.0639
16
AVD_Home_008_1_traj9, ate: 1291.6783377650406
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[4408/15000], training loss: 0.0680
[4416/15000], training loss: 0.0638
[4424/15000], training loss: 0.0629
[4432/15000], training loss: 0.0661
[4440/15000], training loss: 0.0776
16
AVD_Home_008_1_traj9, ate: 1282.7121653120694
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[4448/15000], training loss: 0.0642
[4456/15000], training loss: 0.0645
[4464/15000], training loss: 0.0944
[4472/15000], training loss: 0.0695
[4480/15000], training loss: 0.0766
16
AVD_Home_008_1_traj9, ate: 1279.4348857537802
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[4488/15000], training loss: 0.0791
[4496/15000], training loss: 0.1129
[4504/15000], training loss: 0.0787
[4512/15000], training loss: 0.0677
[4520/15000], training loss: 0.0604
16
AVD_Home_008_1_traj9, ate: 1305.3686726104795
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[4528/15000], training loss: 0.0553
[4536/15000], training loss: 0.0547
[4544/15000], training loss: 0.0645
[4552/15000], training loss: 0.0509
[4560/15000], training loss: 0.0737
16
AVD_Home_008_1_traj9, ate: 1291.450888978304
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[4568/15000], training loss: 0.0608
[4576/15000], training loss: 0.0687
[4584/15000], training loss: 0.0856
[4592/15000], training loss: 0.0631
[4600/15000], training loss: 0.0664
16
AVD_Home_008_1_traj9, ate: 1282.5192124972702
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[4608/15000], training loss: 0.0759
[4616/15000], training loss: 0.0566
[4624/15000], training loss: 0.0616
[4632/15000], training loss: 0.0749
[4640/15000], training loss: 0.0712
16
AVD_Home_008_1_traj9, ate: 1257.924277600987
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[4648/15000], training loss: 0.0803
[4656/15000], training loss: 0.0672
[4664/15000], training loss: 0.0862
[4672/15000], training loss: 0.0618
[4680/15000], training loss: 0.0687
16
AVD_Home_008_1_traj9, ate: 1305.3071836341296
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[4688/15000], training loss: 0.0820
[4696/15000], training loss: 0.0794
[4704/15000], training loss: 0.0670
[4712/15000], training loss: 0.0493
[4720/15000], training loss: 0.0446
16
AVD_Home_008_1_traj9, ate: 1273.356823750346
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[4728/15000], training loss: 0.0778
[4736/15000], training loss: 0.0863
[4744/15000], training loss: 0.0606
[4752/15000], training loss: 0.0637
[4760/15000], training loss: 0.0834
16
AVD_Home_008_1_traj9, ate: 1277.413278978293
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[4768/15000], training loss: 0.0588
[4776/15000], training loss: 0.0517
[4784/15000], training loss: 0.0856
[4792/15000], training loss: 0.0736
[4800/15000], training loss: 0.0660
16
AVD_Home_008_1_traj9, ate: 1275.3324003370678
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[4808/15000], training loss: 0.0638
[4816/15000], training loss: 0.0693
[4824/15000], training loss: 0.0917
[4832/15000], training loss: 0.0593
[4840/15000], training loss: 0.0675
16
AVD_Home_008_1_traj9, ate: 1309.4369252590761
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[4848/15000], training loss: 0.0846
[4856/15000], training loss: 0.0724
[4864/15000], training loss: 0.0479
[4872/15000], training loss: 0.0677
[4880/15000], training loss: 0.0722
16
AVD_Home_008_1_traj9, ate: 1274.5975781071822
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[4888/15000], training loss: 0.0665
[4896/15000], training loss: 0.0507
[4904/15000], training loss: 0.0572
[4912/15000], training loss: 0.0636
[4920/15000], training loss: 0.0637
16
AVD_Home_008_1_traj9, ate: 1287.9930460132264
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[4928/15000], training loss: 0.1002
[4936/15000], training loss: 0.0653
[4944/15000], training loss: 0.0956
[4952/15000], training loss: 0.0525
[4960/15000], training loss: 0.0585
16
AVD_Home_008_1_traj9, ate: 1284.0511833236721
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[4968/15000], training loss: 0.0705
[4976/15000], training loss: 0.0885
[4984/15000], training loss: 0.0622
[4992/15000], training loss: 0.0476
[5000/15000], training loss: 0.0793
16
AVD_Home_008_1_traj9, ate: 1289.6983803369064
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[5008/15000], training loss: 0.0665
[5016/15000], training loss: 0.0683
[5024/15000], training loss: 0.0721
[5032/15000], training loss: 0.0504
[5040/15000], training loss: 0.0651
16
AVD_Home_008_1_traj9, ate: 1282.1605155202683
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[5048/15000], training loss: 0.0740
[5056/15000], training loss: 0.0848
[5064/15000], training loss: 0.0591
[5072/15000], training loss: 0.0545
[5080/15000], training loss: 0.0601
16
AVD_Home_008_1_traj9, ate: 1294.546077379365
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[5088/15000], training loss: 0.0602
[5096/15000], training loss: 0.0613
[5104/15000], training loss: 0.0587
[5112/15000], training loss: 0.0807
[5120/15000], training loss: 0.0760
16
AVD_Home_008_1_traj9, ate: 1300.5532272223375
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[5128/15000], training loss: 0.0723
[5136/15000], training loss: 0.0864
[5144/15000], training loss: 0.0610
[5152/15000], training loss: 0.0614
[5160/15000], training loss: 0.0687
16
AVD_Home_008_1_traj9, ate: 1278.4841115862262
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[5168/15000], training loss: 0.0630
[5176/15000], training loss: 0.0682
[5184/15000], training loss: 0.0769
[5192/15000], training loss: 0.0877
[5200/15000], training loss: 0.0797
16
AVD_Home_008_1_traj9, ate: 1273.9099809846634
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[5208/15000], training loss: 0.0937
[5216/15000], training loss: 0.0574
[5224/15000], training loss: 0.0825
[5232/15000], training loss: 0.0460
[5240/15000], training loss: 0.0723
16
AVD_Home_008_1_traj9, ate: 1279.5849170049382
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[5248/15000], training loss: 0.0583
[5256/15000], training loss: 0.0678
[5264/15000], training loss: 0.0635
[5272/15000], training loss: 0.0714
[5280/15000], training loss: 0.0759
16
AVD_Home_008_1_traj9, ate: 1298.1874701161871
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[5288/15000], training loss: 0.0661
[5296/15000], training loss: 0.0689
[5304/15000], training loss: 0.1133
[5312/15000], training loss: 0.0488
[5320/15000], training loss: 0.0774
16
AVD_Home_008_1_traj9, ate: 1300.9194517101591
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[5328/15000], training loss: 0.1052
[5336/15000], training loss: 0.0833
[5344/15000], training loss: 0.0602
[5352/15000], training loss: 0.0865
[5360/15000], training loss: 0.0782
16
AVD_Home_008_1_traj9, ate: 1296.8990025582068
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[5368/15000], training loss: 0.0912
[5376/15000], training loss: 0.0589
[5384/15000], training loss: 0.0790
[5392/15000], training loss: 0.0478
[5400/15000], training loss: 0.0696
16
AVD_Home_008_1_traj9, ate: 1314.945635625455
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[5408/15000], training loss: 0.0777
[5416/15000], training loss: 0.0635
[5424/15000], training loss: 0.0770
[5432/15000], training loss: 0.0462
[5440/15000], training loss: 0.0595
16
AVD_Home_008_1_traj9, ate: 1282.7185354684946
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[5448/15000], training loss: 0.0936
[5456/15000], training loss: 0.0858
[5464/15000], training loss: 0.0782
[5472/15000], training loss: 0.0727
[5480/15000], training loss: 0.0926
16
AVD_Home_008_1_traj9, ate: 1323.0284620516647
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[5488/15000], training loss: 0.0693
[5496/15000], training loss: 0.0608
[5504/15000], training loss: 0.0705
[5512/15000], training loss: 0.0593
[5520/15000], training loss: 0.0687
16
AVD_Home_008_1_traj9, ate: 1290.960363684996
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[5528/15000], training loss: 0.0769
[5536/15000], training loss: 0.0754
[5544/15000], training loss: 0.0501
[5552/15000], training loss: 0.0638
[5560/15000], training loss: 0.0729
16
AVD_Home_008_1_traj9, ate: 1305.6645526203536
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[5568/15000], training loss: 0.0562
[5576/15000], training loss: 0.0661
[5584/15000], training loss: 0.0714
[5592/15000], training loss: 0.0665
[5600/15000], training loss: 0.0566
16
AVD_Home_008_1_traj9, ate: 1298.1610772977583
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[5608/15000], training loss: 0.0571
[5616/15000], training loss: 0.0468
[5624/15000], training loss: 0.0792
[5632/15000], training loss: 0.0679
[5640/15000], training loss: 0.0595
16
AVD_Home_008_1_traj9, ate: 1302.3265134149663
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[5648/15000], training loss: 0.0503
[5656/15000], training loss: 0.0735
[5664/15000], training loss: 0.0810
[5672/15000], training loss: 0.0710
[5680/15000], training loss: 0.0505
16
AVD_Home_008_1_traj9, ate: 1306.2578710367625
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[5688/15000], training loss: 0.0644
[5696/15000], training loss: 0.0782
[5704/15000], training loss: 0.0613
[5712/15000], training loss: 0.0795
[5720/15000], training loss: 0.0672
16
AVD_Home_008_1_traj9, ate: 1277.5297757159306
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[5728/15000], training loss: 0.0660
[5736/15000], training loss: 0.0631
[5744/15000], training loss: 0.0686
[5752/15000], training loss: 0.0729
[5760/15000], training loss: 0.0510
16
AVD_Home_008_1_traj9, ate: 1296.730103281603
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[5768/15000], training loss: 0.0832
[5776/15000], training loss: 0.0691
[5784/15000], training loss: 0.0618
[5792/15000], training loss: 0.0569
[5800/15000], training loss: 0.0712
16
AVD_Home_008_1_traj9, ate: 1295.7845382124856
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[5808/15000], training loss: 0.0629
[5816/15000], training loss: 0.0833
[5824/15000], training loss: 0.0475
[5832/15000], training loss: 0.0581
[5840/15000], training loss: 0.0517
16
AVD_Home_008_1_traj9, ate: 1282.1582973723378
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[5848/15000], training loss: 0.0616
[5856/15000], training loss: 0.0570
[5864/15000], training loss: 0.1088
[5872/15000], training loss: 0.0776
[5880/15000], training loss: 0.0550
16
AVD_Home_008_1_traj9, ate: 1335.742957457257
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[5888/15000], training loss: 0.0545
[5896/15000], training loss: 0.0597
[5904/15000], training loss: 0.0551
[5912/15000], training loss: 0.0511
[5920/15000], training loss: 0.0621
16
AVD_Home_008_1_traj9, ate: 1311.7084677437895
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[5928/15000], training loss: 0.0751
[5936/15000], training loss: 0.0931
[5944/15000], training loss: 0.0623
[5952/15000], training loss: 0.0760
[5960/15000], training loss: 0.0914
16
AVD_Home_008_1_traj9, ate: 1296.3268784645993
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[5968/15000], training loss: 0.0675
[5976/15000], training loss: 0.0695
[5984/15000], training loss: 0.0604
[5992/15000], training loss: 0.0550
[6000/15000], training loss: 0.0576
16
AVD_Home_008_1_traj9, ate: 1283.9455493241642
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[6008/15000], training loss: 0.0536
[6016/15000], training loss: 0.0686
[6024/15000], training loss: 0.0690
[6032/15000], training loss: 0.0666
[6040/15000], training loss: 0.0612
16
AVD_Home_008_1_traj9, ate: 1309.1389490873046
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[6048/15000], training loss: 0.0955
[6056/15000], training loss: 0.0496
[6064/15000], training loss: 0.0669
[6072/15000], training loss: 0.0684
[6080/15000], training loss: 0.0680
16
AVD_Home_008_1_traj9, ate: 1303.2740228250968
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[6088/15000], training loss: 0.0551
[6096/15000], training loss: 0.0484
[6104/15000], training loss: 0.0674
[6112/15000], training loss: 0.0645
[6120/15000], training loss: 0.0802
16
AVD_Home_008_1_traj9, ate: 1309.5852952801074
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[6128/15000], training loss: 0.0995
[6136/15000], training loss: 0.0667
[6144/15000], training loss: 0.0721
[6152/15000], training loss: 0.0488
[6160/15000], training loss: 0.0739
16
AVD_Home_008_1_traj9, ate: 1287.5090418225743
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[6168/15000], training loss: 0.0515
[6176/15000], training loss: 0.0550
[6184/15000], training loss: 0.0572
[6192/15000], training loss: 0.0567
[6200/15000], training loss: 0.0562
16
AVD_Home_008_1_traj9, ate: 1309.0104379678621
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[6208/15000], training loss: 0.0723
[6216/15000], training loss: 0.0456
[6224/15000], training loss: 0.0501
[6232/15000], training loss: 0.0670
[6240/15000], training loss: 0.0551
16
AVD_Home_008_1_traj9, ate: 1304.4276718267472
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[6248/15000], training loss: 0.0675
[6256/15000], training loss: 0.0679
[6264/15000], training loss: 0.0454
[6272/15000], training loss: 0.0539
[6280/15000], training loss: 0.0825
16
AVD_Home_008_1_traj9, ate: 1297.9421693294826
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[6288/15000], training loss: 0.1047
[6296/15000], training loss: 0.0578
[6304/15000], training loss: 0.0460
[6312/15000], training loss: 0.0703
[6320/15000], training loss: 0.0619
16
AVD_Home_008_1_traj9, ate: 1291.1474034324867
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[6328/15000], training loss: 0.0484
[6336/15000], training loss: 0.0592
[6344/15000], training loss: 0.0661
[6352/15000], training loss: 0.0666
[6360/15000], training loss: 0.0466
16
AVD_Home_008_1_traj9, ate: 1311.366399850055
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[6368/15000], training loss: 0.0552
[6376/15000], training loss: 0.0561
[6384/15000], training loss: 0.0581
[6392/15000], training loss: 0.0683
[6400/15000], training loss: 0.0539
16
AVD_Home_008_1_traj9, ate: 1307.7868489675593
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[6408/15000], training loss: 0.0593
[6416/15000], training loss: 0.0728
[6424/15000], training loss: 0.0577
[6432/15000], training loss: 0.0633
[6440/15000], training loss: 0.0614
16
AVD_Home_008_1_traj9, ate: 1313.9513318441425
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[6448/15000], training loss: 0.0429
[6456/15000], training loss: 0.0559
[6464/15000], training loss: 0.0784
[6472/15000], training loss: 0.0709
[6480/15000], training loss: 0.0677
16
AVD_Home_008_1_traj9, ate: 1280.7435693949706
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[6488/15000], training loss: 0.0605
[6496/15000], training loss: 0.0486
[6504/15000], training loss: 0.0649
[6512/15000], training loss: 0.0779
[6520/15000], training loss: 0.0667
16
AVD_Home_008_1_traj9, ate: 1302.4781456427174
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[6528/15000], training loss: 0.0642
[6536/15000], training loss: 0.0532
[6544/15000], training loss: 0.1001
[6552/15000], training loss: 0.0431
[6560/15000], training loss: 0.0643
16
AVD_Home_008_1_traj9, ate: 1303.6201669096802
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[6568/15000], training loss: 0.0802
[6576/15000], training loss: 0.0738
[6584/15000], training loss: 0.0615
[6592/15000], training loss: 0.0744
[6600/15000], training loss: 0.0701
16
AVD_Home_008_1_traj9, ate: 1321.5750157359225
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[6608/15000], training loss: 0.0536
[6616/15000], training loss: 0.0644
[6624/15000], training loss: 0.0490
[6632/15000], training loss: 0.0650
[6640/15000], training loss: 0.0436
16
AVD_Home_008_1_traj9, ate: 1279.8195350134856
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[6648/15000], training loss: 0.0836
[6656/15000], training loss: 0.0597
[6664/15000], training loss: 0.0421
[6672/15000], training loss: 0.0628
[6680/15000], training loss: 0.0577
16
AVD_Home_008_1_traj9, ate: 1334.5333773582568
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[6688/15000], training loss: 0.0706
[6696/15000], training loss: 0.0478
[6704/15000], training loss: 0.0636
[6712/15000], training loss: 0.0666
[6720/15000], training loss: 0.0777
16
AVD_Home_008_1_traj9, ate: 1299.982804527746
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[6728/15000], training loss: 0.0782
[6736/15000], training loss: 0.0683
[6744/15000], training loss: 0.0647
[6752/15000], training loss: 0.0549
[6760/15000], training loss: 0.0532
16
AVD_Home_008_1_traj9, ate: 1294.0076825789006
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[6768/15000], training loss: 0.0678
[6776/15000], training loss: 0.0931
[6784/15000], training loss: 0.0637
[6792/15000], training loss: 0.0478
[6800/15000], training loss: 0.0708
16
AVD_Home_008_1_traj9, ate: 1305.5597502156315
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[6808/15000], training loss: 0.0660
[6816/15000], training loss: 0.0461
[6824/15000], training loss: 0.0533
[6832/15000], training loss: 0.0662
[6840/15000], training loss: 0.0517
16
AVD_Home_008_1_traj9, ate: 1305.330767446883
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[6848/15000], training loss: 0.0578
[6856/15000], training loss: 0.0616
[6864/15000], training loss: 0.0751
[6872/15000], training loss: 0.0581
[6880/15000], training loss: 0.0673
16
AVD_Home_008_1_traj9, ate: 1322.4868185886094
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[6888/15000], training loss: 0.0588
[6896/15000], training loss: 0.0579
[6904/15000], training loss: 0.0550
[6912/15000], training loss: 0.0568
[6920/15000], training loss: 0.0832
16
AVD_Home_008_1_traj9, ate: 1299.2101087845704
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[6928/15000], training loss: 0.0648
[6936/15000], training loss: 0.0543
[6944/15000], training loss: 0.0429
[6952/15000], training loss: 0.0629
[6960/15000], training loss: 0.0590
16
AVD_Home_008_1_traj9, ate: 1289.2995578250318
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[6968/15000], training loss: 0.0595
[6976/15000], training loss: 0.0604
[6984/15000], training loss: 0.0587
[6992/15000], training loss: 0.0636
[7000/15000], training loss: 0.0886
16
AVD_Home_008_1_traj9, ate: 1295.4145941636793
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[7008/15000], training loss: 0.0569
[7016/15000], training loss: 0.0478
[7024/15000], training loss: 0.0546
[7032/15000], training loss: 0.0458
[7040/15000], training loss: 0.0570
16
AVD_Home_008_1_traj9, ate: 1301.8442407002597
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[7048/15000], training loss: 0.0648
[7056/15000], training loss: 0.0570
[7064/15000], training loss: 0.0716
[7072/15000], training loss: 0.0541
[7080/15000], training loss: 0.0616
16
AVD_Home_008_1_traj9, ate: 1313.9536133379515
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[7088/15000], training loss: 0.0837
[7096/15000], training loss: 0.0694
[7104/15000], training loss: 0.0884
[7112/15000], training loss: 0.0662
[7120/15000], training loss: 0.0493
16
AVD_Home_008_1_traj9, ate: 1297.2857060364702
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[7128/15000], training loss: 0.0557
[7136/15000], training loss: 0.1105
[7144/15000], training loss: 0.0739
[7152/15000], training loss: 0.0487
[7160/15000], training loss: 0.0565
16
AVD_Home_008_1_traj9, ate: 1305.806451064005
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[7168/15000], training loss: 0.0585
[7176/15000], training loss: 0.0518
[7184/15000], training loss: 0.0544
[7192/15000], training loss: 0.0755
[7200/15000], training loss: 0.0428
16
AVD_Home_008_1_traj9, ate: 1293.9206285733358
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[7208/15000], training loss: 0.0562
[7216/15000], training loss: 0.0563
[7224/15000], training loss: 0.0748
[7232/15000], training loss: 0.0589
[7240/15000], training loss: 0.0563
16
AVD_Home_008_1_traj9, ate: 1289.2454573466232
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[7248/15000], training loss: 0.0513
[7256/15000], training loss: 0.0524
[7264/15000], training loss: 0.0470
[7272/15000], training loss: 0.0582
[7280/15000], training loss: 0.0744
16
AVD_Home_008_1_traj9, ate: 1307.7002491059568
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[7288/15000], training loss: 0.0747
[7296/15000], training loss: 0.0457
[7304/15000], training loss: 0.0750
[7312/15000], training loss: 0.0760
[7320/15000], training loss: 0.0960
16
AVD_Home_008_1_traj9, ate: 1289.7647578700607
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[7328/15000], training loss: 0.0692
[7336/15000], training loss: 0.0631
[7344/15000], training loss: 0.0551
[7352/15000], training loss: 0.0574
[7360/15000], training loss: 0.0581
16
AVD_Home_008_1_traj9, ate: 1317.709082760169
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[7368/15000], training loss: 0.0697
[7376/15000], training loss: 0.0657
[7384/15000], training loss: 0.0619
[7392/15000], training loss: 0.0552
[7400/15000], training loss: 0.0528
16
AVD_Home_008_1_traj9, ate: 1304.3135480667945
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[7408/15000], training loss: 0.0470
[7416/15000], training loss: 0.0449
[7424/15000], training loss: 0.0606
[7432/15000], training loss: 0.0701
[7440/15000], training loss: 0.0851
16
AVD_Home_008_1_traj9, ate: 1292.8257432249127
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[7448/15000], training loss: 0.0836
[7456/15000], training loss: 0.0564
[7464/15000], training loss: 0.0673
[7472/15000], training loss: 0.0670
[7480/15000], training loss: 0.0511
16
AVD_Home_008_1_traj9, ate: 1302.9001037688795
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[7488/15000], training loss: 0.0662
[7496/15000], training loss: 0.0530
[7504/15000], training loss: 0.0649
[7512/15000], training loss: 0.0486
[7520/15000], training loss: 0.0609
16
AVD_Home_008_1_traj9, ate: 1294.0181647755007
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[7528/15000], training loss: 0.0780
[7536/15000], training loss: 0.0649
[7544/15000], training loss: 0.0784
[7552/15000], training loss: 0.0611
[7560/15000], training loss: 0.0561
16
AVD_Home_008_1_traj9, ate: 1293.945928534623
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[7568/15000], training loss: 0.0658
[7576/15000], training loss: 0.0754
[7584/15000], training loss: 0.0644
[7592/15000], training loss: 0.0508
[7600/15000], training loss: 0.0567
16
AVD_Home_008_1_traj9, ate: 1292.8478693528066
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[7608/15000], training loss: 0.0566
[7616/15000], training loss: 0.0593
[7624/15000], training loss: 0.0644
[7632/15000], training loss: 0.0676
[7640/15000], training loss: 0.0895
16
AVD_Home_008_1_traj9, ate: 1300.535302097349
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[7648/15000], training loss: 0.0621
[7656/15000], training loss: 0.0593
[7664/15000], training loss: 0.0636
[7672/15000], training loss: 0.0619
[7680/15000], training loss: 0.0483
16
AVD_Home_008_1_traj9, ate: 1304.0064992296736
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[7688/15000], training loss: 0.0806
[7696/15000], training loss: 0.0656
[7704/15000], training loss: 0.0724
[7712/15000], training loss: 0.0589
[7720/15000], training loss: 0.0530
16
AVD_Home_008_1_traj9, ate: 1309.4116542202232
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[7728/15000], training loss: 0.0638
[7736/15000], training loss: 0.0501
[7744/15000], training loss: 0.0440
[7752/15000], training loss: 0.0523
[7760/15000], training loss: 0.0597
16
AVD_Home_008_1_traj9, ate: 1305.6955154174511
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[7768/15000], training loss: 0.1095
[7776/15000], training loss: 0.0561
[7784/15000], training loss: 0.0500
[7792/15000], training loss: 0.0899
[7800/15000], training loss: 0.0490
16
AVD_Home_008_1_traj9, ate: 1291.1478115871898
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[7808/15000], training loss: 0.0578
[7816/15000], training loss: 0.0695
[7824/15000], training loss: 0.0546
[7832/15000], training loss: 0.0481
[7840/15000], training loss: 0.0656
16
AVD_Home_008_1_traj9, ate: 1300.4341059171823
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[7848/15000], training loss: 0.0413
[7856/15000], training loss: 0.0715
[7864/15000], training loss: 0.0789
[7872/15000], training loss: 0.0703
[7880/15000], training loss: 0.0499
16
AVD_Home_008_1_traj9, ate: 1325.4013879413055
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[7888/15000], training loss: 0.0665
[7896/15000], training loss: 0.0706
[7904/15000], training loss: 0.0687
[7912/15000], training loss: 0.0433
[7920/15000], training loss: 0.1027
16
AVD_Home_008_1_traj9, ate: 1316.6162078565235
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[7928/15000], training loss: 0.0518
[7936/15000], training loss: 0.0733
[7944/15000], training loss: 0.0636
[7952/15000], training loss: 0.0663
[7960/15000], training loss: 0.0613
16
AVD_Home_008_1_traj9, ate: 1307.0587466178788
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[7968/15000], training loss: 0.0938
[7976/15000], training loss: 0.0479
[7984/15000], training loss: 0.0471
[7992/15000], training loss: 0.0691
[8000/15000], training loss: 0.0517
16
AVD_Home_008_1_traj9, ate: 1300.3139694399345
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[8008/15000], training loss: 0.0671
[8016/15000], training loss: 0.0603
[8024/15000], training loss: 0.0490
[8032/15000], training loss: 0.0684
[8040/15000], training loss: 0.0479
16
AVD_Home_008_1_traj9, ate: 1289.5256197402991
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[8048/15000], training loss: 0.0597
[8056/15000], training loss: 0.0540
[8064/15000], training loss: 0.0731
[8072/15000], training loss: 0.0465
[8080/15000], training loss: 0.0630
16
AVD_Home_008_1_traj9, ate: 1307.2219132135579
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[8088/15000], training loss: 0.0664
[8096/15000], training loss: 0.0487
[8104/15000], training loss: 0.0842
[8112/15000], training loss: 0.0525
[8120/15000], training loss: 0.0910
16
AVD_Home_008_1_traj9, ate: 1304.544034860699
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[8128/15000], training loss: 0.0715
[8136/15000], training loss: 0.0702
[8144/15000], training loss: 0.0647
[8152/15000], training loss: 0.0578
[8160/15000], training loss: 0.0691
16
AVD_Home_008_1_traj9, ate: 1286.7117558006853
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[8168/15000], training loss: 0.1097
[8176/15000], training loss: 0.0567
[8184/15000], training loss: 0.0691
[8192/15000], training loss: 0.0917
[8200/15000], training loss: 0.0457
16
AVD_Home_008_1_traj9, ate: 1299.854994131652
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[8208/15000], training loss: 0.0606
[8216/15000], training loss: 0.0500
[8224/15000], training loss: 0.0477
[8232/15000], training loss: 0.0544
[8240/15000], training loss: 0.0759
16
AVD_Home_008_1_traj9, ate: 1300.632729560495
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[8248/15000], training loss: 0.0518
[8256/15000], training loss: 0.0502
[8264/15000], training loss: 0.0487
[8272/15000], training loss: 0.0608
[8280/15000], training loss: 0.0617
16
AVD_Home_008_1_traj9, ate: 1301.7669651222818
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[8288/15000], training loss: 0.0568
[8296/15000], training loss: 0.0651
[8304/15000], training loss: 0.0438
[8312/15000], training loss: 0.0738
[8320/15000], training loss: 0.0742
16
AVD_Home_008_1_traj9, ate: 1297.9596697167387
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[8328/15000], training loss: 0.0872
[8336/15000], training loss: 0.0592
[8344/15000], training loss: 0.0780
[8352/15000], training loss: 0.0477
[8360/15000], training loss: 0.0544
16
AVD_Home_008_1_traj9, ate: 1295.4731312245021
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[8368/15000], training loss: 0.0625
[8376/15000], training loss: 0.0513
[8384/15000], training loss: 0.0881
[8392/15000], training loss: 0.0637
[8400/15000], training loss: 0.0456
16
AVD_Home_008_1_traj9, ate: 1301.6193090840331
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[8408/15000], training loss: 0.0696
[8416/15000], training loss: 0.0604
[8424/15000], training loss: 0.0611
[8432/15000], training loss: 0.0586
[8440/15000], training loss: 0.0578
16
AVD_Home_008_1_traj9, ate: 1299.4175381715497
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[8448/15000], training loss: 0.0653
[8456/15000], training loss: 0.0448
[8464/15000], training loss: 0.0470
[8472/15000], training loss: 0.0646
[8480/15000], training loss: 0.0582
16
AVD_Home_008_1_traj9, ate: 1311.0924883343787
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[8488/15000], training loss: 0.0741
[8496/15000], training loss: 0.0482
[8504/15000], training loss: 0.0621
[8512/15000], training loss: 0.0470
[8520/15000], training loss: 0.0753
16
AVD_Home_008_1_traj9, ate: 1309.751722393223
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[8528/15000], training loss: 0.0571
[8536/15000], training loss: 0.0453
[8544/15000], training loss: 0.0503
[8552/15000], training loss: 0.0613
[8560/15000], training loss: 0.0661
16
AVD_Home_008_1_traj9, ate: 1316.0522532144964
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[8568/15000], training loss: 0.0486
[8576/15000], training loss: 0.0944
[8584/15000], training loss: 0.0458
[8592/15000], training loss: 0.0514
[8600/15000], training loss: 0.0508
16
AVD_Home_008_1_traj9, ate: 1308.765889827931
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[8608/15000], training loss: 0.0447
[8616/15000], training loss: 0.0498
[8624/15000], training loss: 0.0456
[8632/15000], training loss: 0.0576
[8640/15000], training loss: 0.0568
16
AVD_Home_008_1_traj9, ate: 1308.8966370903295
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[8648/15000], training loss: 0.0559
[8656/15000], training loss: 0.0508
[8664/15000], training loss: 0.0732
[8672/15000], training loss: 0.0490
[8680/15000], training loss: 0.0700
16
AVD_Home_008_1_traj9, ate: 1314.1319526409557
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[8688/15000], training loss: 0.0628
[8696/15000], training loss: 0.0470
[8704/15000], training loss: 0.0627
[8712/15000], training loss: 0.0678
[8720/15000], training loss: 0.0557
16
AVD_Home_008_1_traj9, ate: 1304.95526555964
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[8728/15000], training loss: 0.0537
[8736/15000], training loss: 0.0560
[8744/15000], training loss: 0.0475
[8752/15000], training loss: 0.0598
[8760/15000], training loss: 0.0685
16
AVD_Home_008_1_traj9, ate: 1310.4066120610664
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[8768/15000], training loss: 0.0719
[8776/15000], training loss: 0.0453
[8784/15000], training loss: 0.0516
[8792/15000], training loss: 0.0433
[8800/15000], training loss: 0.0660
16
AVD_Home_008_1_traj9, ate: 1310.7775573768436
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[8808/15000], training loss: 0.0721
[8816/15000], training loss: 0.0533
[8824/15000], training loss: 0.0660
[8832/15000], training loss: 0.0524
[8840/15000], training loss: 0.0621
16
AVD_Home_008_1_traj9, ate: 1324.8824726676096
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[8848/15000], training loss: 0.0652
[8856/15000], training loss: 0.0466
[8864/15000], training loss: 0.0599
[8872/15000], training loss: 0.0473
[8880/15000], training loss: 0.0584
16
AVD_Home_008_1_traj9, ate: 1284.3468250054696
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[8888/15000], training loss: 0.0657
[8896/15000], training loss: 0.0868
[8904/15000], training loss: 0.0824
[8912/15000], training loss: 0.0821
[8920/15000], training loss: 0.0712
16
AVD_Home_008_1_traj9, ate: 1302.5756642962338
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[8928/15000], training loss: 0.0618
[8936/15000], training loss: 0.0456
[8944/15000], training loss: 0.0483
[8952/15000], training loss: 0.0689
[8960/15000], training loss: 0.0502
16
AVD_Home_008_1_traj9, ate: 1307.1659709437856
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[8968/15000], training loss: 0.0535
[8976/15000], training loss: 0.0571
[8984/15000], training loss: 0.0502
[8992/15000], training loss: 0.0511
[9000/15000], training loss: 0.0633
16
AVD_Home_008_1_traj9, ate: 1317.7825837581072
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[9008/15000], training loss: 0.0484
[9016/15000], training loss: 0.0517
[9024/15000], training loss: 0.0515
[9032/15000], training loss: 0.0534
[9040/15000], training loss: 0.0558
16
AVD_Home_008_1_traj9, ate: 1302.996250902072
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[9048/15000], training loss: 0.0729
[9056/15000], training loss: 0.0726
[9064/15000], training loss: 0.0562
[9072/15000], training loss: 0.0563
[9080/15000], training loss: 0.0536
16
AVD_Home_008_1_traj9, ate: 1309.7244380625523
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[9088/15000], training loss: 0.0443
[9096/15000], training loss: 0.0472
[9104/15000], training loss: 0.0524
[9112/15000], training loss: 0.0585
[9120/15000], training loss: 0.0673
16
AVD_Home_008_1_traj9, ate: 1306.954589168457
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[9128/15000], training loss: 0.0664
[9136/15000], training loss: 0.0662
[9144/15000], training loss: 0.0483
[9152/15000], training loss: 0.0769
[9160/15000], training loss: 0.0450
16
AVD_Home_008_1_traj9, ate: 1303.600120731433
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[9168/15000], training loss: 0.0464
[9176/15000], training loss: 0.0644
[9184/15000], training loss: 0.0544
[9192/15000], training loss: 0.0497
[9200/15000], training loss: 0.0423
16
AVD_Home_008_1_traj9, ate: 1298.5481868818329
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[9208/15000], training loss: 0.0612
[9216/15000], training loss: 0.0541
[9224/15000], training loss: 0.0535
[9232/15000], training loss: 0.0635
[9240/15000], training loss: 0.0583
16
AVD_Home_008_1_traj9, ate: 1298.716082912303
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[9248/15000], training loss: 0.0967
[9256/15000], training loss: 0.0800
[9264/15000], training loss: 0.0543
[9272/15000], training loss: 0.0433
[9280/15000], training loss: 0.0516
16
AVD_Home_008_1_traj9, ate: 1308.666187567266
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[9288/15000], training loss: 0.0523
[9296/15000], training loss: 0.0498
[9304/15000], training loss: 0.0437
[9312/15000], training loss: 0.0518
[9320/15000], training loss: 0.0476
16
AVD_Home_008_1_traj9, ate: 1300.9452191530372
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[9328/15000], training loss: 0.0729
[9336/15000], training loss: 0.0665
[9344/15000], training loss: 0.0483
[9352/15000], training loss: 0.0470
[9360/15000], training loss: 0.0499
16
AVD_Home_008_1_traj9, ate: 1310.7803963425827
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[9368/15000], training loss: 0.0460
[9376/15000], training loss: 0.0438
[9384/15000], training loss: 0.0650
[9392/15000], training loss: 0.0448
[9400/15000], training loss: 0.0654
16
AVD_Home_008_1_traj9, ate: 1309.8155088988317
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[9408/15000], training loss: 0.0713
[9416/15000], training loss: 0.0612
[9424/15000], training loss: 0.0457
[9432/15000], training loss: 0.0638
[9440/15000], training loss: 0.0436
16
AVD_Home_008_1_traj9, ate: 1294.2480023518826
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[9448/15000], training loss: 0.0513
[9456/15000], training loss: 0.0457
[9464/15000], training loss: 0.0503
[9472/15000], training loss: 0.0683
[9480/15000], training loss: 0.0713
16
AVD_Home_008_1_traj9, ate: 1299.294033179754
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[9488/15000], training loss: 0.0504
[9496/15000], training loss: 0.0448
[9504/15000], training loss: 0.0445
[9512/15000], training loss: 0.0482
[9520/15000], training loss: 0.0533
16
AVD_Home_008_1_traj9, ate: 1308.6107155932607
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[9528/15000], training loss: 0.0545
[9536/15000], training loss: 0.0584
[9544/15000], training loss: 0.0438
[9552/15000], training loss: 0.0643
[9560/15000], training loss: 0.0709
16
AVD_Home_008_1_traj9, ate: 1305.3005387465703
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[9568/15000], training loss: 0.0662
[9576/15000], training loss: 0.0750
[9584/15000], training loss: 0.0513
[9592/15000], training loss: 0.0603
[9600/15000], training loss: 0.0641
16
AVD_Home_008_1_traj9, ate: 1297.2331682282334
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[9608/15000], training loss: 0.0530
[9616/15000], training loss: 0.0588
[9624/15000], training loss: 0.0549
[9632/15000], training loss: 0.0538
[9640/15000], training loss: 0.0587
16
AVD_Home_008_1_traj9, ate: 1294.3358375507858
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[9648/15000], training loss: 0.0646
[9656/15000], training loss: 0.0429
[9664/15000], training loss: 0.0592
[9672/15000], training loss: 0.0696
[9680/15000], training loss: 0.0429
16
AVD_Home_008_1_traj9, ate: 1301.7071830535347
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[9688/15000], training loss: 0.0631
[9696/15000], training loss: 0.0502
[9704/15000], training loss: 0.0790
[9712/15000], training loss: 0.0459
[9720/15000], training loss: 0.0469
16
AVD_Home_008_1_traj9, ate: 1303.8950819696852
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[9728/15000], training loss: 0.0443
[9736/15000], training loss: 0.0470
[9744/15000], training loss: 0.0688
[9752/15000], training loss: 0.0447
[9760/15000], training loss: 0.0543
16
AVD_Home_008_1_traj9, ate: 1313.217708914564
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[9768/15000], training loss: 0.0615
[9776/15000], training loss: 0.0683
[9784/15000], training loss: 0.0564
[9792/15000], training loss: 0.0439
[9800/15000], training loss: 0.0649
16
AVD_Home_008_1_traj9, ate: 1301.786640512816
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[9808/15000], training loss: 0.0608
[9816/15000], training loss: 0.0412
[9824/15000], training loss: 0.0507
[9832/15000], training loss: 0.0578
[9840/15000], training loss: 0.0490
16
AVD_Home_008_1_traj9, ate: 1295.7581308154038
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[9848/15000], training loss: 0.0647
[9856/15000], training loss: 0.0924
[9864/15000], training loss: 0.0473
[9872/15000], training loss: 0.0611
[9880/15000], training loss: 0.0489
16
AVD_Home_008_1_traj9, ate: 1306.26571165668
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[9888/15000], training loss: 0.0389
[9896/15000], training loss: 0.0514
[9904/15000], training loss: 0.0604
[9912/15000], training loss: 0.0470
[9920/15000], training loss: 0.0716
16
AVD_Home_008_1_traj9, ate: 1307.241952543838
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[9928/15000], training loss: 0.0447
[9936/15000], training loss: 0.0490
[9944/15000], training loss: 0.0391
[9952/15000], training loss: 0.0448
[9960/15000], training loss: 0.0547
16
AVD_Home_008_1_traj9, ate: 1307.6315015627586
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[9968/15000], training loss: 0.0497
[9976/15000], training loss: 0.0699
[9984/15000], training loss: 0.0632
[9992/15000], training loss: 0.0602
[10000/15000], training loss: 0.0702
16
AVD_Home_008_1_traj9, ate: 1315.5237592361368
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[10008/15000], training loss: 0.0484
[10016/15000], training loss: 0.0492
[10024/15000], training loss: 0.0487
[10032/15000], training loss: 0.0490
[10040/15000], training loss: 0.0651
16
AVD_Home_008_1_traj9, ate: 1310.8597955479272
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[10048/15000], training loss: 0.0542
[10056/15000], training loss: 0.0627
[10064/15000], training loss: 0.0526
[10072/15000], training loss: 0.0407
[10080/15000], training loss: 0.1022
16
AVD_Home_008_1_traj9, ate: 1306.254965676005
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[10088/15000], training loss: 0.0602
[10096/15000], training loss: 0.0713
[10104/15000], training loss: 0.0457
[10112/15000], training loss: 0.0591
[10120/15000], training loss: 0.0413
16
AVD_Home_008_1_traj9, ate: 1309.889468426511
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[10128/15000], training loss: 0.0574
[10136/15000], training loss: 0.0374
[10144/15000], training loss: 0.0568
[10152/15000], training loss: 0.0492
[10160/15000], training loss: 0.0452
16
AVD_Home_008_1_traj9, ate: 1295.873815716917
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[10168/15000], training loss: 0.0860
[10176/15000], training loss: 0.0898
[10184/15000], training loss: 0.0506
[10192/15000], training loss: 0.0548
[10200/15000], training loss: 0.0450
16
AVD_Home_008_1_traj9, ate: 1287.8383621012754
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[10208/15000], training loss: 0.0614
[10216/15000], training loss: 0.0424
[10224/15000], training loss: 0.0841
[10232/15000], training loss: 0.1026
[10240/15000], training loss: 0.0633
16
AVD_Home_008_1_traj9, ate: 1307.6730282041804
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[10248/15000], training loss: 0.0539
[10256/15000], training loss: 0.0571
[10264/15000], training loss: 0.0494
[10272/15000], training loss: 0.0682
[10280/15000], training loss: 0.0564
16
AVD_Home_008_1_traj9, ate: 1308.3619491781305
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[10288/15000], training loss: 0.0638
[10296/15000], training loss: 0.0605
[10304/15000], training loss: 0.0601
[10312/15000], training loss: 0.0421
[10320/15000], training loss: 0.0562
16
AVD_Home_008_1_traj9, ate: 1306.8748411041397
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[10328/15000], training loss: 0.0740
[10336/15000], training loss: 0.0776
[10344/15000], training loss: 0.0568
[10352/15000], training loss: 0.0624
[10360/15000], training loss: 0.0572
16
AVD_Home_008_1_traj9, ate: 1304.683691251029
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[10368/15000], training loss: 0.0663
[10376/15000], training loss: 0.0461
[10384/15000], training loss: 0.0489
[10392/15000], training loss: 0.0484
[10400/15000], training loss: 0.0426
16
AVD_Home_008_1_traj9, ate: 1299.115994389723
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[10408/15000], training loss: 0.0619
[10416/15000], training loss: 0.0515
[10424/15000], training loss: 0.0495
[10432/15000], training loss: 0.0446
[10440/15000], training loss: 0.0737
16
AVD_Home_008_1_traj9, ate: 1310.3552124113671
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[10448/15000], training loss: 0.0497
[10456/15000], training loss: 0.0503
[10464/15000], training loss: 0.0541
[10472/15000], training loss: 0.0500
[10480/15000], training loss: 0.0651
16
AVD_Home_008_1_traj9, ate: 1307.3314522579997
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[10488/15000], training loss: 0.0451
[10496/15000], training loss: 0.0419
[10504/15000], training loss: 0.0559
[10512/15000], training loss: 0.0477
[10520/15000], training loss: 0.0656
16
AVD_Home_008_1_traj9, ate: 1303.261784648598
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[10528/15000], training loss: 0.0406
[10536/15000], training loss: 0.0503
[10544/15000], training loss: 0.0653
[10552/15000], training loss: 0.0889
[10560/15000], training loss: 0.0601
16
AVD_Home_008_1_traj9, ate: 1302.7744492067782
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[10568/15000], training loss: 0.0439
[10576/15000], training loss: 0.0633
[10584/15000], training loss: 0.0661
[10592/15000], training loss: 0.0509
[10600/15000], training loss: 0.0535
16
AVD_Home_008_1_traj9, ate: 1316.3194462544009
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[10608/15000], training loss: 0.0717
[10616/15000], training loss: 0.0487
[10624/15000], training loss: 0.0440
[10632/15000], training loss: 0.0528
[10640/15000], training loss: 0.0504
16
AVD_Home_008_1_traj9, ate: 1301.6305999508597
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[10648/15000], training loss: 0.0839
[10656/15000], training loss: 0.0722
[10664/15000], training loss: 0.0515
[10672/15000], training loss: 0.0520
[10680/15000], training loss: 0.0458
16
AVD_Home_008_1_traj9, ate: 1302.6478928694896
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[10688/15000], training loss: 0.0560
[10696/15000], training loss: 0.0508
[10704/15000], training loss: 0.0447
[10712/15000], training loss: 0.0408
[10720/15000], training loss: 0.0462
16
AVD_Home_008_1_traj9, ate: 1302.1718378720939
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[10728/15000], training loss: 0.0443
[10736/15000], training loss: 0.0571
[10744/15000], training loss: 0.0722
[10752/15000], training loss: 0.0744
[10760/15000], training loss: 0.0617
16
AVD_Home_008_1_traj9, ate: 1296.404974674367
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[10768/15000], training loss: 0.0415
[10776/15000], training loss: 0.0516
[10784/15000], training loss: 0.0525
[10792/15000], training loss: 0.0646
[10800/15000], training loss: 0.0447
16
AVD_Home_008_1_traj9, ate: 1304.66443708962
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[10808/15000], training loss: 0.0670
[10816/15000], training loss: 0.0678
[10824/15000], training loss: 0.0409
[10832/15000], training loss: 0.0595
[10840/15000], training loss: 0.0792
16
AVD_Home_008_1_traj9, ate: 1311.8498617005578
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[10848/15000], training loss: 0.0604
[10856/15000], training loss: 0.0470
[10864/15000], training loss: 0.0613
[10872/15000], training loss: 0.0371
[10880/15000], training loss: 0.0507
16
AVD_Home_008_1_traj9, ate: 1298.7459318841309
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[10888/15000], training loss: 0.0882
[10896/15000], training loss: 0.0581
[10904/15000], training loss: 0.0648
[10912/15000], training loss: 0.0508
[10920/15000], training loss: 0.0558
16
AVD_Home_008_1_traj9, ate: 1309.2515278113806
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[10928/15000], training loss: 0.0511
[10936/15000], training loss: 0.0590
[10944/15000], training loss: 0.0621
[10952/15000], training loss: 0.0432
[10960/15000], training loss: 0.0464
16
AVD_Home_008_1_traj9, ate: 1303.9175043645262
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[10968/15000], training loss: 0.0469
[10976/15000], training loss: 0.0767
[10984/15000], training loss: 0.0443
[10992/15000], training loss: 0.0783
[11000/15000], training loss: 0.0647
16
AVD_Home_008_1_traj9, ate: 1303.5717389036156
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[11008/15000], training loss: 0.0695
[11016/15000], training loss: 0.0496
[11024/15000], training loss: 0.0662
[11032/15000], training loss: 0.0502
[11040/15000], training loss: 0.0713
16
AVD_Home_008_1_traj9, ate: 1301.0214554993938
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[11048/15000], training loss: 0.0526
[11056/15000], training loss: 0.0495
[11064/15000], training loss: 0.0710
[11072/15000], training loss: 0.0674
[11080/15000], training loss: 0.0484
16
AVD_Home_008_1_traj9, ate: 1306.1115161971593
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[11088/15000], training loss: 0.0447
[11096/15000], training loss: 0.0629
[11104/15000], training loss: 0.0530
[11112/15000], training loss: 0.0906
[11120/15000], training loss: 0.0616
16
AVD_Home_008_1_traj9, ate: 1296.5814006515714
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[11128/15000], training loss: 0.0543
[11136/15000], training loss: 0.0828
[11144/15000], training loss: 0.0736
[11152/15000], training loss: 0.0413
[11160/15000], training loss: 0.0689
16
AVD_Home_008_1_traj9, ate: 1295.4236021415231
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[11168/15000], training loss: 0.0691
[11176/15000], training loss: 0.0391
[11184/15000], training loss: 0.0575
[11192/15000], training loss: 0.0915
[11200/15000], training loss: 0.0748
16
AVD_Home_008_1_traj9, ate: 1294.5167749284929
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[11208/15000], training loss: 0.0695
[11216/15000], training loss: 0.0532
[11224/15000], training loss: 0.0551
[11232/15000], training loss: 0.0614
[11240/15000], training loss: 0.0495
16
AVD_Home_008_1_traj9, ate: 1302.0675428218724
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[11248/15000], training loss: 0.0647
[11256/15000], training loss: 0.0471
[11264/15000], training loss: 0.0535
[11272/15000], training loss: 0.0730
[11280/15000], training loss: 0.0605
16
AVD_Home_008_1_traj9, ate: 1308.0630014187502
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[11288/15000], training loss: 0.0410
[11296/15000], training loss: 0.0542
[11304/15000], training loss: 0.0570
[11312/15000], training loss: 0.0454
[11320/15000], training loss: 0.0523
16
AVD_Home_008_1_traj9, ate: 1300.5013743226777
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[11328/15000], training loss: 0.0522
[11336/15000], training loss: 0.0491
[11344/15000], training loss: 0.0455
[11352/15000], training loss: 0.0530
[11360/15000], training loss: 0.0568
16
AVD_Home_008_1_traj9, ate: 1314.2180632504696
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[11368/15000], training loss: 0.0759
[11376/15000], training loss: 0.0611
[11384/15000], training loss: 0.0446
[11392/15000], training loss: 0.0465
[11400/15000], training loss: 0.0486
16
AVD_Home_008_1_traj9, ate: 1300.1978397525945
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[11408/15000], training loss: 0.0443
[11416/15000], training loss: 0.0547
[11424/15000], training loss: 0.0614
[11432/15000], training loss: 0.0494
[11440/15000], training loss: 0.0498
16
AVD_Home_008_1_traj9, ate: 1310.2465855162209
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[11448/15000], training loss: 0.0439
[11456/15000], training loss: 0.0671
[11464/15000], training loss: 0.0551
[11472/15000], training loss: 0.0636
[11480/15000], training loss: 0.0450
16
AVD_Home_008_1_traj9, ate: 1300.4675188935717
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[11488/15000], training loss: 0.0517
[11496/15000], training loss: 0.0715
[11504/15000], training loss: 0.0618
[11512/15000], training loss: 0.0850
[11520/15000], training loss: 0.0602
16
AVD_Home_008_1_traj9, ate: 1297.4626385446722
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[11528/15000], training loss: 0.0587
[11536/15000], training loss: 0.0706
[11544/15000], training loss: 0.0539
[11552/15000], training loss: 0.0503
[11560/15000], training loss: 0.0476
16
AVD_Home_008_1_traj9, ate: 1302.8294556850744
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[11568/15000], training loss: 0.0531
[11576/15000], training loss: 0.0568
[11584/15000], training loss: 0.0464
[11592/15000], training loss: 0.0604
[11600/15000], training loss: 0.0451
16
AVD_Home_008_1_traj9, ate: 1296.949001415208
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[11608/15000], training loss: 0.0594
[11616/15000], training loss: 0.0652
[11624/15000], training loss: 0.0477
[11632/15000], training loss: 0.0445
[11640/15000], training loss: 0.0441
16
AVD_Home_008_1_traj9, ate: 1294.607393387564
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[11648/15000], training loss: 0.0642
[11656/15000], training loss: 0.0604
[11664/15000], training loss: 0.0528
[11672/15000], training loss: 0.0566
[11680/15000], training loss: 0.0400
16
AVD_Home_008_1_traj9, ate: 1304.9655681715044
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[11688/15000], training loss: 0.0492
[11696/15000], training loss: 0.0680
[11704/15000], training loss: 0.0403
[11712/15000], training loss: 0.0538
[11720/15000], training loss: 0.0452
16
AVD_Home_008_1_traj9, ate: 1294.8400780614004
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[11728/15000], training loss: 0.0553
[11736/15000], training loss: 0.0434
[11744/15000], training loss: 0.0649
[11752/15000], training loss: 0.0442
[11760/15000], training loss: 0.0708
16
AVD_Home_008_1_traj9, ate: 1318.1948542495143
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[11768/15000], training loss: 0.0567
[11776/15000], training loss: 0.0599
[11784/15000], training loss: 0.0501
[11792/15000], training loss: 0.0592
[11800/15000], training loss: 0.0497
16
AVD_Home_008_1_traj9, ate: 1313.1690221755732
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[11808/15000], training loss: 0.0541
[11816/15000], training loss: 0.0453
[11824/15000], training loss: 0.0727
[11832/15000], training loss: 0.0660
[11840/15000], training loss: 0.0692
16
AVD_Home_008_1_traj9, ate: 1302.217836254717
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[11848/15000], training loss: 0.0516
[11856/15000], training loss: 0.0470
[11864/15000], training loss: 0.0770
[11872/15000], training loss: 0.0494
[11880/15000], training loss: 0.0803
16
AVD_Home_008_1_traj9, ate: 1304.0413324656167
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[11888/15000], training loss: 0.0430
[11896/15000], training loss: 0.0653
[11904/15000], training loss: 0.0419
[11912/15000], training loss: 0.0635
[11920/15000], training loss: 0.0583
16
AVD_Home_008_1_traj9, ate: 1317.443239785217
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[11928/15000], training loss: 0.0781
[11936/15000], training loss: 0.0614
[11944/15000], training loss: 0.0482
[11952/15000], training loss: 0.0510
[11960/15000], training loss: 0.0667
16
AVD_Home_008_1_traj9, ate: 1323.437687720863
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[11968/15000], training loss: 0.0759
[11976/15000], training loss: 0.0786
[11984/15000], training loss: 0.0889
[11992/15000], training loss: 0.0495
[12000/15000], training loss: 0.0676
16
AVD_Home_008_1_traj9, ate: 1302.0840743059982
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[12008/15000], training loss: 0.0644
[12016/15000], training loss: 0.0600
[12024/15000], training loss: 0.0771
[12032/15000], training loss: 0.0413
[12040/15000], training loss: 0.0611
16
AVD_Home_008_1_traj9, ate: 1305.0197595674013
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[12048/15000], training loss: 0.0709
[12056/15000], training loss: 0.0430
[12064/15000], training loss: 0.0660
[12072/15000], training loss: 0.0515
[12080/15000], training loss: 0.0466
16
AVD_Home_008_1_traj9, ate: 1304.249933334062
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[12088/15000], training loss: 0.0648
[12096/15000], training loss: 0.0687
[12104/15000], training loss: 0.0619
[12112/15000], training loss: 0.0679
[12120/15000], training loss: 0.0460
16
AVD_Home_008_1_traj9, ate: 1303.0515757363603
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[12128/15000], training loss: 0.0703
[12136/15000], training loss: 0.0457
[12144/15000], training loss: 0.0498
[12152/15000], training loss: 0.0604
[12160/15000], training loss: 0.0672
16
AVD_Home_008_1_traj9, ate: 1305.6683885886125
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[12168/15000], training loss: 0.0599
[12176/15000], training loss: 0.0489
[12184/15000], training loss: 0.0858
[12192/15000], training loss: 0.0621
[12200/15000], training loss: 0.0605
16
AVD_Home_008_1_traj9, ate: 1305.1729629776532
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[12208/15000], training loss: 0.0551
[12216/15000], training loss: 0.0433
[12224/15000], training loss: 0.0528
[12232/15000], training loss: 0.0503
[12240/15000], training loss: 0.0479
16
AVD_Home_008_1_traj9, ate: 1310.3302824685256
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[12248/15000], training loss: 0.0588
[12256/15000], training loss: 0.0536
[12264/15000], training loss: 0.0489
[12272/15000], training loss: 0.0479
[12280/15000], training loss: 0.0577
16
AVD_Home_008_1_traj9, ate: 1306.9140069959453
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[12288/15000], training loss: 0.0452
[12296/15000], training loss: 0.0802
[12304/15000], training loss: 0.0488
[12312/15000], training loss: 0.0483
[12320/15000], training loss: 0.0473
16
AVD_Home_008_1_traj9, ate: 1306.3236789502116
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[12328/15000], training loss: 0.0602
[12336/15000], training loss: 0.0402
[12344/15000], training loss: 0.0662
[12352/15000], training loss: 0.0642
[12360/15000], training loss: 0.0441
16
AVD_Home_008_1_traj9, ate: 1302.0553830100232
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[12368/15000], training loss: 0.0403
[12376/15000], training loss: 0.0586
[12384/15000], training loss: 0.0528
[12392/15000], training loss: 0.0640
[12400/15000], training loss: 0.0553
16
AVD_Home_008_1_traj9, ate: 1307.9848825273364
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[12408/15000], training loss: 0.0548
[12416/15000], training loss: 0.0522
[12424/15000], training loss: 0.0775
[12432/15000], training loss: 0.0523
[12440/15000], training loss: 0.0465
16
AVD_Home_008_1_traj9, ate: 1307.059169727254
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[12448/15000], training loss: 0.0571
[12456/15000], training loss: 0.0407
[12464/15000], training loss: 0.0609
[12472/15000], training loss: 0.0711
[12480/15000], training loss: 0.0640
16
AVD_Home_008_1_traj9, ate: 1302.8487846578687
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[12488/15000], training loss: 0.0532
[12496/15000], training loss: 0.0607
[12504/15000], training loss: 0.0447
[12512/15000], training loss: 0.0412
[12520/15000], training loss: 0.0566
16
AVD_Home_008_1_traj9, ate: 1297.019056120509
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[12528/15000], training loss: 0.0582
[12536/15000], training loss: 0.0627
[12544/15000], training loss: 0.0708
[12552/15000], training loss: 0.0449
[12560/15000], training loss: 0.0556
16
AVD_Home_008_1_traj9, ate: 1309.6132278200248
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[12568/15000], training loss: 0.0586
[12576/15000], training loss: 0.0657
[12584/15000], training loss: 0.0502
[12592/15000], training loss: 0.0522
[12600/15000], training loss: 0.0440
16
AVD_Home_008_1_traj9, ate: 1307.6927152088538
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[12608/15000], training loss: 0.0450
[12616/15000], training loss: 0.0508
[12624/15000], training loss: 0.0471
[12632/15000], training loss: 0.0487
[12640/15000], training loss: 0.0873
16
AVD_Home_008_1_traj9, ate: 1293.86145989456
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[12648/15000], training loss: 0.0482
[12656/15000], training loss: 0.0444
[12664/15000], training loss: 0.0548
[12672/15000], training loss: 0.0420
[12680/15000], training loss: 0.0650
16
AVD_Home_008_1_traj9, ate: 1303.2424317136013
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[12688/15000], training loss: 0.0583
[12696/15000], training loss: 0.0669
[12704/15000], training loss: 0.0433
[12712/15000], training loss: 0.0474
[12720/15000], training loss: 0.0502
16
AVD_Home_008_1_traj9, ate: 1304.3706002540061
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[12728/15000], training loss: 0.0596
[12736/15000], training loss: 0.0492
[12744/15000], training loss: 0.0522
[12752/15000], training loss: 0.0486
[12760/15000], training loss: 0.0508
16
AVD_Home_008_1_traj9, ate: 1311.836147147374
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[12768/15000], training loss: 0.0393
[12776/15000], training loss: 0.0469
[12784/15000], training loss: 0.0482
[12792/15000], training loss: 0.0737
[12800/15000], training loss: 0.0530
16
AVD_Home_008_1_traj9, ate: 1311.7681436725277
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[12808/15000], training loss: 0.0409
[12816/15000], training loss: 0.0488
[12824/15000], training loss: 0.0525
[12832/15000], training loss: 0.0900
[12840/15000], training loss: 0.0439
16
AVD_Home_008_1_traj9, ate: 1308.0571504621762
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[12848/15000], training loss: 0.0515
[12856/15000], training loss: 0.0572
[12864/15000], training loss: 0.0416
[12872/15000], training loss: 0.0565
[12880/15000], training loss: 0.0555
16
AVD_Home_008_1_traj9, ate: 1305.6672640260965
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[12888/15000], training loss: 0.0691
[12896/15000], training loss: 0.0672
[12904/15000], training loss: 0.0681
[12912/15000], training loss: 0.0736
[12920/15000], training loss: 0.1013
16
AVD_Home_008_1_traj9, ate: 1311.8647381369547
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[12928/15000], training loss: 0.0480
[12936/15000], training loss: 0.0748
[12944/15000], training loss: 0.0531
[12952/15000], training loss: 0.0490
[12960/15000], training loss: 0.0772
16
AVD_Home_008_1_traj9, ate: 1303.0938474309842
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[12968/15000], training loss: 0.0628
[12976/15000], training loss: 0.0439
[12984/15000], training loss: 0.0572
[12992/15000], training loss: 0.0454
[13000/15000], training loss: 0.0523
16
AVD_Home_008_1_traj9, ate: 1306.4417059314899
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[13008/15000], training loss: 0.0523
[13016/15000], training loss: 0.0473
[13024/15000], training loss: 0.0372
[13032/15000], training loss: 0.0607
[13040/15000], training loss: 0.0495
16
AVD_Home_008_1_traj9, ate: 1302.7304279006578
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[13048/15000], training loss: 0.0475
[13056/15000], training loss: 0.0666
[13064/15000], training loss: 0.0501
[13072/15000], training loss: 0.0408
[13080/15000], training loss: 0.0626
16
AVD_Home_008_1_traj9, ate: 1308.6830049484674
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[13088/15000], training loss: 0.0536
[13096/15000], training loss: 0.0632
[13104/15000], training loss: 0.0509
[13112/15000], training loss: 0.0541
[13120/15000], training loss: 0.0438
16
AVD_Home_008_1_traj9, ate: 1306.6492988990688
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[13128/15000], training loss: 0.0512
[13136/15000], training loss: 0.0699
[13144/15000], training loss: 0.0550
[13152/15000], training loss: 0.0440
[13160/15000], training loss: 0.0585
16
AVD_Home_008_1_traj9, ate: 1307.386983260642
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[13168/15000], training loss: 0.0792
[13176/15000], training loss: 0.0491
[13184/15000], training loss: 0.0388
[13192/15000], training loss: 0.0540
[13200/15000], training loss: 0.0678
16
AVD_Home_008_1_traj9, ate: 1302.8780803800948
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[13208/15000], training loss: 0.0637
[13216/15000], training loss: 0.0647
[13224/15000], training loss: 0.0541
[13232/15000], training loss: 0.0477
[13240/15000], training loss: 0.0547
16
AVD_Home_008_1_traj9, ate: 1310.2330105806975
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[13248/15000], training loss: 0.0433
[13256/15000], training loss: 0.0650
[13264/15000], training loss: 0.0860
[13272/15000], training loss: 0.0662
[13280/15000], training loss: 0.0468
16
AVD_Home_008_1_traj9, ate: 1310.8054671948357
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[13288/15000], training loss: 0.0475
[13296/15000], training loss: 0.0534
[13304/15000], training loss: 0.0659
[13312/15000], training loss: 0.0381
[13320/15000], training loss: 0.0464
16
AVD_Home_008_1_traj9, ate: 1303.3612738033414
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[13328/15000], training loss: 0.0786
[13336/15000], training loss: 0.0523
[13344/15000], training loss: 0.1012
[13352/15000], training loss: 0.0649
[13360/15000], training loss: 0.0393
16
AVD_Home_008_1_traj9, ate: 1308.942208068073
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[13368/15000], training loss: 0.0455
[13376/15000], training loss: 0.0502
[13384/15000], training loss: 0.0583
[13392/15000], training loss: 0.0428
[13400/15000], training loss: 0.0668
16
AVD_Home_008_1_traj9, ate: 1301.6439003235232
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[13408/15000], training loss: 0.0572
[13416/15000], training loss: 0.0450
[13424/15000], training loss: 0.0664
[13432/15000], training loss: 0.0385
[13440/15000], training loss: 0.0632
16
AVD_Home_008_1_traj9, ate: 1307.6872061662611
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[13448/15000], training loss: 0.0754
[13456/15000], training loss: 0.0598
[13464/15000], training loss: 0.0656
[13472/15000], training loss: 0.0560
[13480/15000], training loss: 0.0379
16
AVD_Home_008_1_traj9, ate: 1304.3048181577346
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[13488/15000], training loss: 0.0568
[13496/15000], training loss: 0.0425
[13504/15000], training loss: 0.0439
[13512/15000], training loss: 0.0531
[13520/15000], training loss: 0.0459
16
AVD_Home_008_1_traj9, ate: 1315.594998289346
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[13528/15000], training loss: 0.0396
[13536/15000], training loss: 0.0414
[13544/15000], training loss: 0.0499
[13552/15000], training loss: 0.0435
[13560/15000], training loss: 0.0400
16
AVD_Home_008_1_traj9, ate: 1304.7341507119893
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[13568/15000], training loss: 0.0608
[13576/15000], training loss: 0.0498
[13584/15000], training loss: 0.0567
[13592/15000], training loss: 0.0536
[13600/15000], training loss: 0.0506
16
AVD_Home_008_1_traj9, ate: 1313.1937414598274
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[13608/15000], training loss: 0.0510
[13616/15000], training loss: 0.0671
[13624/15000], training loss: 0.0444
[13632/15000], training loss: 0.0739
[13640/15000], training loss: 0.0708
16
AVD_Home_008_1_traj9, ate: 1299.7456452730935
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[13648/15000], training loss: 0.0584
[13656/15000], training loss: 0.0497
[13664/15000], training loss: 0.0652
[13672/15000], training loss: 0.0752
[13680/15000], training loss: 0.0468
16
AVD_Home_008_1_traj9, ate: 1305.1912267416476
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[13688/15000], training loss: 0.0602
[13696/15000], training loss: 0.0563
[13704/15000], training loss: 0.0475
[13712/15000], training loss: 0.0846
[13720/15000], training loss: 0.0426
16
AVD_Home_008_1_traj9, ate: 1306.1185236533215
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[13728/15000], training loss: 0.0558
[13736/15000], training loss: 0.0660
[13744/15000], training loss: 0.0430
[13752/15000], training loss: 0.0511
[13760/15000], training loss: 0.0642
16
AVD_Home_008_1_traj9, ate: 1302.5419272071238
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[13768/15000], training loss: 0.0643
[13776/15000], training loss: 0.0483
[13784/15000], training loss: 0.0512
[13792/15000], training loss: 0.0646
[13800/15000], training loss: 0.0746
16
AVD_Home_008_1_traj9, ate: 1307.1556293397969
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[13808/15000], training loss: 0.0767
[13816/15000], training loss: 0.0419
[13824/15000], training loss: 0.0559
[13832/15000], training loss: 0.0489
[13840/15000], training loss: 0.0742
16
AVD_Home_008_1_traj9, ate: 1297.9751550505587
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[13848/15000], training loss: 0.0674
[13856/15000], training loss: 0.0422
[13864/15000], training loss: 0.0469
[13872/15000], training loss: 0.0589
[13880/15000], training loss: 0.0457
16
AVD_Home_008_1_traj9, ate: 1309.971532598276
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[13888/15000], training loss: 0.0434
[13896/15000], training loss: 0.0477
[13904/15000], training loss: 0.0471
[13912/15000], training loss: 0.0497
[13920/15000], training loss: 0.0588
16
AVD_Home_008_1_traj9, ate: 1315.8586466150177
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[13928/15000], training loss: 0.0531
[13936/15000], training loss: 0.0610
[13944/15000], training loss: 0.0589
[13952/15000], training loss: 0.0904
[13960/15000], training loss: 0.0365
16
AVD_Home_008_1_traj9, ate: 1305.476477789929
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[13968/15000], training loss: 0.0619
[13976/15000], training loss: 0.0548
[13984/15000], training loss: 0.0666
[13992/15000], training loss: 0.0520
[14000/15000], training loss: 0.0472
16
AVD_Home_008_1_traj9, ate: 1311.938511909239
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[14008/15000], training loss: 0.0969
[14016/15000], training loss: 0.0473
[14024/15000], training loss: 0.0683
[14032/15000], training loss: 0.0785
[14040/15000], training loss: 0.0431
16
AVD_Home_008_1_traj9, ate: 1308.5331537784746
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[14048/15000], training loss: 0.0504
[14056/15000], training loss: 0.0617
[14064/15000], training loss: 0.0427
[14072/15000], training loss: 0.0541
[14080/15000], training loss: 0.0636
16
AVD_Home_008_1_traj9, ate: 1309.150913336906
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[14088/15000], training loss: 0.0550
[14096/15000], training loss: 0.0581
[14104/15000], training loss: 0.0585
[14112/15000], training loss: 0.0455
[14120/15000], training loss: 0.0573
16
AVD_Home_008_1_traj9, ate: 1307.630522914509
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[14128/15000], training loss: 0.0508
[14136/15000], training loss: 0.0641
[14144/15000], training loss: 0.0687
[14152/15000], training loss: 0.0495
[14160/15000], training loss: 0.0640
16
AVD_Home_008_1_traj9, ate: 1306.1275810807633
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[14168/15000], training loss: 0.0560
[14176/15000], training loss: 0.0404
[14184/15000], training loss: 0.0572
[14192/15000], training loss: 0.0416
[14200/15000], training loss: 0.0408
16
AVD_Home_008_1_traj9, ate: 1303.3666161330539
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[14208/15000], training loss: 0.0642
[14216/15000], training loss: 0.0625
[14224/15000], training loss: 0.0417
[14232/15000], training loss: 0.0419
[14240/15000], training loss: 0.0522
16
AVD_Home_008_1_traj9, ate: 1306.4075570821622
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[14248/15000], training loss: 0.0411
[14256/15000], training loss: 0.0420
[14264/15000], training loss: 0.0464
[14272/15000], training loss: 0.0894
[14280/15000], training loss: 0.0466
16
AVD_Home_008_1_traj9, ate: 1297.7536840423622
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[14288/15000], training loss: 0.0584
[14296/15000], training loss: 0.0920
[14304/15000], training loss: 0.0439
[14312/15000], training loss: 0.0556
[14320/15000], training loss: 0.0579
16
AVD_Home_008_1_traj9, ate: 1299.3259868563416
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[14328/15000], training loss: 0.0477
[14336/15000], training loss: 0.0730
[14344/15000], training loss: 0.0606
[14352/15000], training loss: 0.0524
[14360/15000], training loss: 0.0524
16
AVD_Home_008_1_traj9, ate: 1311.0723163147768
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[14368/15000], training loss: 0.0480
[14376/15000], training loss: 0.0434
[14384/15000], training loss: 0.0648
[14392/15000], training loss: 0.0463
[14400/15000], training loss: 0.0584
16
AVD_Home_008_1_traj9, ate: 1301.218158950984
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[14408/15000], training loss: 0.0402
[14416/15000], training loss: 0.0512
[14424/15000], training loss: 0.0446
[14432/15000], training loss: 0.0728
[14440/15000], training loss: 0.0430
16
AVD_Home_008_1_traj9, ate: 1303.7190349548073
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[14448/15000], training loss: 0.0442
[14456/15000], training loss: 0.0459
[14464/15000], training loss: 0.0405
[14472/15000], training loss: 0.0659
[14480/15000], training loss: 0.0730
16
AVD_Home_008_1_traj9, ate: 1308.8960976464828
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[14488/15000], training loss: 0.0632
[14496/15000], training loss: 0.0473
[14504/15000], training loss: 0.0486
[14512/15000], training loss: 0.0383
[14520/15000], training loss: 0.0484
16
AVD_Home_008_1_traj9, ate: 1303.1764975652159
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[14528/15000], training loss: 0.0780
[14536/15000], training loss: 0.0558
[14544/15000], training loss: 0.0495
[14552/15000], training loss: 0.0677
[14560/15000], training loss: 0.0408
16
AVD_Home_008_1_traj9, ate: 1308.021579298396
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[14568/15000], training loss: 0.0605
[14576/15000], training loss: 0.0426
[14584/15000], training loss: 0.0414
[14592/15000], training loss: 0.0599
[14600/15000], training loss: 0.0382
16
AVD_Home_008_1_traj9, ate: 1304.292768605741
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[14608/15000], training loss: 0.0449
[14616/15000], training loss: 0.0428
[14624/15000], training loss: 0.0641
[14632/15000], training loss: 0.0487
[14640/15000], training loss: 0.0811
16
AVD_Home_008_1_traj9, ate: 1314.864254596606
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[14648/15000], training loss: 0.0535
[14656/15000], training loss: 0.0490
[14664/15000], training loss: 0.0486
[14672/15000], training loss: 0.0531
[14680/15000], training loss: 0.0762
16
AVD_Home_008_1_traj9, ate: 1306.3947062164946
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[14688/15000], training loss: 0.0423
[14696/15000], training loss: 0.0473
[14704/15000], training loss: 0.0615
[14712/15000], training loss: 0.0403
[14720/15000], training loss: 0.0522
16
AVD_Home_008_1_traj9, ate: 1309.2130238091147
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[14728/15000], training loss: 0.0631
[14736/15000], training loss: 0.0411
[14744/15000], training loss: 0.0440
[14752/15000], training loss: 0.0491
[14760/15000], training loss: 0.0575
16
AVD_Home_008_1_traj9, ate: 1306.944673790158
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[14768/15000], training loss: 0.0362
[14776/15000], training loss: 0.0425
[14784/15000], training loss: 0.0709
[14792/15000], training loss: 0.0469
[14800/15000], training loss: 0.0696
16
AVD_Home_008_1_traj9, ate: 1310.490287851671
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[14808/15000], training loss: 0.0404
[14816/15000], training loss: 0.0576
[14824/15000], training loss: 0.0494
[14832/15000], training loss: 0.0396
[14840/15000], training loss: 0.0497
16
AVD_Home_008_1_traj9, ate: 1295.3961734744598
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[14848/15000], training loss: 0.0487
[14856/15000], training loss: 0.0566
[14864/15000], training loss: 0.0516
[14872/15000], training loss: 0.0816
[14880/15000], training loss: 0.0458
16
AVD_Home_008_1_traj9, ate: 1304.9260598350909
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[14888/15000], training loss: 0.0664
[14896/15000], training loss: 0.0555
[14904/15000], training loss: 0.0540
[14912/15000], training loss: 0.0575
[14920/15000], training loss: 0.1061
16
AVD_Home_008_1_traj9, ate: 1312.582836299825
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[14928/15000], training loss: 0.0411
[14936/15000], training loss: 0.0417
[14944/15000], training loss: 0.0523
[14952/15000], training loss: 0.0613
[14960/15000], training loss: 0.0507
16
AVD_Home_008_1_traj9, ate: 1298.2055928810507
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
[14968/15000], training loss: 0.0396
[14976/15000], training loss: 0.0492
[14984/15000], training loss: 0.0845
[14992/15000], training loss: 0.0663
[15000/15000], training loss: 0.0575
16
AVD_Home_008_1_traj9, ate: 1302.588796876479
model saved to ../results/AVD/AVD_Home_008_1_traj9/model_best.pth
./lstm_run_train_AVD.sh: line 25: /home/mmvc: Is a directory
